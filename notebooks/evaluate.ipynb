{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10a7443",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25447953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import CL_inference as cl_inference\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%matplotlib notebook\n",
    "plt.style.use('default')\n",
    "plt.close('all')\n",
    "\n",
    "font, rcnew = cl_inference.plot_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "N_threads = cl_inference.train_tools.set_N_threads_(N_threads=1)\n",
    "device = cl_inference.train_tools.set_torch_device_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158f91e",
   "metadata": {},
   "source": [
    "# Check loss of different runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849930c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/cosmos_storage/dlopez/Projects/CL_inference/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f613281",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_name = \"only_inference_models_all_kmax_0.6_box_3000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d984240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_name = \"only_inference_models_all_kmax_-1.2_box_3000\"\n",
    "\n",
    "# main_name = \"only_inference_models_v1v2_kmax_-1.2_box_3000\"\n",
    "\n",
    "# main_name = \"only_CL_Wein_models_v1v2_kmax_-1.2_box_3000\"\n",
    "# main_name = \"only_inference_CL_Wein_models_v1v2_kmax_-1.2_box_3000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ddadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dataset_str = \"v1v2\"\n",
    "tmp_dataset_str = \"v1v3\"\n",
    "tmp_dataset_str = \"v2v3\"\n",
    "\n",
    "tmp_dataset_str = \"f0f1\"\n",
    "tmp_dataset_str = \"f2f3\"\n",
    "tmp_dataset_str = \"f4f5\"\n",
    "tmp_dataset_str = \"f6f7\"\n",
    "tmp_dataset_str = \"f8f9\"\n",
    "\n",
    "tmp_dataset_str = \"illustris_eagle\"\n",
    "tmp_dataset_str = \"bahamas_illustris\"\n",
    "tmp_dataset_str = \"eagle_bahamas\"\n",
    "\n",
    "main_name = \"only_inference_models_\"+tmp_dataset_str+\"_kmax_0.6_box_3000\"\n",
    "# main_name = \"only_CL_Wein_models_\"+tmp_dataset_str+\"_kmax_0.6_box_3000\"\n",
    "main_name = \"only_inference_CL_Wein_models_\"+tmp_dataset_str+\"_kmax_0.6_box_3000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f483555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalute_mode = 'eval_CL' # \"eval_CL\", \"eval_CL_and_inference\", \"eval_inference_supervised\"\n",
    "if \"only_CL\" in main_name:\n",
    "    evalute_mode = 'eval_CL'\n",
    "else:\n",
    "    evalute_mode = 'eval_CL_and_inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_N_best_runs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ed7ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "listdir_names = os.listdir(os.path.join(save_path, main_name))\n",
    "sweep_names = []\n",
    "for ii, listdir_name in enumerate(listdir_names):\n",
    "    if (os.path.isdir(os.path.join(save_path, main_name, listdir_name))) and (\"sweep\" in listdir_name):\n",
    "        sweep_names.append(listdir_name)\n",
    "sweep_names = np.array(sweep_names)\n",
    "\n",
    "custom_lines = [\n",
    "    mpl.lines.Line2D([0], [0], color='grey', ls='-', lw=3, marker=None, markersize=9),\n",
    "    mpl.lines.Line2D([0], [0], color='grey', ls='--', lw=3, marker=None, markersize=9)\n",
    "]\n",
    "fig, ax = cl_inference.plot_utils.simple_plot(\n",
    "    custom_labels=[r'Train', r'Val'],\n",
    "    custom_lines=custom_lines,\n",
    "    x_label='Epoch',\n",
    "    y_label='Loss'\n",
    ")\n",
    "ax.set_title(main_name, fontsize=16)\n",
    "\n",
    "custom_lines = []\n",
    "colors = cl_inference.plot_utils.get_N_colors(len(sweep_names), mpl.colormaps['prism'])\n",
    "min_loss = []\n",
    "for ii, sweep_name in enumerate(sweep_names):\n",
    "    print(sweep_name)\n",
    "    path_to_register = os.path.join(save_path, main_name, sweep_name, \"register.txt\")\n",
    "    losses = np.loadtxt(path_to_register)\n",
    "\n",
    "#     ax.plot(losses[:, 0], c=colors[ii], lw=1, ls='-')\n",
    "    ax.plot(losses[:, 1], c=colors[ii], lw=1, ls='--')\n",
    "    \n",
    "    custom_lines.append(mpl.lines.Line2D([0], [0], color=colors[ii], ls='-', lw=3, marker=None, markersize=8))\n",
    "\n",
    "    min_loss.append(np.nanmin(losses[:, 1]))\n",
    "min_loss = np.array(min_loss)\n",
    "    \n",
    "# legend = ax.legend(custom_lines, sweep_names, loc='upper left',\n",
    "#                    fancybox=True, shadow=True, ncol=2,fontsize=7)\n",
    "# ax.add_artist(legend)\n",
    "\n",
    "# ------------------------ select_N_best_runs ------------------------ #\n",
    "\n",
    "sorted_sweeps_indexes = np.argsort(min_loss)\n",
    "selected_sweeps = sweep_names[sorted_sweeps_indexes][:select_N_best_runs]\n",
    "\n",
    "custom_lines = []\n",
    "print(\"\\n SELECTED SWEEPS\\n\")\n",
    "for ii, sweep_name in enumerate(selected_sweeps):\n",
    "    print(sweep_name)\n",
    "    path_to_register = os.path.join(save_path, main_name, sweep_name, \"register.txt\")\n",
    "    losses = np.loadtxt(path_to_register)\n",
    "\n",
    "#     ax.plot(losses[:, 0], c='k', lw=1, ls='-')\n",
    "    ax.plot(losses[:, 1], c='k', lw=1, ls='-')\n",
    "    \n",
    "    custom_lines.append(mpl.lines.Line2D([0], [0], color='k', ls='-', lw=3, marker=None, markersize=8))\n",
    "\n",
    "legend = ax.legend(custom_lines, selected_sweeps, loc='upper left',\n",
    "                   fancybox=True, shadow=True, ncol=2,fontsize=7)\n",
    "ax.add_artist(legend)\n",
    "    \n",
    "if \"only_inference\" in main_name:\n",
    "    ax.set_ylim([-7.5, -3.5])\n",
    "if \"only_CL\" in main_name:\n",
    "#     ax.set_ylim([0.05, 1])\n",
    "    ax.set_ylim([0.1, 20])\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "fig.set_tight_layout(True)\n",
    "fig.savefig(os.path.join(save_path, main_name, 'eval_loss.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3048f",
   "metadata": {},
   "source": [
    "# Define config and models to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {}\n",
    "for ii, sweep_name in enumerate(selected_sweeps):\n",
    "    print(sweep_name)\n",
    "    if sweep_name == \"manual-sweep-0\":\n",
    "        path_to_config=save_path + main_name + \"/\"+ sweep_name\n",
    "        config_file_name = \"config.yaml\"\n",
    "        configs[sweep_name] = cl_inference.train_tools.load_config_file(\n",
    "            path_to_config=path_to_config,\n",
    "            config_file_name=config_file_name\n",
    "        )\n",
    "    else:\n",
    "        path_to_config=save_path+main_name+\"/\"+sweep_name\n",
    "        configs[sweep_name] = cl_inference.evaluation_tools.load_config_file_wandb_format(\n",
    "            path_to_config=path_to_config,\n",
    "            config_file_name=\"config.yaml\"\n",
    "        )\n",
    "    # print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f6d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_lines = [\n",
    "    mpl.lines.Line2D([0], [0], color='k', ls='-', lw=3, marker=None, markersize=9),\n",
    "    mpl.lines.Line2D([0], [0], color='k', ls='--', lw=3, marker=None, markersize=9)\n",
    "]\n",
    "\n",
    "fig, ax = cl_inference.plot_utils.simple_plot(\n",
    "    custom_labels=[r'Train', r'Val'],\n",
    "    custom_lines=custom_lines,\n",
    "    x_label='Epoch',\n",
    "    y_label='Loss'\n",
    ")\n",
    "\n",
    "for ii, sweep_name in enumerate(selected_sweeps):\n",
    "    path_to_register = os.path.join(save_path, main_name, sweep_name, \"register.txt\")\n",
    "    losses = np.loadtxt(path_to_register)\n",
    "\n",
    "    ax.plot(losses[:, 0], c='k', lw=1, ls='-')\n",
    "    ax.plot(losses[:, 1], c='k', lw=1, ls='--')\n",
    "\n",
    "    fig.set_tight_layout(True)\n",
    "    fig.savefig(configs[sweep_name][\"path_save\"] + \"/eval_loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d2e281",
   "metadata": {},
   "source": [
    "### Check compatibility of config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_assert_compatible_keys = [\n",
    "\"normalize\",\n",
    "\"CL_loss\",\n",
    "\"NN_params_out\",\n",
    "\"NN_augs_batch\",\n",
    "\"add_noise_Pk\",\n",
    "\"boxsize_cosmic_variance\",\n",
    "\"inference_loss\",\n",
    "\"input_encoder\",\n",
    "\"kmax\",\n",
    "\"list_model_names\",\n",
    "\"load_encoder_model_path\",\n",
    "\"normalize\",\n",
    "\"output_encoder\",\n",
    "\"output_projector\",\n",
    "\"path_load\",\n",
    "\"path_save\",\n",
    "\"seed_mode\",\n",
    "\"train_mode\"\n",
    "]\n",
    "\n",
    "for ii, key in enumerate(list_assert_compatible_keys):\n",
    "    tmp_list = []\n",
    "    for jj, sweep_name in enumerate(selected_sweeps):\n",
    "        tmp_list.append(configs[sweep_name][key])\n",
    "    assert all(x==tmp_list[0] for x in tmp_list), \"key: \" + key + \". Not all config files share the same value: \" + str(tmp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec868d",
   "metadata": {},
   "source": [
    "# RELOAD MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b90416",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_encoder, models_inference = cl_inference.evaluation_tools.reload_models(\n",
    "    save_path, main_name, evalute_mode, configs, device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd587710",
   "metadata": {},
   "source": [
    "# CHECK DATASET EMPLOYED FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_titles=[r'$\\Omega_\\mathrm{c}$', r'$\\Omega_\\mathrm{b}$', r'$h$', r'$n_\\mathrm{s}$', r'$\\sigma_{8,\\mathrm{c}}$']\n",
    "limits_plots = [[0.23, 0.4], [0.038, 0.062], [0.60, 0.80], [0.92, 1.01], [0.73, 0.9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac36a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configs[list(configs.keys())[0]]\n",
    "\n",
    "list_model_names = config[\"list_model_names\"]\n",
    "# list_model_names = [\"Model_vary_1\", \"Model_vary_2\", \"Model_vary_3\"]\n",
    "# list_model_names = [\"Model_fixed_0\",\"Model_fixed_1\",\"Model_fixed_2\",\"Model_fixed_3\",\"Model_fixed_4\",\"Model_fixed_5\",\"Model_fixed_6\",\"Model_fixed_7\",\"Model_fixed_8\",\"Model_fixed_9\"]\n",
    "# list_model_names = [\"Model_fixed_eagle\", \"Model_fixed_illustris\", \"Model_fixed_bahamas\"]\n",
    "\n",
    "kmax = config['kmax']\n",
    "\n",
    "dset_name = \"TEST\"\n",
    "loaded_theta, loaded_xx, len_models = cl_inference.data_tools.load_stored_data(\n",
    "    path_load=os.path.join(config['path_load'], dset_name),\n",
    "    list_model_names=list_model_names,\n",
    "    return_len_models=True\n",
    ")\n",
    "dsets = {}\n",
    "dsets[dset_name] = cl_inference.data_tools.data_loader(\n",
    "    loaded_theta,\n",
    "    loaded_xx,\n",
    "    normalize=config['normalize'],\n",
    "    path_load_norm = os.path.join(config['path_save'], sweep_name),\n",
    "    NN_augs_batch = np.sum(len_models),\n",
    "    add_noise_Pk=config['add_noise_Pk'],\n",
    "    kmax=kmax,\n",
    "    boxsize_cosmic_variance=config['boxsize_cosmic_variance'], # Mpc/h\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = cl_inference.plot_utils.theta_distrib_plot(\n",
    "    dsets=dsets,\n",
    "    custom_titles=[r'$\\Omega_\\mathrm{c}$', r'$\\Omega_\\mathrm{b}$', r'$h$', r'$n_\\mathrm{s}$', r'$\\sigma_{8,\\mathrm{c}}$']\n",
    ")\n",
    "fig.savefig(config[\"path_save\"] + \"/theta_distrib.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_plot = 2\n",
    "plot_as_Pk = True\n",
    "dset_key = list(dsets.keys())[0]\n",
    "np.random.seed(config[\"seed\"])\n",
    "# indexes = np.random.choice(dsets[dset_key].NN_cosmos, NN_plot, replace=False)\n",
    "indexes = np.array([137, 1024])\n",
    "\n",
    "xx, hh, theta_true, theta_pred, Cov, len_models = cl_inference.evaluation_tools.compute_dataset_results(\n",
    "    config,\n",
    "    sweep_name,\n",
    "    list_model_names,\n",
    "    models_encoder,\n",
    "    models_inference,\n",
    "    device,\n",
    "    dset_key=dset_key,\n",
    "    indexes_cosmo=indexes,\n",
    "    use_all_dataset_augs_ordered=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3026f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if plot_as_Pk:\n",
    "    xx_plot = 10**(xx*dsets[dset_key].norm_std + dsets[dset_key].norm_mean)\n",
    "else:\n",
    "    xx_plot = xx\n",
    "\n",
    "fig, axs = mpl.pyplot.subplots(2,1,figsize=(9,9), gridspec_kw={'height_ratios': [1.5, 1]})\n",
    "axs[0].set_ylabel(r'$P(k) \\left[ \\left(h^{-1} \\mathrm{Mpc}\\right)^{3} \\right]$')\n",
    "axs[1].set_ylabel(r'$P_{Model}(k) / P_{mean}(k)$')\n",
    "axs[1].set_xlabel(r'$\\mathrm{Wavenumber}\\, k \\left[ h\\, \\mathrm{Mpc}^{-1} \\right]$')\n",
    "\n",
    "fig1, ax1 = cl_inference.plot_utils.simple_plot(x_label=r'Latent x [adim]', y_label=r'Latent y [adim]')\n",
    "fig2, axs2 = plt.subplots(1, theta_pred.shape[-1], figsize=(5.2*theta_pred.shape[-1], 5.2))\n",
    "\n",
    "if plot_as_Pk:\n",
    "    kmin=-2.3\n",
    "    N_kk = int(((kmax-kmin)/(0.6+2.3))*100)\n",
    "    kk = np.logspace(kmin, kmax, num=N_kk)\n",
    "    axs[0].axvline(10**kmax, c='k', ls=':', lw=1.)\n",
    "    axs[1].axvline(10**kmax, c='k', ls=':', lw=1.)\n",
    "else:\n",
    "    kk = np.arange(xx_plot.shape[-1])\n",
    "    kmin=-2.3\n",
    "    N_kk = int(((kmax-kmin)/(0.6+2.3))*100)-1\n",
    "    axs[0].axvline(N_kk, c='k', ls=':', lw=1.)\n",
    "    axs[1].axvline(N_kk, c='k', ls=':', lw=1.)\n",
    "\n",
    "# colors = cl_inference.plot_utils.get_N_colors(NN_plot, mpl.colormaps['prism'])\n",
    "# colors = ['#1F77B4', '#FF7F0E', '#2CA02C']                                                        # vary\n",
    "colors = list(cl_inference.plot_utils.get_N_colors(len(list_model_names), mpl.colormaps['cool'])) # fixed\n",
    "# colors = ['#D62728', '#9467BD', '#8C564B']                                                        # hydro\n",
    "# colors = ['grey']                                                                                 # all\n",
    "colors = ['#1F77B4', '#FF7F0E']\n",
    "# colors = ['#D62728', '#9467BD']\n",
    "\n",
    "linestyles = cl_inference.plot_utils.get_N_linestyles(NN_plot)\n",
    "markers = cl_inference.plot_utils.get_N_markers(NN_plot)\n",
    "ii_aug_column = 0\n",
    "custom_lines = []\n",
    "custom_labels = []\n",
    "custom_lines1 = []\n",
    "custom_labels1 = []\n",
    "for ii_model_dataset, len_model in enumerate(len_models):\n",
    "    custom_lines.append(mpl.lines.Line2D([0],[0],color=colors[ii_model_dataset],ls='-',lw=10,marker=None,markersize=8))\n",
    "    custom_labels.append(list_model_names[ii_model_dataset])\n",
    "    for ii_cosmo in range(xx_plot.shape[0]):\n",
    "        tmp_slice = slice(ii_aug_column, ii_aug_column+len_model)\n",
    "        axs[0].plot(\n",
    "            np.array(kk), xx_plot[ii_cosmo, tmp_slice].T,\n",
    "            c=colors[ii_model_dataset], linestyle=linestyles[ii_cosmo], lw=1., marker=None, ms=2, alpha=0.6\n",
    "        )\n",
    "        axs[1].plot(\n",
    "            np.array(kk), (xx_plot[ii_cosmo, tmp_slice]/np.mean(xx_plot[ii_cosmo], axis=0)).T,\n",
    "            c=colors[ii_model_dataset], linestyle=linestyles[ii_cosmo], lw=1.1, marker=None, ms=2\n",
    "        )\n",
    "        for ii_model_net, sweep_name in enumerate(selected_sweeps):\n",
    "            ax1.scatter(\n",
    "                hh[sweep_name][ii_cosmo, tmp_slice][...,0], hh[sweep_name][ii_cosmo, tmp_slice][...,1],\n",
    "                c=colors[ii_model_dataset], marker=markers[ii_cosmo], s=40\n",
    "            )\n",
    "        for ii_cosmo_param in range(theta_true.shape[-1]):\n",
    "            tmp_theta_true = np.repeat(theta_true[ii_cosmo, ii_cosmo_param], len_model)\n",
    "            tmp_theta_pred = theta_pred[ii_cosmo, tmp_slice, ii_cosmo_param]\n",
    "            tmp_Cov = Cov[ii_cosmo, tmp_slice, ii_cosmo_param, ii_cosmo]\n",
    "            axs2[ii_cosmo_param].scatter(\n",
    "                tmp_theta_true, tmp_theta_pred,\n",
    "               color=colors[ii_model_dataset], marker=markers[ii_cosmo], s=40, alpha=1.\n",
    "            )\n",
    "            axs2[ii_cosmo_param].errorbar(\n",
    "                tmp_theta_true, tmp_theta_pred,\n",
    "                yerr=np.sqrt(tmp_Cov),\n",
    "                c=colors[ii_model_dataset], ls='', capsize=2, alpha=1., elinewidth=1\n",
    "            )            \n",
    "        if ii_model_dataset == 0:\n",
    "            custom_lines1.append(\n",
    "                mpl.lines.Line2D([0],[0],color='grey',ls=linestyles[ii_cosmo],lw=3,marker=None,markersize=8)\n",
    "            )\n",
    "            custom_labels1.append(\"Cosmo #\" + str(indexes[ii_cosmo]))\n",
    "            axs2[ii_cosmo].set_title(custom_titles[ii_cosmo], size=26, pad=16)\n",
    "            axs2[ii_cosmo].set_xlabel(r'True ', size=26)\n",
    "            ymax = limits_plots[ii_cosmo][0]\n",
    "            ymin = limits_plots[ii_cosmo][1]\n",
    "            tmp_xx = np.linspace(ymin, ymax, 2)\n",
    "            axs2[ii_cosmo].plot(tmp_xx, tmp_xx, c='k', lw=2, ls='-', alpha=1)\n",
    "            axs2[ii_cosmo].set_xlim([ymin, ymax])\n",
    "            axs2[ii_cosmo].set_ylim([ymin, ymax])\n",
    "            \n",
    "    ii_aug_column += len_model\n",
    "    \n",
    "axs2[0].set_ylabel(r'Pred ', size=26)\n",
    "\n",
    "legend = axs[0].legend(custom_lines, custom_labels, loc='upper right', fancybox=True, shadow=True, ncol=1,fontsize=14)\n",
    "axs[0].add_artist(legend)\n",
    "legend = axs[0].legend(custom_lines1, custom_labels1, loc='lower left', fancybox=True, shadow=True, ncol=2,fontsize=14)\n",
    "axs[0].add_artist(legend)\n",
    "\n",
    "if plot_as_Pk:\n",
    "    axs[0].set_xscale('log')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[0].set_xlim([0.004, 4.5])\n",
    "    axs[0].set_ylim([40., 70000.])\n",
    "    axs[1].set_xscale('log')\n",
    "    axs[1].set_xlim([0.004, 4.5])\n",
    "    axs[1].set_ylim([0.8, 1.2])\n",
    "else:\n",
    "    axs[0].set_xlim([0., 100.])\n",
    "    axs[0].set_ylim([-2.5, 2.5])\n",
    "    axs[1].set_xlim([0., 100.])\n",
    "    axs[1].set_ylim([0.8, 1.2])\n",
    "\n",
    "axs[0].set_xticklabels([])\n",
    "    \n",
    "fig.set_tight_layout(True)\n",
    "fig1.set_tight_layout(True)\n",
    "fig2.set_tight_layout(True)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "fig.savefig(configs[list(configs.keys())[0]][\"path_save\"] + \"/Pk.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198fc86d",
   "metadata": {},
   "source": [
    "# EVALUATE vary AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e964e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model_names = [\"Model_vary_1\", \"Model_vary_2\", \"Model_vary_3\"]\n",
    "colors = ['#1F77B4', '#FF7F0E', '#2CA02C']\n",
    "\n",
    "xx, hh, theta_true, theta_pred, Cov, len_models = cl_inference.evaluation_tools.compute_dataset_results(\n",
    "    configs[selected_sweeps[0]],\n",
    "    sweep_name=sweep_name,\n",
    "    list_model_names=list_model_names,\n",
    "    models_encoder=models_encoder,\n",
    "    models_inference=models_inference,\n",
    "    device=device,\n",
    "    dset_key=\"TEST\"\n",
    ")\n",
    "fig, axs = cl_inference.plot_utils.plot_inference_split_models(\n",
    "    list_model_names,\n",
    "    len_models,\n",
    "    theta_true,\n",
    "    theta_pred,\n",
    "    Cov,\n",
    "    custom_titles=[r'$\\Omega_\\mathrm{c}$', r'$\\Omega_\\mathrm{b}$', r'$h$', r'$n_\\mathrm{s}$', r'$\\sigma_{8,\\mathrm{c}}$'],\n",
    "    limits_plots = [[0.23, 0.4], [0.038, 0.062], [0.60, 0.80], [0.92, 1.01], [0.73, 0.9]],\n",
    "    colors=colors\n",
    ")\n",
    "fig.suptitle(main_name, size=18)\n",
    "fig.set_tight_layout(True)\n",
    "fig.savefig(configs[list(configs.keys())[0]][\"path_save\"] + \"/eval_inference_vary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbcc9a5",
   "metadata": {},
   "source": [
    "# EVALUATE fixed AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d8ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model_names = [\n",
    "    \"Model_fixed_0\",\n",
    "    \"Model_fixed_1\",\n",
    "    \"Model_fixed_2\",\n",
    "    \"Model_fixed_3\",\n",
    "    \"Model_fixed_4\",\n",
    "    \"Model_fixed_5\",\n",
    "    \"Model_fixed_6\",\n",
    "    \"Model_fixed_7\",\n",
    "    \"Model_fixed_8\",\n",
    "    \"Model_fixed_9\"\n",
    "]\n",
    "colors = list(cl_inference.plot_utils.get_N_colors(len(list_model_names), mpl.colormaps['cool']))\n",
    "\n",
    "xx, hh, theta_true, theta_pred, Cov, len_models = cl_inference.evaluation_tools.compute_dataset_results(\n",
    "    configs[selected_sweeps[0]],\n",
    "    sweep_name=sweep_name,\n",
    "    list_model_names=list_model_names,\n",
    "    models_encoder=models_encoder,\n",
    "    models_inference=models_inference,\n",
    "    device=device,\n",
    "    dset_key=\"TEST\"\n",
    ")\n",
    "fig, axs = cl_inference.plot_utils.plot_inference_split_models(\n",
    "    list_model_names,\n",
    "    len_models,\n",
    "    theta_true,\n",
    "    theta_pred,\n",
    "    Cov,\n",
    "    custom_titles=[r'$\\Omega_\\mathrm{c}$', r'$\\Omega_\\mathrm{b}$', r'$h$', r'$n_\\mathrm{s}$', r'$\\sigma_{8,\\mathrm{c}}$'],\n",
    "    limits_plots = [[0.23, 0.4], [0.038, 0.062], [0.60, 0.80], [0.92, 1.01], [0.73, 0.9]],\n",
    "    colors=colors\n",
    ")\n",
    "fig.suptitle(main_name, size=18)\n",
    "fig.set_tight_layout(True)\n",
    "fig.savefig(configs[list(configs.keys())[0]][\"path_save\"] + \"/eval_inference_fixed.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cbec78",
   "metadata": {},
   "source": [
    "# EVALUATE Hydro AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac09f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model_names = [\"Model_fixed_eagle\", \"Model_fixed_illustris\", \"Model_fixed_bahamas\"]\n",
    "colors = ['#D62728', '#9467BD', '#8C564B']\n",
    "\n",
    "xx, hh, theta_true, theta_pred, Cov, len_models = cl_inference.evaluation_tools.compute_dataset_results(\n",
    "    configs[selected_sweeps[0]],\n",
    "    sweep_name=sweep_name,\n",
    "    list_model_names=list_model_names,\n",
    "    models_encoder=models_encoder,\n",
    "    models_inference=models_inference,\n",
    "    device=device,\n",
    "    dset_key=\"TEST\"\n",
    ")\n",
    "fig, axs = cl_inference.plot_utils.plot_inference_split_models(\n",
    "    list_model_names,\n",
    "    len_models,\n",
    "    theta_true,\n",
    "    theta_pred,\n",
    "    Cov,\n",
    "    custom_titles=[r'$\\Omega_\\mathrm{c}$', r'$\\Omega_\\mathrm{b}$', r'$h$', r'$n_\\mathrm{s}$', r'$\\sigma_{8,\\mathrm{c}}$'],\n",
    "    limits_plots = [[0.23, 0.4], [0.038, 0.062], [0.60, 0.80], [0.92, 1.01], [0.73, 0.9]],\n",
    "    colors=colors\n",
    ")\n",
    "fig.suptitle(main_name, size=18)\n",
    "fig.set_tight_layout(True)\n",
    "fig.savefig(configs[list(configs.keys())[0]][\"path_save\"] + \"/eval_inference_hydros.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ac375",
   "metadata": {},
   "source": [
    "# EVALUATE ALL AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40efd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model_names = [\"Model_vary_all\"]\n",
    "colors = ['grey']\n",
    "\n",
    "xx, hh, theta_true, theta_pred, Cov, len_models = cl_inference.evaluation_tools.compute_dataset_results(\n",
    "    configs[selected_sweeps[0]],\n",
    "    sweep_name=sweep_name,\n",
    "    list_model_names=list_model_names,\n",
    "    models_encoder=models_encoder,\n",
    "    models_inference=models_inference,\n",
    "    device=device,\n",
    "    dset_key=\"TEST\"\n",
    ")\n",
    "fig, axs = cl_inference.plot_utils.plot_inference_split_models(\n",
    "    list_model_names,\n",
    "    len_models,\n",
    "    theta_true,\n",
    "    theta_pred,\n",
    "    Cov,\n",
    "    custom_titles=[r'$\\Omega_\\mathrm{c}$', r'$\\Omega_\\mathrm{b}$', r'$h$', r'$n_\\mathrm{s}$', r'$\\sigma_{8,\\mathrm{c}}$'],\n",
    "    limits_plots = [[0.23, 0.4], [0.038, 0.062], [0.60, 0.80], [0.92, 1.01], [0.73, 0.9]],\n",
    "    colors=colors\n",
    ")\n",
    "fig.suptitle(main_name, size=18)\n",
    "fig.set_tight_layout(True)\n",
    "fig.savefig(configs[list(configs.keys())[0]][\"path_save\"] + \"/eval_inference_all.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061cabec",
   "metadata": {},
   "source": [
    "# generate bias figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b7390",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_samples = []\n",
    "for ii, model_name in enumerate(config[\"list_model_names\"]):\n",
    "    xx, hh, theta_true, theta_pred, Cov, len_models = cl_inference.evaluation_tools.compute_dataset_results(\n",
    "        configs[selected_sweeps[0]],\n",
    "        sweep_name=sweep_name,\n",
    "        list_model_names=[model_name],\n",
    "        models_encoder=models_encoder,\n",
    "        models_inference=models_inference,\n",
    "        device=device,\n",
    "        dset_key=\"TEST\"\n",
    "    )\n",
    "    theta_true = np.repeat(theta_true, theta_pred.shape[1], axis=0)\n",
    "    theta_pred = np.reshape(theta_pred, (theta_pred.shape[0]*theta_pred.shape[1], theta_pred.shape[-1]))[:,np.newaxis]\n",
    "    Cov = np.reshape(Cov, (Cov.shape[0]*Cov.shape[1], Cov.shape[-2], Cov.shape[-1]))[:,np.newaxis]\n",
    "    tmp_bin_edges_self , tmp_bin_centers_self, tmp_y_hists_self, tmp_NN_points_self = cl_inference.plot_utils.compute_bias_hist_augs(\n",
    "        theta_true, theta_pred, Cov, min_x=-6, max_x=6, bins=60\n",
    "    )\n",
    "    if ii == 0:\n",
    "        bin_edges_self = tmp_bin_edges_self\n",
    "        bin_centers_self = tmp_bin_centers_self\n",
    "        y_hists_self = tmp_y_hists_self\n",
    "        NN_points_self = tmp_NN_points_self\n",
    "    else:\n",
    "        bin_edges_self = np.concatenate((bin_edges_self, tmp_bin_edges_self), axis=1)\n",
    "        bin_centers_self = np.concatenate((bin_centers_self, tmp_bin_centers_self), axis=1)\n",
    "        y_hists_self = np.concatenate((y_hists_self, tmp_y_hists_self), axis=1)\n",
    "        NN_points_self = np.concatenate((NN_points_self, tmp_NN_points_self), axis=1)\n",
    "    NN_samples.append(xx.shape[0]*xx.shape[1])\n",
    "    \n",
    "list_model_names = [\"Model_vary_all\"]\n",
    "xx, hh, theta_true, theta_pred, Cov, len_models = cl_inference.evaluation_tools.compute_dataset_results(\n",
    "    configs[selected_sweeps[0]],\n",
    "    sweep_name=sweep_name,\n",
    "    list_model_names=list_model_names,\n",
    "    models_encoder=models_encoder,\n",
    "    models_inference=models_inference,\n",
    "    device=device,\n",
    "    dset_key=\"TEST\"\n",
    ")\n",
    "theta_true = np.repeat(theta_true, theta_pred.shape[1], axis=0)\n",
    "theta_pred = np.reshape(theta_pred, (theta_pred.shape[0]*theta_pred.shape[1], theta_pred.shape[-1]))[:,np.newaxis]\n",
    "Cov = np.reshape(Cov, (Cov.shape[0]*Cov.shape[1], Cov.shape[-2], Cov.shape[-1]))[:,np.newaxis]\n",
    "bin_edges_all, bin_centers_all, y_hists_all, NN_points_all = cl_inference.plot_utils.compute_bias_hist_augs(\n",
    "    theta_true, theta_pred, Cov, min_x=-6, max_x=6, bins=60\n",
    ")\n",
    "NN_samples.append(xx.shape[0]*xx.shape[1])\n",
    "NN_samples=np.array(NN_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b59ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centers_self = np.insert(bin_centers_self, 0, bin_edges_self[..., 0], axis=-1)\n",
    "bin_centers_self = np.insert(bin_centers_self, bin_centers_self.shape[-1], bin_edges_self[..., -1], axis=-1)\n",
    "\n",
    "bin_centers_all = np.insert(bin_centers_all, 0, bin_edges_all[..., 0], axis=-1)\n",
    "bin_centers_all = np.insert(bin_centers_all, bin_centers_all.shape[-1], bin_edges_all[..., -1], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f52f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = np.concatenate((y_hists_self, y_hists_all), axis=1)\n",
    "bin_centers_final = np.concatenate((bin_centers_self, bin_centers_all), axis=1)\n",
    "NN_points_final = np.concatenate((NN_points_self, NN_points_all), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3173c7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fontsize=26\n",
    "fontsize1=18\n",
    "# colors = cl_inference.plot_utils.get_N_colors(y_final.shape[1], mpl.colormaps['prism'])\n",
    "colors = ['#1F77B4', '#FF7F0E', 'grey']\n",
    "# colors = ['#D62728', '#9467BD', 'grey']\n",
    "custom_titles=[r'$\\Omega_\\mathrm{c}$', r'$\\Omega_\\mathrm{b}$', r'$h$', r'$n_\\mathrm{s}$', r'$\\sigma_{8,\\mathrm{c}}$']\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1, len(custom_titles), figsize=(5.2*len(custom_titles), 5.2)\n",
    ")\n",
    "axs[0].set_ylabel(r'Normalized Counts ', size=fontsize)\n",
    "\n",
    "for ii_cosmo_param in range(len(custom_titles)):\n",
    "    ax = axs[ii_cosmo_param]\n",
    "    ax.set_title(custom_titles[ii_cosmo_param], size=fontsize+8, pad=16)\n",
    "    ax.set_xlabel(r'Bias ', size=fontsize)\n",
    "    ax.axvline(0, c='k', ls=':', lw=1)\n",
    "#     ax.axvspan(np.min(bin_centers_final[ii_cosmo_param]), -1, alpha=0.2, facecolor ='red')\n",
    "#     ax.axvspan(1, np.max(bin_centers_final[ii_cosmo_param]), alpha=0.2, facecolor ='red')\n",
    "    for ii_aug in range(y_final.shape[1]):\n",
    "        if ii_aug+1 == y_final.shape[1]:\n",
    "            color = 'k'\n",
    "        else:\n",
    "            color = colors[ii_aug]\n",
    "        ax.plot(\n",
    "            bin_centers_final[ii_cosmo_param, ii_aug], y_final[ii_cosmo_param, ii_aug]/NN_points_final[ii_cosmo_param, ii_aug],\n",
    "            color=color, lw=3, alpha=0.9\n",
    "        )\n",
    "        \n",
    "#         tmp_hist = np.random.normal(loc=0,scale=1,size=NN_samples[ii_aug])\n",
    "#         counts, bin_edges = np.histogram(tmp_hist, bins=50, range=(-6, 6))\n",
    "#         bin_centers = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "#         y_hist = np.array(counts)/NN_samples[ii_aug]\n",
    "#         ax.plot(\n",
    "#             bin_centers, y_hist, color=color, lw=3, alpha=0.9, ls='--'\n",
    "#         )\n",
    "        \n",
    "fig.set_tight_layout(True)\n",
    "fig.savefig(configs[list(configs.keys())[0]][\"path_save\"] + \"/bias.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ededb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask =np.abs(bin_centers_final) > 2\n",
    "fraction_biased = np.zeros((y_final.shape[0], y_final.shape[1]))\n",
    "for ii in range(y_final.shape[0]):\n",
    "    for jj in range(y_final.shape[1]):\n",
    "        fraction_biased[ii,jj] = np.sum(y_final[ii, jj][mask[ii, jj]])/NN_points_final[ii,jj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff7d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(configs[list(configs.keys())[0]][\"path_save\"] + \"/y_final.npy\", y_final)\n",
    "np.save(configs[list(configs.keys())[0]][\"path_save\"] + \"/bin_centers_final.npy\", bin_centers_final)\n",
    "np.save(configs[list(configs.keys())[0]][\"path_save\"] + \"/fraction_biased.npy\", fraction_biased)\n",
    "np.save(configs[list(configs.keys())[0]][\"path_save\"] + \"/NN_points_final.npy\", NN_points_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a5659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
