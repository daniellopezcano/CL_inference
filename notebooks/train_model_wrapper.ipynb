{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39e56f8",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1c050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_threads: 1\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import CL_inference as cl_inference\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%matplotlib notebook\n",
    "plt.style.use('default')\n",
    "plt.close('all')\n",
    "\n",
    "font, rcnew = cl_inference.plot_utils.matplotlib_default_config()\n",
    "mpl.rc('font', **font)\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "N_threads = cl_inference.train_tools.set_N_threads_(N_threads=1)\n",
    "device = cl_inference.train_tools.set_torch_device_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e68035",
   "metadata": {},
   "source": [
    "# SETUP - config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3c26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_name = \"config_only_inference_models_v1v2_kmax_0.6_box_3000.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df310979",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = cl_inference.train_tools.load_config_file(\n",
    "    path_to_config=\"../config_files\",\n",
    "    config_file_name=config_file_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315aacb",
   "metadata": {},
   "source": [
    "# TRAIN MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea2993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_save: /cosmos_storage/dlopez/Projects/CL_inference/models/only_inference_models_v1v2_kmax_0.6_box_3000/manual-sweep-0\n",
      "N_threads: 1\n",
      "Device: cuda\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 1 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: 1.136262 | batch: [   51/  512]\n",
      "    loss: 0.523813 | batch: [  102/  512]\n",
      "    loss: -0.156301 | batch: [  153/  512]\n",
      "    loss: -0.874131 | batch: [  204/  512]\n",
      "    loss: -1.180862 | batch: [  255/  512]\n",
      "    loss: -2.032018 | batch: [  306/  512]\n",
      "    loss: -2.585196 | batch: [  357/  512]\n",
      "    loss: -2.978978 | batch: [  408/  512]\n",
      "    loss: -3.271229 | batch: [  459/  512]\n",
      "    loss: -3.681713 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    Saving Model from Epoch-0\n",
      "\n",
      "    min_val_loss = -2.693128\n",
      "    train_loss = -2.743610\n",
      "    val_loss = -2.693128\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 2 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -3.739954 | batch: [   51/  512]\n",
      "    loss: -4.077950 | batch: [  102/  512]\n",
      "    loss: -3.968775 | batch: [  153/  512]\n",
      "    loss: -3.820341 | batch: [  204/  512]\n",
      "    loss: -4.075076 | batch: [  255/  512]\n",
      "    loss: -4.267532 | batch: [  306/  512]\n",
      "    loss: -4.430441 | batch: [  357/  512]\n",
      "    loss: -4.306337 | batch: [  408/  512]\n",
      "    loss: -4.364781 | batch: [  459/  512]\n",
      "    loss: -4.470816 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -2.693128\n",
      "    train_loss = -3.425003\n",
      "    val_loss = -3.432221\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 3 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -3.205920 | batch: [   51/  512]\n",
      "    loss: -4.182875 | batch: [  102/  512]\n",
      "    loss: -4.189906 | batch: [  153/  512]\n",
      "    loss: -4.413900 | batch: [  204/  512]\n",
      "    loss: -4.496781 | batch: [  255/  512]\n",
      "    loss: -4.915816 | batch: [  306/  512]\n",
      "    loss: -4.565926 | batch: [  357/  512]\n",
      "    loss: -4.764558 | batch: [  408/  512]\n",
      "    loss: -4.563962 | batch: [  459/  512]\n",
      "    loss: -4.449577 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -3.432221\n",
      "    train_loss = -3.655900\n",
      "    val_loss = -3.627139\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 4 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -4.680684 | batch: [   51/  512]\n",
      "    loss: -4.348835 | batch: [  102/  512]\n",
      "    loss: -4.777676 | batch: [  153/  512]\n",
      "    loss: -4.937156 | batch: [  204/  512]\n",
      "    loss: -4.280403 | batch: [  255/  512]\n",
      "    loss: -4.912726 | batch: [  306/  512]\n",
      "    loss: -4.225521 | batch: [  357/  512]\n",
      "    loss: -4.720988 | batch: [  408/  512]\n",
      "    loss: -4.662814 | batch: [  459/  512]\n",
      "    loss: -4.905656 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -3.627139\n",
      "    train_loss = -3.714678\n",
      "    val_loss = -3.718457\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 5 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -4.689783 | batch: [   51/  512]\n",
      "    loss: -4.924140 | batch: [  102/  512]\n",
      "    loss: -5.191511 | batch: [  153/  512]\n",
      "    loss: -4.605745 | batch: [  204/  512]\n",
      "    loss: -2.381081 | batch: [  255/  512]\n",
      "    loss: -5.177274 | batch: [  306/  512]\n",
      "    loss: -5.167296 | batch: [  357/  512]\n",
      "    loss: -5.089522 | batch: [  408/  512]\n",
      "    loss: -5.061747 | batch: [  459/  512]\n",
      "    loss: -4.096845 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -3.718457\n",
      "    train_loss = -3.675020\n",
      "    val_loss = -3.655699\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 6 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -4.930746 | batch: [   51/  512]\n",
      "    loss: -4.354727 | batch: [  102/  512]\n",
      "    loss: -4.325300 | batch: [  153/  512]\n",
      "    loss: -5.134792 | batch: [  204/  512]\n",
      "    loss: -5.116935 | batch: [  255/  512]\n",
      "    loss: -5.244387 | batch: [  306/  512]\n",
      "    loss: -5.131768 | batch: [  357/  512]\n",
      "    loss: -5.005141 | batch: [  408/  512]\n",
      "    loss: -5.161246 | batch: [  459/  512]\n",
      "    loss: -5.211236 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -3.718457\n",
      "    train_loss = -3.687231\n",
      "    val_loss = -3.734046\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 7 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -4.898628 | batch: [   51/  512]\n",
      "    loss: -5.020145 | batch: [  102/  512]\n",
      "    loss: -4.928407 | batch: [  153/  512]\n",
      "    loss: -4.974686 | batch: [  204/  512]\n",
      "    loss: -4.761349 | batch: [  255/  512]\n",
      "    loss: -5.102103 | batch: [  306/  512]\n",
      "    loss: -4.352765 | batch: [  357/  512]\n",
      "    loss: -4.924964 | batch: [  408/  512]\n",
      "    loss: -5.307305 | batch: [  459/  512]\n",
      "    loss: -5.218605 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -3.734046\n",
      "    train_loss = -4.073822\n",
      "    val_loss = -4.044920\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 8 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.278330 | batch: [   51/  512]\n",
      "    loss: -5.437908 | batch: [  102/  512]\n",
      "    loss: -5.039045 | batch: [  153/  512]\n",
      "    loss: -5.400458 | batch: [  204/  512]\n",
      "    loss: -5.400406 | batch: [  255/  512]\n",
      "    loss: -5.206003 | batch: [  306/  512]\n",
      "    loss: -4.594710 | batch: [  357/  512]\n",
      "    loss: -5.138797 | batch: [  408/  512]\n",
      "    loss: -4.862687 | batch: [  459/  512]\n",
      "    loss: -5.027452 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.044920\n",
      "    train_loss = -3.933716\n",
      "    val_loss = -3.928281\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 9 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -4.524780 | batch: [   51/  512]\n",
      "    loss: -4.543178 | batch: [  102/  512]\n",
      "    loss: -5.287759 | batch: [  153/  512]\n",
      "    loss: -5.501038 | batch: [  204/  512]\n",
      "    loss: -5.254206 | batch: [  255/  512]\n",
      "    loss: -5.182137 | batch: [  306/  512]\n",
      "    loss: -5.051527 | batch: [  357/  512]\n",
      "    loss: -4.354084 | batch: [  408/  512]\n",
      "    loss: -5.135233 | batch: [  459/  512]\n",
      "    loss: -4.223424 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.044920\n",
      "    train_loss = -4.222279\n",
      "    val_loss = -4.209754\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 10 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -4.692579 | batch: [   51/  512]\n",
      "    loss: -5.384295 | batch: [  102/  512]\n",
      "    loss: -5.151038 | batch: [  153/  512]\n",
      "    loss: -5.326456 | batch: [  204/  512]\n",
      "    loss: -5.276349 | batch: [  255/  512]\n",
      "    loss: -4.929847 | batch: [  306/  512]\n",
      "    loss: -5.366216 | batch: [  357/  512]\n",
      "    loss: -4.916230 | batch: [  408/  512]\n",
      "    loss: -4.863307 | batch: [  459/  512]\n",
      "    loss: -5.512377 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.209754\n",
      "    train_loss = -4.044857\n",
      "    val_loss = -4.086368\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 11 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.241510 | batch: [   51/  512]\n",
      "    loss: -4.785379 | batch: [  102/  512]\n",
      "    loss: -5.402204 | batch: [  153/  512]\n",
      "    loss: -5.242009 | batch: [  204/  512]\n",
      "    loss: -5.200548 | batch: [  255/  512]\n",
      "    loss: -5.051523 | batch: [  306/  512]\n",
      "    loss: -5.159340 | batch: [  357/  512]\n",
      "    loss: -5.326463 | batch: [  408/  512]\n",
      "    loss: -5.312389 | batch: [  459/  512]\n",
      "    loss: -1.322376 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.209754\n",
      "    train_loss = -3.715683\n",
      "    val_loss = -3.759666\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 12 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.550767 | batch: [   51/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -4.302398 | batch: [  102/  512]\n",
      "    loss: -5.475472 | batch: [  153/  512]\n",
      "    loss: -4.504690 | batch: [  204/  512]\n",
      "    loss: -5.474822 | batch: [  255/  512]\n",
      "    loss: -4.490759 | batch: [  306/  512]\n",
      "    loss: -5.324895 | batch: [  357/  512]\n",
      "    loss: -5.097633 | batch: [  408/  512]\n",
      "    loss: -5.000585 | batch: [  459/  512]\n",
      "    loss: -4.326351 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.209754\n",
      "    train_loss = -3.906153\n",
      "    val_loss = -3.911193\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 13 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.086550 | batch: [   51/  512]\n",
      "    loss: -5.589587 | batch: [  102/  512]\n",
      "    loss: -5.570123 | batch: [  153/  512]\n",
      "    loss: -5.654682 | batch: [  204/  512]\n",
      "    loss: -5.342110 | batch: [  255/  512]\n",
      "    loss: -5.444984 | batch: [  306/  512]\n",
      "    loss: -5.718028 | batch: [  357/  512]\n",
      "    loss: -5.045259 | batch: [  408/  512]\n",
      "    loss: -5.530620 | batch: [  459/  512]\n",
      "    loss: -5.372849 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.209754\n",
      "    train_loss = -4.026589\n",
      "    val_loss = -4.046724\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 14 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.556462 | batch: [   51/  512]\n",
      "    loss: -5.302616 | batch: [  102/  512]\n",
      "    loss: -5.505977 | batch: [  153/  512]\n",
      "    loss: -5.351297 | batch: [  204/  512]\n",
      "    loss: 1.863460 | batch: [  255/  512]\n",
      "    loss: -5.673593 | batch: [  306/  512]\n",
      "    loss: -5.306473 | batch: [  357/  512]\n",
      "    loss: -5.285760 | batch: [  408/  512]\n",
      "    loss: -5.294737 | batch: [  459/  512]\n",
      "    loss: -5.186334 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.209754\n",
      "    train_loss = -3.317070\n",
      "    val_loss = -3.430515\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 15 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.479451 | batch: [   51/  512]\n",
      "    loss: -5.056733 | batch: [  102/  512]\n",
      "    loss: -5.620206 | batch: [  153/  512]\n",
      "    loss: -5.528399 | batch: [  204/  512]\n",
      "    loss: -5.463232 | batch: [  255/  512]\n",
      "    loss: -4.462483 | batch: [  306/  512]\n",
      "    loss: -5.626278 | batch: [  357/  512]\n",
      "    loss: -5.482302 | batch: [  408/  512]\n",
      "    loss: -5.472605 | batch: [  459/  512]\n",
      "    loss: -5.114661 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.209754\n",
      "    train_loss = -4.244785\n",
      "    val_loss = -4.228785\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 16 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.602762 | batch: [   51/  512]\n",
      "    loss: -5.596910 | batch: [  102/  512]\n",
      "    loss: -5.251909 | batch: [  153/  512]\n",
      "    loss: -5.604280 | batch: [  204/  512]\n",
      "    loss: -5.456550 | batch: [  255/  512]\n",
      "    loss: -5.358158 | batch: [  306/  512]\n",
      "    loss: -5.865887 | batch: [  357/  512]\n",
      "    loss: -5.538330 | batch: [  408/  512]\n",
      "    loss: -5.484027 | batch: [  459/  512]\n",
      "    loss: -5.921381 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.228785\n",
      "    train_loss = -3.945257\n",
      "    val_loss = -4.004914\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 17 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -4.753379 | batch: [   51/  512]\n",
      "    loss: -5.680910 | batch: [  102/  512]\n",
      "    loss: -5.721474 | batch: [  153/  512]\n",
      "    loss: -5.148906 | batch: [  204/  512]\n",
      "    loss: -5.263018 | batch: [  255/  512]\n",
      "    loss: -5.706848 | batch: [  306/  512]\n",
      "    loss: -5.518533 | batch: [  357/  512]\n",
      "    loss: -5.972899 | batch: [  408/  512]\n",
      "    loss: -5.232497 | batch: [  459/  512]\n",
      "    loss: -5.891654 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.228785\n",
      "    train_loss = -4.299762\n",
      "    val_loss = -4.316426\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 18 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -4.855792 | batch: [   51/  512]\n",
      "    loss: -5.315517 | batch: [  102/  512]\n",
      "    loss: -5.484580 | batch: [  153/  512]\n",
      "    loss: -4.827217 | batch: [  204/  512]\n",
      "    loss: -5.543287 | batch: [  255/  512]\n",
      "    loss: -5.810854 | batch: [  306/  512]\n",
      "    loss: -5.167216 | batch: [  357/  512]\n",
      "    loss: -5.561604 | batch: [  408/  512]\n",
      "    loss: -5.634333 | batch: [  459/  512]\n",
      "    loss: -4.744398 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.316426\n",
      "    train_loss = -4.248946\n",
      "    val_loss = -4.286495\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 19 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.554187 | batch: [   51/  512]\n",
      "    loss: -5.581036 | batch: [  102/  512]\n",
      "    loss: -5.731652 | batch: [  153/  512]\n",
      "    loss: -5.766860 | batch: [  204/  512]\n",
      "    loss: -5.722975 | batch: [  255/  512]\n",
      "    loss: -5.726375 | batch: [  306/  512]\n",
      "    loss: -4.654446 | batch: [  357/  512]\n",
      "    loss: -5.809030 | batch: [  408/  512]\n",
      "    loss: -4.711460 | batch: [  459/  512]\n",
      "    loss: -5.816208 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.316426\n",
      "    train_loss = -4.251925\n",
      "    val_loss = -4.234982\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 20 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -4.728284 | batch: [   51/  512]\n",
      "    loss: -5.666863 | batch: [  102/  512]\n",
      "    loss: -5.918149 | batch: [  153/  512]\n",
      "    loss: -5.749204 | batch: [  204/  512]\n",
      "    loss: -5.817343 | batch: [  255/  512]\n",
      "    loss: -5.080292 | batch: [  306/  512]\n",
      "    loss: -5.243112 | batch: [  357/  512]\n",
      "    loss: -5.871106 | batch: [  408/  512]\n",
      "    loss: -5.806727 | batch: [  459/  512]\n",
      "    loss: -5.748261 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.316426\n",
      "    train_loss = -4.198513\n",
      "    val_loss = -4.197709\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 21 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.267072 | batch: [   51/  512]\n",
      "    loss: -5.845882 | batch: [  102/  512]\n",
      "    loss: -5.770196 | batch: [  153/  512]\n",
      "    loss: -5.188868 | batch: [  204/  512]\n",
      "    loss: -5.871464 | batch: [  255/  512]\n",
      "    loss: -5.309966 | batch: [  306/  512]\n",
      "    loss: -5.779242 | batch: [  357/  512]\n",
      "    loss: -5.665041 | batch: [  408/  512]\n",
      "    loss: -5.610170 | batch: [  459/  512]\n",
      "    loss: -5.837458 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.316426\n",
      "    train_loss = -4.415062\n",
      "    val_loss = -4.429222\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 22 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.366194 | batch: [   51/  512]\n",
      "    loss: -5.298745 | batch: [  102/  512]\n",
      "    loss: -6.078081 | batch: [  153/  512]\n",
      "    loss: -5.594165 | batch: [  204/  512]\n",
      "    loss: -6.044716 | batch: [  255/  512]\n",
      "    loss: -4.448508 | batch: [  306/  512]\n",
      "    loss: -5.885635 | batch: [  357/  512]\n",
      "    loss: -5.534535 | batch: [  408/  512]\n",
      "    loss: -5.818117 | batch: [  459/  512]\n",
      "    loss: -5.883307 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.429222\n",
      "    train_loss = -4.477699\n",
      "    val_loss = -4.483861\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 23 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.535738 | batch: [   51/  512]\n",
      "    loss: -5.183649 | batch: [  102/  512]\n",
      "    loss: -5.212454 | batch: [  153/  512]\n",
      "    loss: -5.749299 | batch: [  204/  512]\n",
      "    loss: -5.381837 | batch: [  255/  512]\n",
      "    loss: -5.154159 | batch: [  306/  512]\n",
      "    loss: -5.967138 | batch: [  357/  512]\n",
      "    loss: -5.833868 | batch: [  408/  512]\n",
      "    loss: -5.553623 | batch: [  459/  512]\n",
      "    loss: -5.762958 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.483861\n",
      "    train_loss = -4.533245\n",
      "    val_loss = -4.539249\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 24 --------------\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -5.659237 | batch: [   51/  512]\n",
      "    loss: -5.752472 | batch: [  102/  512]\n",
      "    loss: -5.577640 | batch: [  153/  512]\n",
      "    loss: -5.999660 | batch: [  204/  512]\n",
      "    loss: -5.787224 | batch: [  255/  512]\n",
      "    loss: -5.838238 | batch: [  306/  512]\n",
      "    loss: -5.328215 | batch: [  357/  512]\n",
      "    loss: -6.008457 | batch: [  408/  512]\n",
      "    loss: -5.421087 | batch: [  459/  512]\n",
      "    loss: -5.387028 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.539249\n",
      "    train_loss = -4.420328\n",
      "    val_loss = -4.434624\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 25 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.669384 | batch: [   51/  512]\n",
      "    loss: -5.775414 | batch: [  102/  512]\n",
      "    loss: -5.801302 | batch: [  153/  512]\n",
      "    loss: -5.814842 | batch: [  204/  512]\n",
      "    loss: -5.819448 | batch: [  255/  512]\n",
      "    loss: -4.843685 | batch: [  306/  512]\n",
      "    loss: -5.586910 | batch: [  357/  512]\n",
      "    loss: -5.880406 | batch: [  408/  512]\n",
      "    loss: -5.875353 | batch: [  459/  512]\n",
      "    loss: -6.137632 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.539249\n",
      "    train_loss = -4.506602\n",
      "    val_loss = -4.528544\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 26 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.614753 | batch: [   51/  512]\n",
      "    loss: -5.854830 | batch: [  102/  512]\n",
      "    loss: -5.668791 | batch: [  153/  512]\n",
      "    loss: -5.594580 | batch: [  204/  512]\n",
      "    loss: -5.748597 | batch: [  255/  512]\n",
      "    loss: -5.344157 | batch: [  306/  512]\n",
      "    loss: -5.934710 | batch: [  357/  512]\n",
      "    loss: -5.925763 | batch: [  408/  512]\n",
      "    loss: -5.547134 | batch: [  459/  512]\n",
      "    loss: -5.853969 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.539249\n",
      "    train_loss = -4.528631\n",
      "    val_loss = -4.540687\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 27 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.283210 | batch: [   51/  512]\n",
      "    loss: -5.853106 | batch: [  102/  512]\n",
      "    loss: -5.092409 | batch: [  153/  512]\n",
      "    loss: -5.964796 | batch: [  204/  512]\n",
      "    loss: -5.561193 | batch: [  255/  512]\n",
      "    loss: -5.250988 | batch: [  306/  512]\n",
      "    loss: -5.927428 | batch: [  357/  512]\n",
      "    loss: -5.233777 | batch: [  408/  512]\n",
      "    loss: -6.000214 | batch: [  459/  512]\n",
      "    loss: -5.995368 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.540687\n",
      "    train_loss = -4.253397\n",
      "    val_loss = -4.298388\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 28 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.751214 | batch: [   51/  512]\n",
      "    loss: -5.830255 | batch: [  102/  512]\n",
      "    loss: -5.863713 | batch: [  153/  512]\n",
      "    loss: -5.621002 | batch: [  204/  512]\n",
      "    loss: -5.797358 | batch: [  255/  512]\n",
      "    loss: -6.037169 | batch: [  306/  512]\n",
      "    loss: -6.043087 | batch: [  357/  512]\n",
      "    loss: -6.188878 | batch: [  408/  512]\n",
      "    loss: -5.654146 | batch: [  459/  512]\n",
      "    loss: -5.470320 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.540687\n",
      "    train_loss = -4.338530\n",
      "    val_loss = -4.364709\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 29 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.888823 | batch: [   51/  512]\n",
      "    loss: -4.941629 | batch: [  102/  512]\n",
      "    loss: -5.445901 | batch: [  153/  512]\n",
      "    loss: -4.849581 | batch: [  204/  512]\n",
      "    loss: -5.789815 | batch: [  255/  512]\n",
      "    loss: -5.783998 | batch: [  306/  512]\n",
      "    loss: -5.957202 | batch: [  357/  512]\n",
      "    loss: -5.338211 | batch: [  408/  512]\n",
      "    loss: -5.854554 | batch: [  459/  512]\n",
      "    loss: -5.581970 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.540687\n",
      "    train_loss = -4.411664\n",
      "    val_loss = -4.431238\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 30 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.912838 | batch: [   51/  512]\n",
      "    loss: -5.561065 | batch: [  102/  512]\n",
      "    loss: -6.074893 | batch: [  153/  512]\n",
      "    loss: -3.899648 | batch: [  204/  512]\n",
      "    loss: -5.912358 | batch: [  255/  512]\n",
      "    loss: -5.603352 | batch: [  306/  512]\n",
      "    loss: -5.992843 | batch: [  357/  512]\n",
      "    loss: -6.069608 | batch: [  408/  512]\n",
      "    loss: -6.010619 | batch: [  459/  512]\n",
      "    loss: -5.684289 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.540687\n",
      "    train_loss = -4.572471\n",
      "    val_loss = -4.591785\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 31 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.598560 | batch: [   51/  512]\n",
      "    loss: -4.509789 | batch: [  102/  512]\n",
      "    loss: -5.985635 | batch: [  153/  512]\n",
      "    loss: -6.242221 | batch: [  204/  512]\n",
      "    loss: -5.892955 | batch: [  255/  512]\n",
      "    loss: -5.457306 | batch: [  306/  512]\n",
      "    loss: -5.889214 | batch: [  357/  512]\n",
      "    loss: -5.563127 | batch: [  408/  512]\n",
      "    loss: -5.813417 | batch: [  459/  512]\n",
      "    loss: -5.904421 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.591785\n",
      "    train_loss = -4.580960\n",
      "    val_loss = -4.602245\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 32 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.227367 | batch: [   51/  512]\n",
      "    loss: -5.869885 | batch: [  102/  512]\n",
      "    loss: -5.684162 | batch: [  153/  512]\n",
      "    loss: -5.426220 | batch: [  204/  512]\n",
      "    loss: -5.897885 | batch: [  255/  512]\n",
      "    loss: -6.049489 | batch: [  306/  512]\n",
      "    loss: -5.508380 | batch: [  357/  512]\n",
      "    loss: -6.022321 | batch: [  408/  512]\n",
      "    loss: -5.624957 | batch: [  459/  512]\n",
      "    loss: -5.684353 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.602245\n",
      "    train_loss = -4.550181\n",
      "    val_loss = -4.552211\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 33 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.979922 | batch: [   51/  512]\n",
      "    loss: -5.891452 | batch: [  102/  512]\n",
      "    loss: -5.593337 | batch: [  153/  512]\n",
      "    loss: -5.679022 | batch: [  204/  512]\n",
      "    loss: -5.930731 | batch: [  255/  512]\n",
      "    loss: -5.267076 | batch: [  306/  512]\n",
      "    loss: -5.565646 | batch: [  357/  512]\n",
      "    loss: -5.690353 | batch: [  408/  512]\n",
      "    loss: -5.903780 | batch: [  459/  512]\n",
      "    loss: -5.187805 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.602245\n",
      "    train_loss = -4.538876\n",
      "    val_loss = -4.566290\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 34 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.893371 | batch: [   51/  512]\n",
      "    loss: -6.000482 | batch: [  102/  512]\n",
      "    loss: -5.500095 | batch: [  153/  512]\n",
      "    loss: -5.501028 | batch: [  204/  512]\n",
      "    loss: -6.054816 | batch: [  255/  512]\n",
      "    loss: -5.781434 | batch: [  306/  512]\n",
      "    loss: -5.806011 | batch: [  357/  512]\n",
      "    loss: -6.039603 | batch: [  408/  512]\n",
      "    loss: -5.813547 | batch: [  459/  512]\n",
      "    loss: -5.936809 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.602245\n",
      "    train_loss = -4.334474\n",
      "    val_loss = -4.337138\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 35 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.244689 | batch: [   51/  512]\n",
      "    loss: -5.996771 | batch: [  102/  512]\n",
      "    loss: -5.269865 | batch: [  153/  512]\n",
      "    loss: -6.332939 | batch: [  204/  512]\n",
      "    loss: -5.420916 | batch: [  255/  512]\n",
      "    loss: -5.887488 | batch: [  306/  512]\n",
      "    loss: -5.545994 | batch: [  357/  512]\n",
      "    loss: -5.998025 | batch: [  408/  512]\n",
      "    loss: -6.002300 | batch: [  459/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -5.534927 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.602245\n",
      "    train_loss = -4.069298\n",
      "    val_loss = -4.098924\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 36 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.846939 | batch: [   51/  512]\n",
      "    loss: -5.966373 | batch: [  102/  512]\n",
      "    loss: -5.844221 | batch: [  153/  512]\n",
      "    loss: -5.955079 | batch: [  204/  512]\n",
      "    loss: -6.203860 | batch: [  255/  512]\n",
      "    loss: -4.765318 | batch: [  306/  512]\n",
      "    loss: -5.991358 | batch: [  357/  512]\n",
      "    loss: -5.651978 | batch: [  408/  512]\n",
      "    loss: -5.536371 | batch: [  459/  512]\n",
      "    loss: -5.697960 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.602245\n",
      "    train_loss = -4.207687\n",
      "    val_loss = -4.232721\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 37 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.281924 | batch: [   51/  512]\n",
      "    loss: -6.203639 | batch: [  102/  512]\n",
      "    loss: -6.084952 | batch: [  153/  512]\n",
      "    loss: -5.358357 | batch: [  204/  512]\n",
      "    loss: -5.969290 | batch: [  255/  512]\n",
      "    loss: -5.320824 | batch: [  306/  512]\n",
      "    loss: -6.137403 | batch: [  357/  512]\n",
      "    loss: -4.958180 | batch: [  408/  512]\n",
      "    loss: -5.388839 | batch: [  459/  512]\n",
      "    loss: -6.033765 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.602245\n",
      "    train_loss = -4.410304\n",
      "    val_loss = -4.445886\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 38 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.904762 | batch: [   51/  512]\n",
      "    loss: -6.229692 | batch: [  102/  512]\n",
      "    loss: -5.662285 | batch: [  153/  512]\n",
      "    loss: -5.547403 | batch: [  204/  512]\n",
      "    loss: -5.600958 | batch: [  255/  512]\n",
      "    loss: -6.366251 | batch: [  306/  512]\n",
      "    loss: -5.907894 | batch: [  357/  512]\n",
      "    loss: -6.181181 | batch: [  408/  512]\n",
      "    loss: -5.664490 | batch: [  459/  512]\n",
      "    loss: -5.931461 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.602245\n",
      "    train_loss = -4.450448\n",
      "    val_loss = -4.487452\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 39 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.879459 | batch: [   51/  512]\n",
      "    loss: -6.229521 | batch: [  102/  512]\n",
      "    loss: -5.551860 | batch: [  153/  512]\n",
      "    loss: -5.645428 | batch: [  204/  512]\n",
      "    loss: -6.173820 | batch: [  255/  512]\n",
      "    loss: -6.094576 | batch: [  306/  512]\n",
      "    loss: -5.958314 | batch: [  357/  512]\n",
      "    loss: -4.243339 | batch: [  408/  512]\n",
      "    loss: -6.064806 | batch: [  459/  512]\n",
      "    loss: -5.954360 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.602245\n",
      "    train_loss = -3.972449\n",
      "    val_loss = -4.013084\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 40 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.272255 | batch: [   51/  512]\n",
      "    loss: -5.635217 | batch: [  102/  512]\n",
      "    loss: -6.093428 | batch: [  153/  512]\n",
      "    loss: -6.272829 | batch: [  204/  512]\n",
      "    loss: -6.097906 | batch: [  255/  512]\n",
      "    loss: -6.101335 | batch: [  306/  512]\n",
      "    loss: -5.424757 | batch: [  357/  512]\n",
      "    loss: -5.795397 | batch: [  408/  512]\n",
      "    loss: -6.180950 | batch: [  459/  512]\n",
      "    loss: -6.019819 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.602245\n",
      "    train_loss = -4.621395\n",
      "    val_loss = -4.661015\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 41 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.187769 | batch: [   51/  512]\n",
      "    loss: -5.629755 | batch: [  102/  512]\n",
      "    loss: -5.638772 | batch: [  153/  512]\n",
      "    loss: -6.175146 | batch: [  204/  512]\n",
      "    loss: -4.824184 | batch: [  255/  512]\n",
      "    loss: -5.924866 | batch: [  306/  512]\n",
      "    loss: -4.673110 | batch: [  357/  512]\n",
      "    loss: -5.995891 | batch: [  408/  512]\n",
      "    loss: -5.908638 | batch: [  459/  512]\n",
      "    loss: -6.019056 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.661015\n",
      "    train_loss = -4.169904\n",
      "    val_loss = -4.254102\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 42 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.461726 | batch: [   51/  512]\n",
      "    loss: -5.841802 | batch: [  102/  512]\n",
      "    loss: -5.259237 | batch: [  153/  512]\n",
      "    loss: -5.088226 | batch: [  204/  512]\n",
      "    loss: -4.680515 | batch: [  255/  512]\n",
      "    loss: -5.904721 | batch: [  306/  512]\n",
      "    loss: -5.881918 | batch: [  357/  512]\n",
      "    loss: -6.223018 | batch: [  408/  512]\n",
      "    loss: -5.020209 | batch: [  459/  512]\n",
      "    loss: -6.308423 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.661015\n",
      "    train_loss = -4.675056\n",
      "    val_loss = -4.667608\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 43 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -3.574722 | batch: [   51/  512]\n",
      "    loss: -6.103404 | batch: [  102/  512]\n",
      "    loss: -5.512930 | batch: [  153/  512]\n",
      "    loss: -6.120619 | batch: [  204/  512]\n",
      "    loss: -6.036849 | batch: [  255/  512]\n",
      "    loss: -6.402845 | batch: [  306/  512]\n",
      "    loss: -6.081749 | batch: [  357/  512]\n",
      "    loss: -5.747542 | batch: [  408/  512]\n",
      "    loss: -6.037609 | batch: [  459/  512]\n",
      "    loss: -5.640989 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.667608\n",
      "    train_loss = -4.553985\n",
      "    val_loss = -4.616597\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 44 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.060026 | batch: [   51/  512]\n",
      "    loss: -6.262939 | batch: [  102/  512]\n",
      "    loss: -6.167841 | batch: [  153/  512]\n",
      "    loss: -5.300502 | batch: [  204/  512]\n",
      "    loss: -6.169827 | batch: [  255/  512]\n",
      "    loss: -6.159090 | batch: [  306/  512]\n",
      "    loss: -5.905879 | batch: [  357/  512]\n",
      "    loss: -6.107187 | batch: [  408/  512]\n",
      "    loss: -5.875667 | batch: [  459/  512]\n",
      "    loss: -5.901140 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.667608\n",
      "    train_loss = -4.467284\n",
      "    val_loss = -4.467481\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 45 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.795669 | batch: [   51/  512]\n",
      "    loss: -6.364663 | batch: [  102/  512]\n",
      "    loss: -5.650529 | batch: [  153/  512]\n",
      "    loss: -5.581215 | batch: [  204/  512]\n",
      "    loss: -6.225790 | batch: [  255/  512]\n",
      "    loss: -6.145281 | batch: [  306/  512]\n",
      "    loss: -6.202444 | batch: [  357/  512]\n",
      "    loss: -6.208078 | batch: [  408/  512]\n",
      "    loss: -6.168865 | batch: [  459/  512]\n",
      "    loss: -6.202915 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.667608\n",
      "    train_loss = -4.566688\n",
      "    val_loss = -4.642490\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 46 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.866351 | batch: [   51/  512]\n",
      "    loss: -6.151859 | batch: [  102/  512]\n",
      "    loss: -6.140044 | batch: [  153/  512]\n",
      "    loss: -6.125899 | batch: [  204/  512]\n",
      "    loss: -4.550182 | batch: [  255/  512]\n",
      "    loss: -5.760202 | batch: [  306/  512]\n",
      "    loss: -6.141568 | batch: [  357/  512]\n",
      "    loss: -5.957756 | batch: [  408/  512]\n",
      "    loss: -6.111228 | batch: [  459/  512]\n",
      "    loss: -5.702614 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.667608\n",
      "    train_loss = -4.683415\n",
      "    val_loss = -4.734155\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 47 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.858220 | batch: [   51/  512]\n",
      "    loss: -5.912049 | batch: [  102/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -6.239192 | batch: [  153/  512]\n",
      "    loss: -5.738147 | batch: [  204/  512]\n",
      "    loss: -6.029275 | batch: [  255/  512]\n",
      "    loss: -6.160415 | batch: [  306/  512]\n",
      "    loss: -6.091905 | batch: [  357/  512]\n",
      "    loss: -6.060820 | batch: [  408/  512]\n",
      "    loss: -6.393503 | batch: [  459/  512]\n",
      "    loss: -5.890885 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.734155\n",
      "    train_loss = -4.381253\n",
      "    val_loss = -4.418183\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 48 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.372592 | batch: [   51/  512]\n",
      "    loss: -6.401167 | batch: [  102/  512]\n",
      "    loss: -6.349112 | batch: [  153/  512]\n",
      "    loss: -5.693511 | batch: [  204/  512]\n",
      "    loss: -5.240678 | batch: [  255/  512]\n",
      "    loss: -6.197882 | batch: [  306/  512]\n",
      "    loss: -6.110823 | batch: [  357/  512]\n",
      "    loss: -5.940961 | batch: [  408/  512]\n",
      "    loss: -6.175728 | batch: [  459/  512]\n",
      "    loss: -5.569353 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.734155\n",
      "    train_loss = -4.761319\n",
      "    val_loss = -4.786580\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 49 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.929478 | batch: [   51/  512]\n",
      "    loss: -5.857468 | batch: [  102/  512]\n",
      "    loss: -6.350949 | batch: [  153/  512]\n",
      "    loss: -5.989952 | batch: [  204/  512]\n",
      "    loss: -6.380676 | batch: [  255/  512]\n",
      "    loss: -6.100391 | batch: [  306/  512]\n",
      "    loss: -5.757273 | batch: [  357/  512]\n",
      "    loss: -6.021150 | batch: [  408/  512]\n",
      "    loss: -6.067841 | batch: [  459/  512]\n",
      "    loss: -6.446809 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.786580\n",
      "    train_loss = -4.948724\n",
      "    val_loss = -4.975758\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 50 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.796416 | batch: [   51/  512]\n",
      "    loss: -5.782906 | batch: [  102/  512]\n",
      "    loss: -5.724594 | batch: [  153/  512]\n",
      "    loss: -6.077061 | batch: [  204/  512]\n",
      "    loss: -5.988069 | batch: [  255/  512]\n",
      "    loss: -5.883858 | batch: [  306/  512]\n",
      "    loss: -6.241035 | batch: [  357/  512]\n",
      "    loss: -6.188676 | batch: [  408/  512]\n",
      "    loss: -6.326865 | batch: [  459/  512]\n",
      "    loss: -6.307505 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.547143\n",
      "    val_loss = -4.544203\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 51 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.767773 | batch: [   51/  512]\n",
      "    loss: -5.779779 | batch: [  102/  512]\n",
      "    loss: -6.087377 | batch: [  153/  512]\n",
      "    loss: -6.253951 | batch: [  204/  512]\n",
      "    loss: -6.398675 | batch: [  255/  512]\n",
      "    loss: -5.856796 | batch: [  306/  512]\n",
      "    loss: -6.374590 | batch: [  357/  512]\n",
      "    loss: -6.236035 | batch: [  408/  512]\n",
      "    loss: -5.880587 | batch: [  459/  512]\n",
      "    loss: -6.274572 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.400175\n",
      "    val_loss = -4.423218\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 52 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.224179 | batch: [   51/  512]\n",
      "    loss: -6.339171 | batch: [  102/  512]\n",
      "    loss: -6.211551 | batch: [  153/  512]\n",
      "    loss: -5.650393 | batch: [  204/  512]\n",
      "    loss: -5.961873 | batch: [  255/  512]\n",
      "    loss: -5.831409 | batch: [  306/  512]\n",
      "    loss: -5.360386 | batch: [  357/  512]\n",
      "    loss: -6.554031 | batch: [  408/  512]\n",
      "    loss: -5.826234 | batch: [  459/  512]\n",
      "    loss: -6.443016 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.831797\n",
      "    val_loss = -4.862273\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 53 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.753028 | batch: [   51/  512]\n",
      "    loss: -5.946301 | batch: [  102/  512]\n",
      "    loss: -5.750352 | batch: [  153/  512]\n",
      "    loss: -5.692090 | batch: [  204/  512]\n",
      "    loss: -6.237517 | batch: [  255/  512]\n",
      "    loss: -4.722630 | batch: [  306/  512]\n",
      "    loss: -5.273371 | batch: [  357/  512]\n",
      "    loss: -6.209443 | batch: [  408/  512]\n",
      "    loss: -6.312919 | batch: [  459/  512]\n",
      "    loss: -6.191589 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.526750\n",
      "    val_loss = -4.588056\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 54 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.726853 | batch: [   51/  512]\n",
      "    loss: -5.036106 | batch: [  102/  512]\n",
      "    loss: -5.916694 | batch: [  153/  512]\n",
      "    loss: -6.371641 | batch: [  204/  512]\n",
      "    loss: -6.060915 | batch: [  255/  512]\n",
      "    loss: -5.609588 | batch: [  306/  512]\n",
      "    loss: -6.379468 | batch: [  357/  512]\n",
      "    loss: -5.326941 | batch: [  408/  512]\n",
      "    loss: -6.007584 | batch: [  459/  512]\n",
      "    loss: -6.182619 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.749256\n",
      "    val_loss = -4.769766\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 55 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.354312 | batch: [   51/  512]\n",
      "    loss: -6.254499 | batch: [  102/  512]\n",
      "    loss: -6.401708 | batch: [  153/  512]\n",
      "    loss: -6.249347 | batch: [  204/  512]\n",
      "    loss: -6.241895 | batch: [  255/  512]\n",
      "    loss: -6.366930 | batch: [  306/  512]\n",
      "    loss: -6.338619 | batch: [  357/  512]\n",
      "    loss: -6.022057 | batch: [  408/  512]\n",
      "    loss: -6.460726 | batch: [  459/  512]\n",
      "    loss: -6.261791 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.587500\n",
      "    val_loss = -4.649300\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 56 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.537470 | batch: [   51/  512]\n",
      "    loss: -6.179965 | batch: [  102/  512]\n",
      "    loss: -5.912762 | batch: [  153/  512]\n",
      "    loss: -6.243358 | batch: [  204/  512]\n",
      "    loss: -5.890072 | batch: [  255/  512]\n",
      "    loss: -3.995445 | batch: [  306/  512]\n",
      "    loss: -5.631654 | batch: [  357/  512]\n",
      "    loss: -6.408917 | batch: [  408/  512]\n",
      "    loss: -6.236110 | batch: [  459/  512]\n",
      "    loss: -6.182257 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.783418\n",
      "    val_loss = -4.814391\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 57 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.169302 | batch: [   51/  512]\n",
      "    loss: -6.277734 | batch: [  102/  512]\n",
      "    loss: -6.042425 | batch: [  153/  512]\n",
      "    loss: -5.588573 | batch: [  204/  512]\n",
      "    loss: -6.307636 | batch: [  255/  512]\n",
      "    loss: -6.220886 | batch: [  306/  512]\n",
      "    loss: -5.933106 | batch: [  357/  512]\n",
      "    loss: -3.464545 | batch: [  408/  512]\n",
      "    loss: -6.235255 | batch: [  459/  512]\n",
      "    loss: -5.998646 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.696932\n",
      "    val_loss = -4.755988\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 58 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.849249 | batch: [   51/  512]\n",
      "    loss: -5.679132 | batch: [  102/  512]\n",
      "    loss: -5.831505 | batch: [  153/  512]\n",
      "    loss: -5.915091 | batch: [  204/  512]\n",
      "    loss: -5.813262 | batch: [  255/  512]\n",
      "    loss: -6.246863 | batch: [  306/  512]\n",
      "    loss: -6.092854 | batch: [  357/  512]\n",
      "    loss: -4.818282 | batch: [  408/  512]\n",
      "    loss: -6.185069 | batch: [  459/  512]\n",
      "    loss: -5.903865 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.826497\n",
      "    val_loss = -4.855188\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 59 --------------\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -5.902802 | batch: [   51/  512]\n",
      "    loss: -6.408932 | batch: [  102/  512]\n",
      "    loss: -6.320158 | batch: [  153/  512]\n",
      "    loss: -6.262678 | batch: [  204/  512]\n",
      "    loss: -5.752558 | batch: [  255/  512]\n",
      "    loss: -6.277606 | batch: [  306/  512]\n",
      "    loss: -6.209911 | batch: [  357/  512]\n",
      "    loss: -5.890066 | batch: [  408/  512]\n",
      "    loss: -6.116877 | batch: [  459/  512]\n",
      "    loss: -6.264997 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.651229\n",
      "    val_loss = -4.698634\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 60 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.489390 | batch: [   51/  512]\n",
      "    loss: -6.350495 | batch: [  102/  512]\n",
      "    loss: -5.734837 | batch: [  153/  512]\n",
      "    loss: -6.244025 | batch: [  204/  512]\n",
      "    loss: -5.935490 | batch: [  255/  512]\n",
      "    loss: -6.085022 | batch: [  306/  512]\n",
      "    loss: -5.930786 | batch: [  357/  512]\n",
      "    loss: -6.279794 | batch: [  408/  512]\n",
      "    loss: -6.366552 | batch: [  459/  512]\n",
      "    loss: -6.113476 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.655492\n",
      "    val_loss = -4.707109\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 61 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.465855 | batch: [   51/  512]\n",
      "    loss: -6.413893 | batch: [  102/  512]\n",
      "    loss: -5.359671 | batch: [  153/  512]\n",
      "    loss: -6.316726 | batch: [  204/  512]\n",
      "    loss: -5.564728 | batch: [  255/  512]\n",
      "    loss: -6.004199 | batch: [  306/  512]\n",
      "    loss: -6.492639 | batch: [  357/  512]\n",
      "    loss: -5.871537 | batch: [  408/  512]\n",
      "    loss: -6.347700 | batch: [  459/  512]\n",
      "    loss: -6.160398 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.759959\n",
      "    val_loss = -4.806822\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 62 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.249671 | batch: [   51/  512]\n",
      "    loss: -6.022213 | batch: [  102/  512]\n",
      "    loss: -6.077688 | batch: [  153/  512]\n",
      "    loss: -6.098326 | batch: [  204/  512]\n",
      "    loss: -6.046854 | batch: [  255/  512]\n",
      "    loss: -6.085680 | batch: [  306/  512]\n",
      "    loss: -4.584257 | batch: [  357/  512]\n",
      "    loss: -6.049999 | batch: [  408/  512]\n",
      "    loss: -6.292701 | batch: [  459/  512]\n",
      "    loss: -6.215299 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.719746\n",
      "    val_loss = -4.757673\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 63 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -4.880710 | batch: [   51/  512]\n",
      "    loss: -5.684763 | batch: [  102/  512]\n",
      "    loss: -6.261949 | batch: [  153/  512]\n",
      "    loss: -6.302144 | batch: [  204/  512]\n",
      "    loss: -6.034500 | batch: [  255/  512]\n",
      "    loss: -6.050982 | batch: [  306/  512]\n",
      "    loss: -6.306003 | batch: [  357/  512]\n",
      "    loss: -5.922701 | batch: [  408/  512]\n",
      "    loss: -6.074288 | batch: [  459/  512]\n",
      "    loss: -5.640790 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.730955\n",
      "    val_loss = -4.758263\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 64 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -2.734734 | batch: [   51/  512]\n",
      "    loss: -6.255339 | batch: [  102/  512]\n",
      "    loss: -6.161861 | batch: [  153/  512]\n",
      "    loss: -6.312412 | batch: [  204/  512]\n",
      "    loss: -5.776509 | batch: [  255/  512]\n",
      "    loss: -6.330696 | batch: [  306/  512]\n",
      "    loss: -6.259505 | batch: [  357/  512]\n",
      "    loss: -6.421281 | batch: [  408/  512]\n",
      "    loss: -6.371223 | batch: [  459/  512]\n",
      "    loss: -6.011097 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.654212\n",
      "    val_loss = -4.748010\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 65 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.273104 | batch: [   51/  512]\n",
      "    loss: -5.767562 | batch: [  102/  512]\n",
      "    loss: -6.243467 | batch: [  153/  512]\n",
      "    loss: -6.466968 | batch: [  204/  512]\n",
      "    loss: -6.520706 | batch: [  255/  512]\n",
      "    loss: -6.386430 | batch: [  306/  512]\n",
      "    loss: -6.311818 | batch: [  357/  512]\n",
      "    loss: -6.313033 | batch: [  408/  512]\n",
      "    loss: -6.407175 | batch: [  459/  512]\n",
      "    loss: -6.370188 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.732120\n",
      "    val_loss = -4.793115\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 66 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.166259 | batch: [   51/  512]\n",
      "    loss: -5.957552 | batch: [  102/  512]\n",
      "    loss: -6.097718 | batch: [  153/  512]\n",
      "    loss: -5.836972 | batch: [  204/  512]\n",
      "    loss: -6.003025 | batch: [  255/  512]\n",
      "    loss: -6.235823 | batch: [  306/  512]\n",
      "    loss: -6.312063 | batch: [  357/  512]\n",
      "    loss: -6.157127 | batch: [  408/  512]\n",
      "    loss: -5.909483 | batch: [  459/  512]\n",
      "    loss: -5.716004 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.742192\n",
      "    val_loss = -4.806558\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 67 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.328291 | batch: [   51/  512]\n",
      "    loss: -6.200242 | batch: [  102/  512]\n",
      "    loss: -5.277151 | batch: [  153/  512]\n",
      "    loss: -6.510953 | batch: [  204/  512]\n",
      "    loss: -5.304980 | batch: [  255/  512]\n",
      "    loss: -5.941580 | batch: [  306/  512]\n",
      "    loss: -6.305809 | batch: [  357/  512]\n",
      "    loss: -5.806918 | batch: [  408/  512]\n",
      "    loss: -5.091368 | batch: [  459/  512]\n",
      "    loss: -6.089387 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.757639\n",
      "    val_loss = -4.814812\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 68 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.299191 | batch: [   51/  512]\n",
      "    loss: -6.686699 | batch: [  102/  512]\n",
      "    loss: -6.188367 | batch: [  153/  512]\n",
      "    loss: -6.506080 | batch: [  204/  512]\n",
      "    loss: -6.157708 | batch: [  255/  512]\n",
      "    loss: -6.156074 | batch: [  306/  512]\n",
      "    loss: -5.856822 | batch: [  357/  512]\n",
      "    loss: -6.344660 | batch: [  408/  512]\n",
      "    loss: -6.077886 | batch: [  459/  512]\n",
      "    loss: -6.483390 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.736578\n",
      "    val_loss = -4.785824\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 69 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.663157 | batch: [   51/  512]\n",
      "    loss: -6.447022 | batch: [  102/  512]\n",
      "    loss: -6.035642 | batch: [  153/  512]\n",
      "    loss: -6.443699 | batch: [  204/  512]\n",
      "    loss: -6.366979 | batch: [  255/  512]\n",
      "    loss: -6.204822 | batch: [  306/  512]\n",
      "    loss: -6.003360 | batch: [  357/  512]\n",
      "    loss: -6.317049 | batch: [  408/  512]\n",
      "    loss: -6.341439 | batch: [  459/  512]\n",
      "    loss: -6.192163 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.885392\n",
      "    val_loss = -4.925735\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 70 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.390423 | batch: [   51/  512]\n",
      "    loss: -6.048485 | batch: [  102/  512]\n",
      "    loss: -5.830456 | batch: [  153/  512]\n",
      "    loss: -6.201316 | batch: [  204/  512]\n",
      "    loss: -5.631100 | batch: [  255/  512]\n",
      "    loss: -6.195534 | batch: [  306/  512]\n",
      "    loss: -6.593818 | batch: [  357/  512]\n",
      "    loss: -5.869728 | batch: [  408/  512]\n",
      "    loss: -6.143526 | batch: [  459/  512]\n",
      "    loss: -5.842912 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -3.490166\n",
      "    val_loss = -3.539486\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 71 --------------\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -6.218424 | batch: [   51/  512]\n",
      "    loss: -6.302715 | batch: [  102/  512]\n",
      "    loss: -6.601858 | batch: [  153/  512]\n",
      "    loss: -5.995083 | batch: [  204/  512]\n",
      "    loss: -6.406240 | batch: [  255/  512]\n",
      "    loss: -6.633264 | batch: [  306/  512]\n",
      "    loss: -0.566597 | batch: [  357/  512]\n",
      "    loss: -6.565361 | batch: [  408/  512]\n",
      "    loss: -6.218556 | batch: [  459/  512]\n",
      "    loss: -6.460733 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.810670\n",
      "    val_loss = -4.855930\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 72 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.899351 | batch: [   51/  512]\n",
      "    loss: -6.311093 | batch: [  102/  512]\n",
      "    loss: -6.208270 | batch: [  153/  512]\n",
      "    loss: -6.412996 | batch: [  204/  512]\n",
      "    loss: -6.074377 | batch: [  255/  512]\n",
      "    loss: -5.469705 | batch: [  306/  512]\n",
      "    loss: -6.615843 | batch: [  357/  512]\n",
      "    loss: -6.554422 | batch: [  408/  512]\n",
      "    loss: -6.037656 | batch: [  459/  512]\n",
      "    loss: -6.372893 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.663989\n",
      "    val_loss = -4.718860\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 73 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.405602 | batch: [   51/  512]\n",
      "    loss: -6.537752 | batch: [  102/  512]\n",
      "    loss: -6.423011 | batch: [  153/  512]\n",
      "    loss: -6.149258 | batch: [  204/  512]\n",
      "    loss: -6.576824 | batch: [  255/  512]\n",
      "    loss: -6.187570 | batch: [  306/  512]\n",
      "    loss: -4.581175 | batch: [  357/  512]\n",
      "    loss: -4.794045 | batch: [  408/  512]\n",
      "    loss: -6.197587 | batch: [  459/  512]\n",
      "    loss: -6.396663 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.808507\n",
      "    val_loss = -4.852292\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 74 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.583218 | batch: [   51/  512]\n",
      "    loss: -5.263358 | batch: [  102/  512]\n",
      "    loss: -6.228992 | batch: [  153/  512]\n",
      "    loss: -6.242772 | batch: [  204/  512]\n",
      "    loss: -6.513858 | batch: [  255/  512]\n",
      "    loss: -6.062515 | batch: [  306/  512]\n",
      "    loss: -5.524895 | batch: [  357/  512]\n",
      "    loss: -5.602000 | batch: [  408/  512]\n",
      "    loss: -6.482354 | batch: [  459/  512]\n",
      "    loss: -6.413060 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.523721\n",
      "    val_loss = -4.652808\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 75 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.590731 | batch: [   51/  512]\n",
      "    loss: -6.533627 | batch: [  102/  512]\n",
      "    loss: -5.727208 | batch: [  153/  512]\n",
      "    loss: -6.160509 | batch: [  204/  512]\n",
      "    loss: -5.529255 | batch: [  255/  512]\n",
      "    loss: -6.442869 | batch: [  306/  512]\n",
      "    loss: -4.949994 | batch: [  357/  512]\n",
      "    loss: -6.260653 | batch: [  408/  512]\n",
      "    loss: -6.462341 | batch: [  459/  512]\n",
      "    loss: -5.836812 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.438252\n",
      "    val_loss = -4.568957\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 76 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.663204 | batch: [   51/  512]\n",
      "    loss: -6.225117 | batch: [  102/  512]\n",
      "    loss: -5.861363 | batch: [  153/  512]\n",
      "    loss: -5.921144 | batch: [  204/  512]\n",
      "    loss: -4.353529 | batch: [  255/  512]\n",
      "    loss: -4.911751 | batch: [  306/  512]\n",
      "    loss: -6.319637 | batch: [  357/  512]\n",
      "    loss: -6.321846 | batch: [  408/  512]\n",
      "    loss: -6.095134 | batch: [  459/  512]\n",
      "    loss: -6.392994 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.756824\n",
      "    val_loss = -4.780683\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 77 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.360991 | batch: [   51/  512]\n",
      "    loss: -5.739752 | batch: [  102/  512]\n",
      "    loss: -6.327988 | batch: [  153/  512]\n",
      "    loss: -6.500956 | batch: [  204/  512]\n",
      "    loss: -6.268261 | batch: [  255/  512]\n",
      "    loss: -5.816039 | batch: [  306/  512]\n",
      "    loss: -6.074471 | batch: [  357/  512]\n",
      "    loss: -5.979033 | batch: [  408/  512]\n",
      "    loss: -6.317867 | batch: [  459/  512]\n",
      "    loss: -5.751111 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.487791\n",
      "    val_loss = -4.599513\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 78 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.115123 | batch: [   51/  512]\n",
      "    loss: -1.907453 | batch: [  102/  512]\n",
      "    loss: -6.291180 | batch: [  153/  512]\n",
      "    loss: -6.680444 | batch: [  204/  512]\n",
      "    loss: -6.244319 | batch: [  255/  512]\n",
      "    loss: -6.346652 | batch: [  306/  512]\n",
      "    loss: -6.268391 | batch: [  357/  512]\n",
      "    loss: -6.458991 | batch: [  408/  512]\n",
      "    loss: -6.609820 | batch: [  459/  512]\n",
      "    loss: -6.177964 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.857008\n",
      "    val_loss = -4.878765\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 79 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.524028 | batch: [   51/  512]\n",
      "    loss: -6.236118 | batch: [  102/  512]\n",
      "    loss: -6.284633 | batch: [  153/  512]\n",
      "    loss: -6.215959 | batch: [  204/  512]\n",
      "    loss: -6.507484 | batch: [  255/  512]\n",
      "    loss: -6.251315 | batch: [  306/  512]\n",
      "    loss: -5.985927 | batch: [  357/  512]\n",
      "    loss: -6.518034 | batch: [  408/  512]\n",
      "    loss: -6.141192 | batch: [  459/  512]\n",
      "    loss: -6.095181 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.339506\n",
      "    val_loss = -4.463756\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 80 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.203656 | batch: [   51/  512]\n",
      "    loss: -6.285910 | batch: [  102/  512]\n",
      "    loss: -6.433023 | batch: [  153/  512]\n",
      "    loss: -5.640104 | batch: [  204/  512]\n",
      "    loss: -6.449747 | batch: [  255/  512]\n",
      "    loss: -6.450987 | batch: [  306/  512]\n",
      "    loss: -6.384193 | batch: [  357/  512]\n",
      "    loss: -6.025126 | batch: [  408/  512]\n",
      "    loss: -6.241449 | batch: [  459/  512]\n",
      "    loss: -6.500851 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -4.848453\n",
      "    val_loss = -4.917161\n",
      "Epoch 00080: reducing learning rate of group 0 to 9.0000e-05.\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 81 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.894337 | batch: [   51/  512]\n",
      "    loss: -7.136798 | batch: [  102/  512]\n",
      "    loss: -6.961614 | batch: [  153/  512]\n",
      "    loss: -7.131173 | batch: [  204/  512]\n",
      "    loss: -7.173428 | batch: [  255/  512]\n",
      "    loss: -7.064985 | batch: [  306/  512]\n",
      "    loss: -6.648465 | batch: [  357/  512]\n",
      "    loss: -7.376595 | batch: [  408/  512]\n",
      "    loss: -7.240826 | batch: [  459/  512]\n",
      "    loss: -7.274775 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -4.975758\n",
      "    train_loss = -5.556161\n",
      "    val_loss = -5.573289\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 82 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.057847 | batch: [   51/  512]\n",
      "    loss: -7.266407 | batch: [  102/  512]\n",
      "    loss: -7.372183 | batch: [  153/  512]\n",
      "    loss: -7.372071 | batch: [  204/  512]\n",
      "    loss: -6.963833 | batch: [  255/  512]\n",
      "    loss: -6.870580 | batch: [  306/  512]\n",
      "    loss: -7.049173 | batch: [  357/  512]\n",
      "    loss: -7.156758 | batch: [  408/  512]\n",
      "    loss: -6.917222 | batch: [  459/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -7.122024 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.573289\n",
      "    train_loss = -5.454550\n",
      "    val_loss = -5.502869\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 83 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.295056 | batch: [   51/  512]\n",
      "    loss: -7.079473 | batch: [  102/  512]\n",
      "    loss: -7.384223 | batch: [  153/  512]\n",
      "    loss: -6.991357 | batch: [  204/  512]\n",
      "    loss: -7.406097 | batch: [  255/  512]\n",
      "    loss: -7.499026 | batch: [  306/  512]\n",
      "    loss: -6.156689 | batch: [  357/  512]\n",
      "    loss: -7.229862 | batch: [  408/  512]\n",
      "    loss: -7.075991 | batch: [  459/  512]\n",
      "    loss: -7.242593 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.573289\n",
      "    train_loss = -5.645707\n",
      "    val_loss = -5.690906\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 84 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.882294 | batch: [   51/  512]\n",
      "    loss: -6.896725 | batch: [  102/  512]\n",
      "    loss: -7.345004 | batch: [  153/  512]\n",
      "    loss: -7.111699 | batch: [  204/  512]\n",
      "    loss: -7.066438 | batch: [  255/  512]\n",
      "    loss: -7.352293 | batch: [  306/  512]\n",
      "    loss: -7.233099 | batch: [  357/  512]\n",
      "    loss: -6.939666 | batch: [  408/  512]\n",
      "    loss: -6.881420 | batch: [  459/  512]\n",
      "    loss: -7.402920 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.690906\n",
      "    train_loss = -5.680789\n",
      "    val_loss = -5.694693\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 85 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.415664 | batch: [   51/  512]\n",
      "    loss: -6.915973 | batch: [  102/  512]\n",
      "    loss: -6.907169 | batch: [  153/  512]\n",
      "    loss: -6.914392 | batch: [  204/  512]\n",
      "    loss: -7.316214 | batch: [  255/  512]\n",
      "    loss: -7.267621 | batch: [  306/  512]\n",
      "    loss: -7.259046 | batch: [  357/  512]\n",
      "    loss: -6.913477 | batch: [  408/  512]\n",
      "    loss: -7.377767 | batch: [  459/  512]\n",
      "    loss: -7.438029 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.694693\n",
      "    train_loss = -5.607036\n",
      "    val_loss = -5.663915\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 86 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.264461 | batch: [   51/  512]\n",
      "    loss: -7.347737 | batch: [  102/  512]\n",
      "    loss: -6.924473 | batch: [  153/  512]\n",
      "    loss: -6.945263 | batch: [  204/  512]\n",
      "    loss: -7.258296 | batch: [  255/  512]\n",
      "    loss: -7.279432 | batch: [  306/  512]\n",
      "    loss: -7.437085 | batch: [  357/  512]\n",
      "    loss: -7.119956 | batch: [  408/  512]\n",
      "    loss: -7.118060 | batch: [  459/  512]\n",
      "    loss: -7.255155 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.694693\n",
      "    train_loss = -5.664128\n",
      "    val_loss = -5.704175\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 87 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.451256 | batch: [   51/  512]\n",
      "    loss: -7.386208 | batch: [  102/  512]\n",
      "    loss: -6.927511 | batch: [  153/  512]\n",
      "    loss: -7.296996 | batch: [  204/  512]\n",
      "    loss: -6.939533 | batch: [  255/  512]\n",
      "    loss: -6.438784 | batch: [  306/  512]\n",
      "    loss: -7.258512 | batch: [  357/  512]\n",
      "    loss: -7.154446 | batch: [  408/  512]\n",
      "    loss: -7.358221 | batch: [  459/  512]\n",
      "    loss: -6.723672 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.704175\n",
      "    train_loss = -5.660671\n",
      "    val_loss = -5.665726\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 88 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.816835 | batch: [   51/  512]\n",
      "    loss: -7.343909 | batch: [  102/  512]\n",
      "    loss: -6.907955 | batch: [  153/  512]\n",
      "    loss: -7.462257 | batch: [  204/  512]\n",
      "    loss: -7.526269 | batch: [  255/  512]\n",
      "    loss: -7.499398 | batch: [  306/  512]\n",
      "    loss: -6.390110 | batch: [  357/  512]\n",
      "    loss: -6.824104 | batch: [  408/  512]\n",
      "    loss: -7.365126 | batch: [  459/  512]\n",
      "    loss: -7.104346 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.704175\n",
      "    train_loss = -5.584958\n",
      "    val_loss = -5.652982\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 89 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.263321 | batch: [   51/  512]\n",
      "    loss: -7.036409 | batch: [  102/  512]\n",
      "    loss: -7.464354 | batch: [  153/  512]\n",
      "    loss: -7.311876 | batch: [  204/  512]\n",
      "    loss: -6.641550 | batch: [  255/  512]\n",
      "    loss: -6.668411 | batch: [  306/  512]\n",
      "    loss: -7.277642 | batch: [  357/  512]\n",
      "    loss: -7.203992 | batch: [  408/  512]\n",
      "    loss: -7.223408 | batch: [  459/  512]\n",
      "    loss: -7.342162 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.704175\n",
      "    train_loss = -5.608477\n",
      "    val_loss = -5.653579\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 90 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.196108 | batch: [   51/  512]\n",
      "    loss: -7.327919 | batch: [  102/  512]\n",
      "    loss: -7.218233 | batch: [  153/  512]\n",
      "    loss: -7.098037 | batch: [  204/  512]\n",
      "    loss: -6.803686 | batch: [  255/  512]\n",
      "    loss: -6.970640 | batch: [  306/  512]\n",
      "    loss: -7.473240 | batch: [  357/  512]\n",
      "    loss: -6.831121 | batch: [  408/  512]\n",
      "    loss: -6.931663 | batch: [  459/  512]\n",
      "    loss: -6.466554 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.704175\n",
      "    train_loss = -5.586594\n",
      "    val_loss = -5.649746\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 91 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.087157 | batch: [   51/  512]\n",
      "    loss: -6.831789 | batch: [  102/  512]\n",
      "    loss: -7.300444 | batch: [  153/  512]\n",
      "    loss: -7.238208 | batch: [  204/  512]\n",
      "    loss: -5.992958 | batch: [  255/  512]\n",
      "    loss: -7.364491 | batch: [  306/  512]\n",
      "    loss: -6.882445 | batch: [  357/  512]\n",
      "    loss: -7.327532 | batch: [  408/  512]\n",
      "    loss: -7.063643 | batch: [  459/  512]\n",
      "    loss: -7.367751 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.704175\n",
      "    train_loss = -5.663325\n",
      "    val_loss = -5.696558\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 92 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.777056 | batch: [   51/  512]\n",
      "    loss: -7.102617 | batch: [  102/  512]\n",
      "    loss: -7.308400 | batch: [  153/  512]\n",
      "    loss: -7.494152 | batch: [  204/  512]\n",
      "    loss: -7.193806 | batch: [  255/  512]\n",
      "    loss: -7.577008 | batch: [  306/  512]\n",
      "    loss: -6.883911 | batch: [  357/  512]\n",
      "    loss: -6.983019 | batch: [  408/  512]\n",
      "    loss: -7.493202 | batch: [  459/  512]\n",
      "    loss: -7.401057 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.704175\n",
      "    train_loss = -5.644999\n",
      "    val_loss = -5.693686\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 93 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.997171 | batch: [   51/  512]\n",
      "    loss: -7.366986 | batch: [  102/  512]\n",
      "    loss: -7.269550 | batch: [  153/  512]\n",
      "    loss: -7.004017 | batch: [  204/  512]\n",
      "    loss: -7.164483 | batch: [  255/  512]\n",
      "    loss: -7.193426 | batch: [  306/  512]\n",
      "    loss: -7.348576 | batch: [  357/  512]\n",
      "    loss: -7.255729 | batch: [  408/  512]\n",
      "    loss: -7.102594 | batch: [  459/  512]\n",
      "    loss: -7.397414 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.704175\n",
      "    train_loss = -5.684364\n",
      "    val_loss = -5.718364\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 94 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.307555 | batch: [   51/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -6.872731 | batch: [  102/  512]\n",
      "    loss: -7.165403 | batch: [  153/  512]\n",
      "    loss: -6.548615 | batch: [  204/  512]\n",
      "    loss: -7.180737 | batch: [  255/  512]\n",
      "    loss: -6.332785 | batch: [  306/  512]\n",
      "    loss: -7.165358 | batch: [  357/  512]\n",
      "    loss: -6.939654 | batch: [  408/  512]\n",
      "    loss: -7.302522 | batch: [  459/  512]\n",
      "    loss: -7.067487 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.718364\n",
      "    train_loss = -5.577691\n",
      "    val_loss = -5.601168\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 95 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.140385 | batch: [   51/  512]\n",
      "    loss: -7.391013 | batch: [  102/  512]\n",
      "    loss: -6.924284 | batch: [  153/  512]\n",
      "    loss: -7.424596 | batch: [  204/  512]\n",
      "    loss: -6.634940 | batch: [  255/  512]\n",
      "    loss: -7.349339 | batch: [  306/  512]\n",
      "    loss: -7.103536 | batch: [  357/  512]\n",
      "    loss: -7.551865 | batch: [  408/  512]\n",
      "    loss: -7.252927 | batch: [  459/  512]\n",
      "    loss: -7.279620 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.718364\n",
      "    train_loss = -5.692408\n",
      "    val_loss = -5.718474\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 96 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.116409 | batch: [   51/  512]\n",
      "    loss: -7.284118 | batch: [  102/  512]\n",
      "    loss: -7.418375 | batch: [  153/  512]\n",
      "    loss: -7.319593 | batch: [  204/  512]\n",
      "    loss: -7.141037 | batch: [  255/  512]\n",
      "    loss: -7.217531 | batch: [  306/  512]\n",
      "    loss: -7.375505 | batch: [  357/  512]\n",
      "    loss: -6.856462 | batch: [  408/  512]\n",
      "    loss: -7.214008 | batch: [  459/  512]\n",
      "    loss: -7.301342 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.718474\n",
      "    train_loss = -5.561687\n",
      "    val_loss = -5.609911\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 97 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.358106 | batch: [   51/  512]\n",
      "    loss: -7.415082 | batch: [  102/  512]\n",
      "    loss: -7.028609 | batch: [  153/  512]\n",
      "    loss: -7.224452 | batch: [  204/  512]\n",
      "    loss: -7.337598 | batch: [  255/  512]\n",
      "    loss: -6.952651 | batch: [  306/  512]\n",
      "    loss: -5.618880 | batch: [  357/  512]\n",
      "    loss: -7.290872 | batch: [  408/  512]\n",
      "    loss: -7.195748 | batch: [  459/  512]\n",
      "    loss: -7.344270 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.718474\n",
      "    train_loss = -5.307349\n",
      "    val_loss = -5.385771\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 98 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.827929 | batch: [   51/  512]\n",
      "    loss: -7.200120 | batch: [  102/  512]\n",
      "    loss: -7.289654 | batch: [  153/  512]\n",
      "    loss: -6.757489 | batch: [  204/  512]\n",
      "    loss: -7.248128 | batch: [  255/  512]\n",
      "    loss: -7.187970 | batch: [  306/  512]\n",
      "    loss: -7.227785 | batch: [  357/  512]\n",
      "    loss: -7.184818 | batch: [  408/  512]\n",
      "    loss: -7.067698 | batch: [  459/  512]\n",
      "    loss: -7.308652 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.718474\n",
      "    train_loss = -5.519190\n",
      "    val_loss = -5.600994\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 99 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.140222 | batch: [   51/  512]\n",
      "    loss: -7.187471 | batch: [  102/  512]\n",
      "    loss: -7.087214 | batch: [  153/  512]\n",
      "    loss: -7.064253 | batch: [  204/  512]\n",
      "    loss: -5.768075 | batch: [  255/  512]\n",
      "    loss: -7.498911 | batch: [  306/  512]\n",
      "    loss: -7.320071 | batch: [  357/  512]\n",
      "    loss: -6.617257 | batch: [  408/  512]\n",
      "    loss: -7.251240 | batch: [  459/  512]\n",
      "    loss: -6.789903 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.718474\n",
      "    train_loss = -5.608502\n",
      "    val_loss = -5.650697\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 100 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -4.180132 | batch: [   51/  512]\n",
      "    loss: -7.012506 | batch: [  102/  512]\n",
      "    loss: -7.443547 | batch: [  153/  512]\n",
      "    loss: -7.227348 | batch: [  204/  512]\n",
      "    loss: -7.593793 | batch: [  255/  512]\n",
      "    loss: -7.373010 | batch: [  306/  512]\n",
      "    loss: -7.357742 | batch: [  357/  512]\n",
      "    loss: -7.262088 | batch: [  408/  512]\n",
      "    loss: -6.892179 | batch: [  459/  512]\n",
      "    loss: -7.118783 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.718474\n",
      "    train_loss = -5.535281\n",
      "    val_loss = -5.603910\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 101 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.926632 | batch: [   51/  512]\n",
      "    loss: -7.316350 | batch: [  102/  512]\n",
      "    loss: -7.130182 | batch: [  153/  512]\n",
      "    loss: -7.396237 | batch: [  204/  512]\n",
      "    loss: -6.464337 | batch: [  255/  512]\n",
      "    loss: -6.686450 | batch: [  306/  512]\n",
      "    loss: -6.657823 | batch: [  357/  512]\n",
      "    loss: -7.339000 | batch: [  408/  512]\n",
      "    loss: -7.353940 | batch: [  459/  512]\n",
      "    loss: -6.517325 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.718474\n",
      "    train_loss = -5.596393\n",
      "    val_loss = -5.643690\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 102 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.758446 | batch: [   51/  512]\n",
      "    loss: -7.159130 | batch: [  102/  512]\n",
      "    loss: -7.585938 | batch: [  153/  512]\n",
      "    loss: -7.192797 | batch: [  204/  512]\n",
      "    loss: -7.495382 | batch: [  255/  512]\n",
      "    loss: -7.221283 | batch: [  306/  512]\n",
      "    loss: -7.278011 | batch: [  357/  512]\n",
      "    loss: -6.617756 | batch: [  408/  512]\n",
      "    loss: -7.138734 | batch: [  459/  512]\n",
      "    loss: -7.312401 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.718474\n",
      "    train_loss = -5.581115\n",
      "    val_loss = -5.593303\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 103 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.888148 | batch: [   51/  512]\n",
      "    loss: -7.006611 | batch: [  102/  512]\n",
      "    loss: -7.339496 | batch: [  153/  512]\n",
      "    loss: -7.354747 | batch: [  204/  512]\n",
      "    loss: -6.160445 | batch: [  255/  512]\n",
      "    loss: -7.005200 | batch: [  306/  512]\n",
      "    loss: -7.022712 | batch: [  357/  512]\n",
      "    loss: -6.520231 | batch: [  408/  512]\n",
      "    loss: -7.352369 | batch: [  459/  512]\n",
      "    loss: -7.446165 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.718474\n",
      "    train_loss = -5.679075\n",
      "    val_loss = -5.726475\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 104 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.003646 | batch: [   51/  512]\n",
      "    loss: -6.807913 | batch: [  102/  512]\n",
      "    loss: -7.223798 | batch: [  153/  512]\n",
      "    loss: -7.256366 | batch: [  204/  512]\n",
      "    loss: -7.062726 | batch: [  255/  512]\n",
      "    loss: -7.072540 | batch: [  306/  512]\n",
      "    loss: -6.627278 | batch: [  357/  512]\n",
      "    loss: -7.099340 | batch: [  408/  512]\n",
      "    loss: -7.120816 | batch: [  459/  512]\n",
      "    loss: -7.107913 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.726475\n",
      "    train_loss = -5.691732\n",
      "    val_loss = -5.716331\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 105 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.651147 | batch: [   51/  512]\n",
      "    loss: -7.206960 | batch: [  102/  512]\n",
      "    loss: -6.953906 | batch: [  153/  512]\n",
      "    loss: -7.220207 | batch: [  204/  512]\n",
      "    loss: -7.044289 | batch: [  255/  512]\n",
      "    loss: -7.277645 | batch: [  306/  512]\n",
      "    loss: -6.912561 | batch: [  357/  512]\n",
      "    loss: -7.091148 | batch: [  408/  512]\n",
      "    loss: -6.664209 | batch: [  459/  512]\n",
      "    loss: -7.294398 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.726475\n",
      "    train_loss = -5.613120\n",
      "    val_loss = -5.645624\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 106 --------------\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -7.360490 | batch: [   51/  512]\n",
      "    loss: -7.251745 | batch: [  102/  512]\n",
      "    loss: -6.405213 | batch: [  153/  512]\n",
      "    loss: -7.190364 | batch: [  204/  512]\n",
      "    loss: -7.140028 | batch: [  255/  512]\n",
      "    loss: -7.214341 | batch: [  306/  512]\n",
      "    loss: -7.431173 | batch: [  357/  512]\n",
      "    loss: -7.207049 | batch: [  408/  512]\n",
      "    loss: -7.129806 | batch: [  459/  512]\n",
      "    loss: -7.284741 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.726475\n",
      "    train_loss = -5.657335\n",
      "    val_loss = -5.657824\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 107 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.591157 | batch: [   51/  512]\n",
      "    loss: -7.374373 | batch: [  102/  512]\n",
      "    loss: -7.366626 | batch: [  153/  512]\n",
      "    loss: -7.267690 | batch: [  204/  512]\n",
      "    loss: -7.415888 | batch: [  255/  512]\n",
      "    loss: -7.193730 | batch: [  306/  512]\n",
      "    loss: -5.684330 | batch: [  357/  512]\n",
      "    loss: -7.081918 | batch: [  408/  512]\n",
      "    loss: -6.409637 | batch: [  459/  512]\n",
      "    loss: -7.364921 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.726475\n",
      "    train_loss = -5.463409\n",
      "    val_loss = -5.506109\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 108 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.012726 | batch: [   51/  512]\n",
      "    loss: -7.466350 | batch: [  102/  512]\n",
      "    loss: -7.460664 | batch: [  153/  512]\n",
      "    loss: -7.248250 | batch: [  204/  512]\n",
      "    loss: -7.450308 | batch: [  255/  512]\n",
      "    loss: -7.437161 | batch: [  306/  512]\n",
      "    loss: -7.322034 | batch: [  357/  512]\n",
      "    loss: -6.967065 | batch: [  408/  512]\n",
      "    loss: -6.934293 | batch: [  459/  512]\n",
      "    loss: -7.321209 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.726475\n",
      "    train_loss = -5.656868\n",
      "    val_loss = -5.708226\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 109 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.105331 | batch: [   51/  512]\n",
      "    loss: -7.559374 | batch: [  102/  512]\n",
      "    loss: -7.274758 | batch: [  153/  512]\n",
      "    loss: -7.321088 | batch: [  204/  512]\n",
      "    loss: -6.784965 | batch: [  255/  512]\n",
      "    loss: -6.841658 | batch: [  306/  512]\n",
      "    loss: -7.517293 | batch: [  357/  512]\n",
      "    loss: -7.247356 | batch: [  408/  512]\n",
      "    loss: -6.932805 | batch: [  459/  512]\n",
      "    loss: -7.019679 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.726475\n",
      "    train_loss = -5.261899\n",
      "    val_loss = -5.406862\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 110 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.264814 | batch: [   51/  512]\n",
      "    loss: -7.118664 | batch: [  102/  512]\n",
      "    loss: -7.346859 | batch: [  153/  512]\n",
      "    loss: -7.138169 | batch: [  204/  512]\n",
      "    loss: -6.993242 | batch: [  255/  512]\n",
      "    loss: -7.406903 | batch: [  306/  512]\n",
      "    loss: -7.380842 | batch: [  357/  512]\n",
      "    loss: -7.355322 | batch: [  408/  512]\n",
      "    loss: -6.759961 | batch: [  459/  512]\n",
      "    loss: -7.355175 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.726475\n",
      "    train_loss = -5.730386\n",
      "    val_loss = -5.752833\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 111 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.369713 | batch: [   51/  512]\n",
      "    loss: -6.555841 | batch: [  102/  512]\n",
      "    loss: -5.650315 | batch: [  153/  512]\n",
      "    loss: -7.271140 | batch: [  204/  512]\n",
      "    loss: -7.527486 | batch: [  255/  512]\n",
      "    loss: -7.502022 | batch: [  306/  512]\n",
      "    loss: -6.946917 | batch: [  357/  512]\n",
      "    loss: -7.222774 | batch: [  408/  512]\n",
      "    loss: -7.300880 | batch: [  459/  512]\n",
      "    loss: -7.233490 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.752833\n",
      "    train_loss = -5.708067\n",
      "    val_loss = -5.769741\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 112 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.773037 | batch: [   51/  512]\n",
      "    loss: -7.494752 | batch: [  102/  512]\n",
      "    loss: -7.514592 | batch: [  153/  512]\n",
      "    loss: -7.421599 | batch: [  204/  512]\n",
      "    loss: -7.280345 | batch: [  255/  512]\n",
      "    loss: -6.789729 | batch: [  306/  512]\n",
      "    loss: -7.368416 | batch: [  357/  512]\n",
      "    loss: -7.595720 | batch: [  408/  512]\n",
      "    loss: -6.129926 | batch: [  459/  512]\n",
      "    loss: -7.407390 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.769741\n",
      "    train_loss = -5.630466\n",
      "    val_loss = -5.660038\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 113 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -5.913202 | batch: [   51/  512]\n",
      "    loss: -7.311379 | batch: [  102/  512]\n",
      "    loss: -7.187507 | batch: [  153/  512]\n",
      "    loss: -7.238594 | batch: [  204/  512]\n",
      "    loss: -7.355020 | batch: [  255/  512]\n",
      "    loss: -7.240741 | batch: [  306/  512]\n",
      "    loss: -7.502762 | batch: [  357/  512]\n",
      "    loss: -7.141986 | batch: [  408/  512]\n",
      "    loss: -6.771333 | batch: [  459/  512]\n",
      "    loss: -7.389895 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.769741\n",
      "    train_loss = -5.622772\n",
      "    val_loss = -5.682315\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 114 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.417971 | batch: [   51/  512]\n",
      "    loss: -6.827106 | batch: [  102/  512]\n",
      "    loss: -7.568766 | batch: [  153/  512]\n",
      "    loss: -6.051431 | batch: [  204/  512]\n",
      "    loss: -7.578115 | batch: [  255/  512]\n",
      "    loss: -7.473228 | batch: [  306/  512]\n",
      "    loss: -7.190708 | batch: [  357/  512]\n",
      "    loss: -6.851628 | batch: [  408/  512]\n",
      "    loss: -7.408856 | batch: [  459/  512]\n",
      "    loss: -7.090517 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.769741\n",
      "    train_loss = -5.505620\n",
      "    val_loss = -5.528600\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 115 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.386959 | batch: [   51/  512]\n",
      "    loss: -7.140761 | batch: [  102/  512]\n",
      "    loss: -7.251023 | batch: [  153/  512]\n",
      "    loss: -7.451945 | batch: [  204/  512]\n",
      "    loss: -7.292417 | batch: [  255/  512]\n",
      "    loss: -7.457712 | batch: [  306/  512]\n",
      "    loss: -7.301810 | batch: [  357/  512]\n",
      "    loss: -7.529841 | batch: [  408/  512]\n",
      "    loss: -7.262773 | batch: [  459/  512]\n",
      "    loss: -7.355586 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.769741\n",
      "    train_loss = -5.736830\n",
      "    val_loss = -5.772868\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 116 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.263937 | batch: [   51/  512]\n",
      "    loss: -7.146584 | batch: [  102/  512]\n",
      "    loss: -7.214067 | batch: [  153/  512]\n",
      "    loss: -7.332803 | batch: [  204/  512]\n",
      "    loss: -7.465793 | batch: [  255/  512]\n",
      "    loss: -7.479757 | batch: [  306/  512]\n",
      "    loss: -7.475647 | batch: [  357/  512]\n",
      "    loss: -7.392479 | batch: [  408/  512]\n",
      "    loss: -7.595685 | batch: [  459/  512]\n",
      "    loss: -6.373257 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.772868\n",
      "    train_loss = -5.628514\n",
      "    val_loss = -5.662571\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 117 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.979267 | batch: [   51/  512]\n",
      "    loss: -7.405435 | batch: [  102/  512]\n",
      "    loss: -6.542017 | batch: [  153/  512]\n",
      "    loss: -7.339260 | batch: [  204/  512]\n",
      "    loss: -6.916670 | batch: [  255/  512]\n",
      "    loss: -7.000154 | batch: [  306/  512]\n",
      "    loss: -7.474424 | batch: [  357/  512]\n",
      "    loss: -6.308016 | batch: [  408/  512]\n",
      "    loss: -6.570059 | batch: [  459/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -6.727283 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.772868\n",
      "    train_loss = -5.685458\n",
      "    val_loss = -5.722627\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 118 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.297291 | batch: [   51/  512]\n",
      "    loss: -7.055093 | batch: [  102/  512]\n",
      "    loss: -7.629074 | batch: [  153/  512]\n",
      "    loss: -6.986439 | batch: [  204/  512]\n",
      "    loss: -6.885523 | batch: [  255/  512]\n",
      "    loss: -5.839513 | batch: [  306/  512]\n",
      "    loss: -7.123058 | batch: [  357/  512]\n",
      "    loss: -7.188250 | batch: [  408/  512]\n",
      "    loss: -7.261816 | batch: [  459/  512]\n",
      "    loss: -7.402281 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.772868\n",
      "    train_loss = -5.476001\n",
      "    val_loss = -5.540733\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 119 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.355355 | batch: [   51/  512]\n",
      "    loss: -4.800256 | batch: [  102/  512]\n",
      "    loss: -7.166225 | batch: [  153/  512]\n",
      "    loss: -5.595571 | batch: [  204/  512]\n",
      "    loss: -7.008265 | batch: [  255/  512]\n",
      "    loss: -7.350010 | batch: [  306/  512]\n",
      "    loss: -7.491746 | batch: [  357/  512]\n",
      "    loss: -7.188989 | batch: [  408/  512]\n",
      "    loss: -6.850588 | batch: [  459/  512]\n",
      "    loss: -7.198211 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.772868\n",
      "    train_loss = -5.435390\n",
      "    val_loss = -5.468096\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 120 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.631667 | batch: [   51/  512]\n",
      "    loss: -7.343761 | batch: [  102/  512]\n",
      "    loss: -7.316716 | batch: [  153/  512]\n",
      "    loss: -7.537137 | batch: [  204/  512]\n",
      "    loss: -7.394335 | batch: [  255/  512]\n",
      "    loss: -7.423328 | batch: [  306/  512]\n",
      "    loss: -7.199627 | batch: [  357/  512]\n",
      "    loss: -6.772084 | batch: [  408/  512]\n",
      "    loss: -6.844392 | batch: [  459/  512]\n",
      "    loss: -7.729661 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.772868\n",
      "    train_loss = -5.781620\n",
      "    val_loss = -5.831366\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 121 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.411072 | batch: [   51/  512]\n",
      "    loss: -7.598281 | batch: [  102/  512]\n",
      "    loss: -6.799866 | batch: [  153/  512]\n",
      "    loss: -7.110524 | batch: [  204/  512]\n",
      "    loss: -6.431456 | batch: [  255/  512]\n",
      "    loss: -7.509531 | batch: [  306/  512]\n",
      "    loss: -7.331474 | batch: [  357/  512]\n",
      "    loss: -7.228219 | batch: [  408/  512]\n",
      "    loss: -7.322673 | batch: [  459/  512]\n",
      "    loss: -6.922414 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.673432\n",
      "    val_loss = -5.677578\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 122 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.313508 | batch: [   51/  512]\n",
      "    loss: -7.172741 | batch: [  102/  512]\n",
      "    loss: -7.421528 | batch: [  153/  512]\n",
      "    loss: -7.137236 | batch: [  204/  512]\n",
      "    loss: -7.369289 | batch: [  255/  512]\n",
      "    loss: -7.008632 | batch: [  306/  512]\n",
      "    loss: -7.118870 | batch: [  357/  512]\n",
      "    loss: -6.547361 | batch: [  408/  512]\n",
      "    loss: -6.745090 | batch: [  459/  512]\n",
      "    loss: -6.845321 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.698028\n",
      "    val_loss = -5.733859\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 123 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.302752 | batch: [   51/  512]\n",
      "    loss: -7.063143 | batch: [  102/  512]\n",
      "    loss: -7.207685 | batch: [  153/  512]\n",
      "    loss: -7.341477 | batch: [  204/  512]\n",
      "    loss: -7.245397 | batch: [  255/  512]\n",
      "    loss: -6.061952 | batch: [  306/  512]\n",
      "    loss: -7.418151 | batch: [  357/  512]\n",
      "    loss: -6.420946 | batch: [  408/  512]\n",
      "    loss: -7.124298 | batch: [  459/  512]\n",
      "    loss: -6.215556 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.601308\n",
      "    val_loss = -5.635932\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 124 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.326497 | batch: [   51/  512]\n",
      "    loss: -7.589539 | batch: [  102/  512]\n",
      "    loss: -7.341602 | batch: [  153/  512]\n",
      "    loss: -7.605410 | batch: [  204/  512]\n",
      "    loss: -7.461685 | batch: [  255/  512]\n",
      "    loss: -7.574302 | batch: [  306/  512]\n",
      "    loss: -7.319890 | batch: [  357/  512]\n",
      "    loss: -7.096808 | batch: [  408/  512]\n",
      "    loss: -6.483318 | batch: [  459/  512]\n",
      "    loss: -6.998344 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.687186\n",
      "    val_loss = -5.713188\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 125 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.402679 | batch: [   51/  512]\n",
      "    loss: -7.275656 | batch: [  102/  512]\n",
      "    loss: -7.125926 | batch: [  153/  512]\n",
      "    loss: -7.342577 | batch: [  204/  512]\n",
      "    loss: -7.099691 | batch: [  255/  512]\n",
      "    loss: -7.429902 | batch: [  306/  512]\n",
      "    loss: -6.854938 | batch: [  357/  512]\n",
      "    loss: -7.087512 | batch: [  408/  512]\n",
      "    loss: -6.882477 | batch: [  459/  512]\n",
      "    loss: -7.531600 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.590081\n",
      "    val_loss = -5.658717\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 126 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.339540 | batch: [   51/  512]\n",
      "    loss: -7.216668 | batch: [  102/  512]\n",
      "    loss: -7.393247 | batch: [  153/  512]\n",
      "    loss: -7.244358 | batch: [  204/  512]\n",
      "    loss: -7.329357 | batch: [  255/  512]\n",
      "    loss: -7.631999 | batch: [  306/  512]\n",
      "    loss: -7.630119 | batch: [  357/  512]\n",
      "    loss: -7.378535 | batch: [  408/  512]\n",
      "    loss: -7.312068 | batch: [  459/  512]\n",
      "    loss: -7.479963 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.567313\n",
      "    val_loss = -5.576125\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 127 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.257341 | batch: [   51/  512]\n",
      "    loss: -6.818901 | batch: [  102/  512]\n",
      "    loss: -7.538314 | batch: [  153/  512]\n",
      "    loss: -6.161719 | batch: [  204/  512]\n",
      "    loss: -7.280347 | batch: [  255/  512]\n",
      "    loss: -7.030482 | batch: [  306/  512]\n",
      "    loss: -7.054056 | batch: [  357/  512]\n",
      "    loss: -7.514130 | batch: [  408/  512]\n",
      "    loss: -7.390049 | batch: [  459/  512]\n",
      "    loss: -7.212411 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.700559\n",
      "    val_loss = -5.726981\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 128 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.326844 | batch: [   51/  512]\n",
      "    loss: -6.084191 | batch: [  102/  512]\n",
      "    loss: -7.570578 | batch: [  153/  512]\n",
      "    loss: -7.275229 | batch: [  204/  512]\n",
      "    loss: -6.952320 | batch: [  255/  512]\n",
      "    loss: -7.101882 | batch: [  306/  512]\n",
      "    loss: -6.181711 | batch: [  357/  512]\n",
      "    loss: -6.771860 | batch: [  408/  512]\n",
      "    loss: -7.491581 | batch: [  459/  512]\n",
      "    loss: -7.691386 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.773328\n",
      "    val_loss = -5.792017\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 129 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.559122 | batch: [   51/  512]\n",
      "    loss: -7.397947 | batch: [  102/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -7.556017 | batch: [  153/  512]\n",
      "    loss: -6.671680 | batch: [  204/  512]\n",
      "    loss: -7.483581 | batch: [  255/  512]\n",
      "    loss: -7.467957 | batch: [  306/  512]\n",
      "    loss: -7.382363 | batch: [  357/  512]\n",
      "    loss: -7.519628 | batch: [  408/  512]\n",
      "    loss: -6.979352 | batch: [  459/  512]\n",
      "    loss: -7.397346 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.529054\n",
      "    val_loss = -5.586166\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 130 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.361099 | batch: [   51/  512]\n",
      "    loss: -7.740532 | batch: [  102/  512]\n",
      "    loss: -7.379939 | batch: [  153/  512]\n",
      "    loss: -7.502540 | batch: [  204/  512]\n",
      "    loss: -7.403681 | batch: [  255/  512]\n",
      "    loss: -7.005161 | batch: [  306/  512]\n",
      "    loss: -7.288563 | batch: [  357/  512]\n",
      "    loss: -7.469581 | batch: [  408/  512]\n",
      "    loss: -7.437748 | batch: [  459/  512]\n",
      "    loss: -7.403538 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.796128\n",
      "    val_loss = -5.824147\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 131 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.394397 | batch: [   51/  512]\n",
      "    loss: -6.531590 | batch: [  102/  512]\n",
      "    loss: -7.454586 | batch: [  153/  512]\n",
      "    loss: -7.069489 | batch: [  204/  512]\n",
      "    loss: -7.150521 | batch: [  255/  512]\n",
      "    loss: -7.652236 | batch: [  306/  512]\n",
      "    loss: -7.159457 | batch: [  357/  512]\n",
      "    loss: -7.118234 | batch: [  408/  512]\n",
      "    loss: -7.365434 | batch: [  459/  512]\n",
      "    loss: -7.602946 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.636486\n",
      "    val_loss = -5.722669\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 132 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.215018 | batch: [   51/  512]\n",
      "    loss: -6.476911 | batch: [  102/  512]\n",
      "    loss: -7.133921 | batch: [  153/  512]\n",
      "    loss: -7.289211 | batch: [  204/  512]\n",
      "    loss: -6.787288 | batch: [  255/  512]\n",
      "    loss: -7.620800 | batch: [  306/  512]\n",
      "    loss: -7.467397 | batch: [  357/  512]\n",
      "    loss: -7.201558 | batch: [  408/  512]\n",
      "    loss: -7.281381 | batch: [  459/  512]\n",
      "    loss: -7.528503 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.831366\n",
      "    train_loss = -5.828568\n",
      "    val_loss = -5.849357\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 133 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.690115 | batch: [   51/  512]\n",
      "    loss: -7.394963 | batch: [  102/  512]\n",
      "    loss: -6.837451 | batch: [  153/  512]\n",
      "    loss: -7.298848 | batch: [  204/  512]\n",
      "    loss: -7.033449 | batch: [  255/  512]\n",
      "    loss: -7.172657 | batch: [  306/  512]\n",
      "    loss: -7.725599 | batch: [  357/  512]\n",
      "    loss: -7.597670 | batch: [  408/  512]\n",
      "    loss: -7.140390 | batch: [  459/  512]\n",
      "    loss: -7.208140 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.849357\n",
      "    train_loss = -5.792713\n",
      "    val_loss = -5.829362\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 134 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.226613 | batch: [   51/  512]\n",
      "    loss: -7.322253 | batch: [  102/  512]\n",
      "    loss: -7.449284 | batch: [  153/  512]\n",
      "    loss: -7.389095 | batch: [  204/  512]\n",
      "    loss: -7.248220 | batch: [  255/  512]\n",
      "    loss: -7.204837 | batch: [  306/  512]\n",
      "    loss: -7.458640 | batch: [  357/  512]\n",
      "    loss: -7.558103 | batch: [  408/  512]\n",
      "    loss: -7.018670 | batch: [  459/  512]\n",
      "    loss: -7.248111 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.849357\n",
      "    train_loss = -5.615084\n",
      "    val_loss = -5.662052\n",
      "Epoch 00134: reducing learning rate of group 0 to 2.7000e-05.\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 135 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.649922 | batch: [   51/  512]\n",
      "    loss: -7.636026 | batch: [  102/  512]\n",
      "    loss: -7.652506 | batch: [  153/  512]\n",
      "    loss: -7.524125 | batch: [  204/  512]\n",
      "    loss: -7.892905 | batch: [  255/  512]\n",
      "    loss: -7.173675 | batch: [  306/  512]\n",
      "    loss: -7.849808 | batch: [  357/  512]\n",
      "    loss: -7.739185 | batch: [  408/  512]\n",
      "    loss: -7.334258 | batch: [  459/  512]\n",
      "    loss: -7.810910 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -5.849357\n",
      "    train_loss = -6.126932\n",
      "    val_loss = -6.141637\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 136 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.849153 | batch: [   51/  512]\n",
      "    loss: -7.664016 | batch: [  102/  512]\n",
      "    loss: -7.736726 | batch: [  153/  512]\n",
      "    loss: -7.671694 | batch: [  204/  512]\n",
      "    loss: -7.680832 | batch: [  255/  512]\n",
      "    loss: -7.200094 | batch: [  306/  512]\n",
      "    loss: -7.800599 | batch: [  357/  512]\n",
      "    loss: -6.186390 | batch: [  408/  512]\n",
      "    loss: -7.736111 | batch: [  459/  512]\n",
      "    loss: -7.635768 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.141637\n",
      "    train_loss = -6.056551\n",
      "    val_loss = -6.056888\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 137 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.351212 | batch: [   51/  512]\n",
      "    loss: -7.896261 | batch: [  102/  512]\n",
      "    loss: -7.359245 | batch: [  153/  512]\n",
      "    loss: -7.596632 | batch: [  204/  512]\n",
      "    loss: -7.685540 | batch: [  255/  512]\n",
      "    loss: -7.572822 | batch: [  306/  512]\n",
      "    loss: -6.741247 | batch: [  357/  512]\n",
      "    loss: -7.296036 | batch: [  408/  512]\n",
      "    loss: -7.707162 | batch: [  459/  512]\n",
      "    loss: -6.466403 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.141637\n",
      "    train_loss = -6.161160\n",
      "    val_loss = -6.169357\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 138 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.166772 | batch: [   51/  512]\n",
      "    loss: -8.034784 | batch: [  102/  512]\n",
      "    loss: -7.614584 | batch: [  153/  512]\n",
      "    loss: -7.898435 | batch: [  204/  512]\n",
      "    loss: -7.936152 | batch: [  255/  512]\n",
      "    loss: -7.788518 | batch: [  306/  512]\n",
      "    loss: -7.327362 | batch: [  357/  512]\n",
      "    loss: -7.880890 | batch: [  408/  512]\n",
      "    loss: -7.589348 | batch: [  459/  512]\n",
      "    loss: -7.473447 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.169357\n",
      "    train_loss = -6.106474\n",
      "    val_loss = -6.132891\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 139 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.003049 | batch: [   51/  512]\n",
      "    loss: -8.081815 | batch: [  102/  512]\n",
      "    loss: -7.420153 | batch: [  153/  512]\n",
      "    loss: -7.770191 | batch: [  204/  512]\n",
      "    loss: -7.780027 | batch: [  255/  512]\n",
      "    loss: -7.688043 | batch: [  306/  512]\n",
      "    loss: -8.115973 | batch: [  357/  512]\n",
      "    loss: -7.569426 | batch: [  408/  512]\n",
      "    loss: -7.846136 | batch: [  459/  512]\n",
      "    loss: -7.805276 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.169357\n",
      "    train_loss = -6.141823\n",
      "    val_loss = -6.150018\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 140 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.764952 | batch: [   51/  512]\n",
      "    loss: -7.452433 | batch: [  102/  512]\n",
      "    loss: -7.725582 | batch: [  153/  512]\n",
      "    loss: -7.174779 | batch: [  204/  512]\n",
      "    loss: -7.198218 | batch: [  255/  512]\n",
      "    loss: -7.911040 | batch: [  306/  512]\n",
      "    loss: -6.401033 | batch: [  357/  512]\n",
      "    loss: -7.933746 | batch: [  408/  512]\n",
      "    loss: -7.667373 | batch: [  459/  512]\n",
      "    loss: -7.675598 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.169357\n",
      "    train_loss = -6.165847\n",
      "    val_loss = -6.178704\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 141 --------------\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -7.950828 | batch: [   51/  512]\n",
      "    loss: -7.819292 | batch: [  102/  512]\n",
      "    loss: -7.668364 | batch: [  153/  512]\n",
      "    loss: -7.258999 | batch: [  204/  512]\n",
      "    loss: -7.974733 | batch: [  255/  512]\n",
      "    loss: -7.794412 | batch: [  306/  512]\n",
      "    loss: -8.024687 | batch: [  357/  512]\n",
      "    loss: -7.897491 | batch: [  408/  512]\n",
      "    loss: -7.949172 | batch: [  459/  512]\n",
      "    loss: -7.685496 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.178704\n",
      "    train_loss = -6.157624\n",
      "    val_loss = -6.180429\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 142 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.862417 | batch: [   51/  512]\n",
      "    loss: -7.678855 | batch: [  102/  512]\n",
      "    loss: -7.976369 | batch: [  153/  512]\n",
      "    loss: -7.512753 | batch: [  204/  512]\n",
      "    loss: -8.191288 | batch: [  255/  512]\n",
      "    loss: -7.857156 | batch: [  306/  512]\n",
      "    loss: -7.967625 | batch: [  357/  512]\n",
      "    loss: -7.662736 | batch: [  408/  512]\n",
      "    loss: -7.684350 | batch: [  459/  512]\n",
      "    loss: -7.865644 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.180429\n",
      "    train_loss = -6.227561\n",
      "    val_loss = -6.241665\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 143 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.973696 | batch: [   51/  512]\n",
      "    loss: -7.738807 | batch: [  102/  512]\n",
      "    loss: -7.906282 | batch: [  153/  512]\n",
      "    loss: -7.917604 | batch: [  204/  512]\n",
      "    loss: -7.477845 | batch: [  255/  512]\n",
      "    loss: -7.576255 | batch: [  306/  512]\n",
      "    loss: -7.918645 | batch: [  357/  512]\n",
      "    loss: -7.147463 | batch: [  408/  512]\n",
      "    loss: -7.109916 | batch: [  459/  512]\n",
      "    loss: -7.671372 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.155659\n",
      "    val_loss = -6.166528\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 144 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.819780 | batch: [   51/  512]\n",
      "    loss: -7.367955 | batch: [  102/  512]\n",
      "    loss: -7.970901 | batch: [  153/  512]\n",
      "    loss: -7.068816 | batch: [  204/  512]\n",
      "    loss: -5.980745 | batch: [  255/  512]\n",
      "    loss: -7.672234 | batch: [  306/  512]\n",
      "    loss: -7.734938 | batch: [  357/  512]\n",
      "    loss: -7.473023 | batch: [  408/  512]\n",
      "    loss: -7.773758 | batch: [  459/  512]\n",
      "    loss: -7.691672 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.170971\n",
      "    val_loss = -6.190235\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 145 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.979508 | batch: [   51/  512]\n",
      "    loss: -7.600935 | batch: [  102/  512]\n",
      "    loss: -7.799220 | batch: [  153/  512]\n",
      "    loss: -7.701635 | batch: [  204/  512]\n",
      "    loss: -7.673240 | batch: [  255/  512]\n",
      "    loss: -7.559829 | batch: [  306/  512]\n",
      "    loss: -7.488929 | batch: [  357/  512]\n",
      "    loss: -7.909295 | batch: [  408/  512]\n",
      "    loss: -7.853223 | batch: [  459/  512]\n",
      "    loss: -6.917073 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.054832\n",
      "    val_loss = -6.051648\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 146 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.081388 | batch: [   51/  512]\n",
      "    loss: -8.041441 | batch: [  102/  512]\n",
      "    loss: -7.909526 | batch: [  153/  512]\n",
      "    loss: -7.975142 | batch: [  204/  512]\n",
      "    loss: -7.673330 | batch: [  255/  512]\n",
      "    loss: -7.708029 | batch: [  306/  512]\n",
      "    loss: -7.724024 | batch: [  357/  512]\n",
      "    loss: -7.787657 | batch: [  408/  512]\n",
      "    loss: -7.832386 | batch: [  459/  512]\n",
      "    loss: -7.636142 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.192484\n",
      "    val_loss = -6.179576\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 147 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.027645 | batch: [   51/  512]\n",
      "    loss: -8.023624 | batch: [  102/  512]\n",
      "    loss: -7.974402 | batch: [  153/  512]\n",
      "    loss: -7.390081 | batch: [  204/  512]\n",
      "    loss: -8.021851 | batch: [  255/  512]\n",
      "    loss: -7.693257 | batch: [  306/  512]\n",
      "    loss: -7.316511 | batch: [  357/  512]\n",
      "    loss: -8.012144 | batch: [  408/  512]\n",
      "    loss: -7.482432 | batch: [  459/  512]\n",
      "    loss: -7.995850 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.144585\n",
      "    val_loss = -6.095622\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 148 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.050865 | batch: [   51/  512]\n",
      "    loss: -7.861586 | batch: [  102/  512]\n",
      "    loss: -7.875975 | batch: [  153/  512]\n",
      "    loss: -7.820134 | batch: [  204/  512]\n",
      "    loss: -7.824233 | batch: [  255/  512]\n",
      "    loss: -7.820311 | batch: [  306/  512]\n",
      "    loss: -7.948892 | batch: [  357/  512]\n",
      "    loss: -7.535084 | batch: [  408/  512]\n",
      "    loss: -7.589980 | batch: [  459/  512]\n",
      "    loss: -8.072603 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.139693\n",
      "    val_loss = -6.147798\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 149 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.879378 | batch: [   51/  512]\n",
      "    loss: -6.689330 | batch: [  102/  512]\n",
      "    loss: -7.419272 | batch: [  153/  512]\n",
      "    loss: -8.023704 | batch: [  204/  512]\n",
      "    loss: -4.565390 | batch: [  255/  512]\n",
      "    loss: -7.576800 | batch: [  306/  512]\n",
      "    loss: -6.970677 | batch: [  357/  512]\n",
      "    loss: -7.753019 | batch: [  408/  512]\n",
      "    loss: -7.681922 | batch: [  459/  512]\n",
      "    loss: -7.850583 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.197266\n",
      "    val_loss = -6.203135\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 150 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.158228 | batch: [   51/  512]\n",
      "    loss: -7.354023 | batch: [  102/  512]\n",
      "    loss: -7.986875 | batch: [  153/  512]\n",
      "    loss: -8.111292 | batch: [  204/  512]\n",
      "    loss: -7.882437 | batch: [  255/  512]\n",
      "    loss: -7.408163 | batch: [  306/  512]\n",
      "    loss: -8.140913 | batch: [  357/  512]\n",
      "    loss: -8.107171 | batch: [  408/  512]\n",
      "    loss: -7.787611 | batch: [  459/  512]\n",
      "    loss: -7.305823 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.156940\n",
      "    val_loss = -6.155687\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 151 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.695845 | batch: [   51/  512]\n",
      "    loss: -7.827294 | batch: [  102/  512]\n",
      "    loss: -7.392449 | batch: [  153/  512]\n",
      "    loss: -8.101962 | batch: [  204/  512]\n",
      "    loss: -8.036230 | batch: [  255/  512]\n",
      "    loss: -7.951120 | batch: [  306/  512]\n",
      "    loss: -7.974447 | batch: [  357/  512]\n",
      "    loss: -6.035408 | batch: [  408/  512]\n",
      "    loss: -7.563978 | batch: [  459/  512]\n",
      "    loss: -7.893707 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.194545\n",
      "    val_loss = -6.202720\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 152 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.467900 | batch: [   51/  512]\n",
      "    loss: -7.899000 | batch: [  102/  512]\n",
      "    loss: -7.276604 | batch: [  153/  512]\n",
      "    loss: -7.721651 | batch: [  204/  512]\n",
      "    loss: -7.315473 | batch: [  255/  512]\n",
      "    loss: -7.987556 | batch: [  306/  512]\n",
      "    loss: -8.002511 | batch: [  357/  512]\n",
      "    loss: -8.045075 | batch: [  408/  512]\n",
      "    loss: -8.037842 | batch: [  459/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -7.961364 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.124074\n",
      "    val_loss = -6.143923\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 153 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.580173 | batch: [   51/  512]\n",
      "    loss: -7.526957 | batch: [  102/  512]\n",
      "    loss: -7.888087 | batch: [  153/  512]\n",
      "    loss: -7.995820 | batch: [  204/  512]\n",
      "    loss: -7.983871 | batch: [  255/  512]\n",
      "    loss: -7.643869 | batch: [  306/  512]\n",
      "    loss: -7.883730 | batch: [  357/  512]\n",
      "    loss: -8.131671 | batch: [  408/  512]\n",
      "    loss: -8.007535 | batch: [  459/  512]\n",
      "    loss: -7.843156 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -5.665701\n",
      "    val_loss = -5.781461\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 154 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.865149 | batch: [   51/  512]\n",
      "    loss: -7.470745 | batch: [  102/  512]\n",
      "    loss: -7.236885 | batch: [  153/  512]\n",
      "    loss: -7.984813 | batch: [  204/  512]\n",
      "    loss: -7.708017 | batch: [  255/  512]\n",
      "    loss: -7.638115 | batch: [  306/  512]\n",
      "    loss: -7.574387 | batch: [  357/  512]\n",
      "    loss: -7.942672 | batch: [  408/  512]\n",
      "    loss: -7.153709 | batch: [  459/  512]\n",
      "    loss: -7.850804 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.194663\n",
      "    val_loss = -6.203019\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 155 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.642599 | batch: [   51/  512]\n",
      "    loss: -7.487302 | batch: [  102/  512]\n",
      "    loss: -8.030181 | batch: [  153/  512]\n",
      "    loss: -7.879165 | batch: [  204/  512]\n",
      "    loss: -7.510201 | batch: [  255/  512]\n",
      "    loss: -8.116696 | batch: [  306/  512]\n",
      "    loss: -7.679269 | batch: [  357/  512]\n",
      "    loss: -7.533876 | batch: [  408/  512]\n",
      "    loss: -7.956106 | batch: [  459/  512]\n",
      "    loss: -8.060141 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.174943\n",
      "    val_loss = -6.182364\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 156 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.537160 | batch: [   51/  512]\n",
      "    loss: -7.376999 | batch: [  102/  512]\n",
      "    loss: -7.938415 | batch: [  153/  512]\n",
      "    loss: -8.005575 | batch: [  204/  512]\n",
      "    loss: -7.716546 | batch: [  255/  512]\n",
      "    loss: -8.007811 | batch: [  306/  512]\n",
      "    loss: -7.983352 | batch: [  357/  512]\n",
      "    loss: -8.054177 | batch: [  408/  512]\n",
      "    loss: -7.925947 | batch: [  459/  512]\n",
      "    loss: -7.858191 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -5.995370\n",
      "    val_loss = -6.033016\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 157 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.067403 | batch: [   51/  512]\n",
      "    loss: -7.984975 | batch: [  102/  512]\n",
      "    loss: -7.673259 | batch: [  153/  512]\n",
      "    loss: -8.181519 | batch: [  204/  512]\n",
      "    loss: -7.771655 | batch: [  255/  512]\n",
      "    loss: -7.850553 | batch: [  306/  512]\n",
      "    loss: -7.544114 | batch: [  357/  512]\n",
      "    loss: -7.146795 | batch: [  408/  512]\n",
      "    loss: -7.437555 | batch: [  459/  512]\n",
      "    loss: -8.035253 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.112450\n",
      "    val_loss = -6.127144\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 158 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.548678 | batch: [   51/  512]\n",
      "    loss: -7.805520 | batch: [  102/  512]\n",
      "    loss: -6.817842 | batch: [  153/  512]\n",
      "    loss: -7.590874 | batch: [  204/  512]\n",
      "    loss: -7.329412 | batch: [  255/  512]\n",
      "    loss: -7.843520 | batch: [  306/  512]\n",
      "    loss: -7.169845 | batch: [  357/  512]\n",
      "    loss: -7.805697 | batch: [  408/  512]\n",
      "    loss: -8.095387 | batch: [  459/  512]\n",
      "    loss: -8.023863 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.226375\n",
      "    val_loss = -6.239059\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 159 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.420708 | batch: [   51/  512]\n",
      "    loss: -6.101367 | batch: [  102/  512]\n",
      "    loss: -7.563493 | batch: [  153/  512]\n",
      "    loss: -8.025864 | batch: [  204/  512]\n",
      "    loss: -7.828538 | batch: [  255/  512]\n",
      "    loss: -7.729128 | batch: [  306/  512]\n",
      "    loss: -7.989363 | batch: [  357/  512]\n",
      "    loss: -7.962187 | batch: [  408/  512]\n",
      "    loss: -7.825655 | batch: [  459/  512]\n",
      "    loss: -7.799283 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.043083\n",
      "    val_loss = -6.086098\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 160 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.964047 | batch: [   51/  512]\n",
      "    loss: -7.948453 | batch: [  102/  512]\n",
      "    loss: -7.958233 | batch: [  153/  512]\n",
      "    loss: -7.850270 | batch: [  204/  512]\n",
      "    loss: -8.016684 | batch: [  255/  512]\n",
      "    loss: -7.845482 | batch: [  306/  512]\n",
      "    loss: -7.568748 | batch: [  357/  512]\n",
      "    loss: -8.107872 | batch: [  408/  512]\n",
      "    loss: -7.729633 | batch: [  459/  512]\n",
      "    loss: -7.837133 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.182067\n",
      "    val_loss = -6.183057\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 161 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.375085 | batch: [   51/  512]\n",
      "    loss: -7.819850 | batch: [  102/  512]\n",
      "    loss: -7.375719 | batch: [  153/  512]\n",
      "    loss: -7.682200 | batch: [  204/  512]\n",
      "    loss: -7.327569 | batch: [  255/  512]\n",
      "    loss: -7.860980 | batch: [  306/  512]\n",
      "    loss: -7.196382 | batch: [  357/  512]\n",
      "    loss: -7.897471 | batch: [  408/  512]\n",
      "    loss: -7.924542 | batch: [  459/  512]\n",
      "    loss: -8.037188 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.204646\n",
      "    val_loss = -6.233562\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 162 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.022937 | batch: [   51/  512]\n",
      "    loss: -7.812819 | batch: [  102/  512]\n",
      "    loss: -8.130951 | batch: [  153/  512]\n",
      "    loss: -7.851206 | batch: [  204/  512]\n",
      "    loss: -7.780422 | batch: [  255/  512]\n",
      "    loss: -7.866806 | batch: [  306/  512]\n",
      "    loss: -7.733663 | batch: [  357/  512]\n",
      "    loss: -7.901284 | batch: [  408/  512]\n",
      "    loss: -7.867331 | batch: [  459/  512]\n",
      "    loss: -7.810301 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.186290\n",
      "    val_loss = -6.182803\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 163 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.948525 | batch: [   51/  512]\n",
      "    loss: -8.015755 | batch: [  102/  512]\n",
      "    loss: -7.797777 | batch: [  153/  512]\n",
      "    loss: -7.206084 | batch: [  204/  512]\n",
      "    loss: -8.060161 | batch: [  255/  512]\n",
      "    loss: -7.847806 | batch: [  306/  512]\n",
      "    loss: -7.917215 | batch: [  357/  512]\n",
      "    loss: -7.580985 | batch: [  408/  512]\n",
      "    loss: -7.925214 | batch: [  459/  512]\n",
      "    loss: -7.921682 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.232608\n",
      "    val_loss = -6.223698\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 164 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.037030 | batch: [   51/  512]\n",
      "    loss: -7.593302 | batch: [  102/  512]\n",
      "    loss: -7.935795 | batch: [  153/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -8.114121 | batch: [  204/  512]\n",
      "    loss: -7.871202 | batch: [  255/  512]\n",
      "    loss: -7.673698 | batch: [  306/  512]\n",
      "    loss: -7.197730 | batch: [  357/  512]\n",
      "    loss: -7.627371 | batch: [  408/  512]\n",
      "    loss: -7.925960 | batch: [  459/  512]\n",
      "    loss: -7.736012 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.241665\n",
      "    train_loss = -6.226775\n",
      "    val_loss = -6.243185\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 165 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.823284 | batch: [   51/  512]\n",
      "    loss: -7.545532 | batch: [  102/  512]\n",
      "    loss: -7.518198 | batch: [  153/  512]\n",
      "    loss: -5.475822 | batch: [  204/  512]\n",
      "    loss: -7.682193 | batch: [  255/  512]\n",
      "    loss: -8.205955 | batch: [  306/  512]\n",
      "    loss: -7.912940 | batch: [  357/  512]\n",
      "    loss: -8.064410 | batch: [  408/  512]\n",
      "    loss: -7.652007 | batch: [  459/  512]\n",
      "    loss: -7.231112 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.243185\n",
      "    train_loss = -6.185887\n",
      "    val_loss = -6.209406\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 166 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.032393 | batch: [   51/  512]\n",
      "    loss: -7.851270 | batch: [  102/  512]\n",
      "    loss: -7.541926 | batch: [  153/  512]\n",
      "    loss: -8.036067 | batch: [  204/  512]\n",
      "    loss: -7.900332 | batch: [  255/  512]\n",
      "    loss: -7.738075 | batch: [  306/  512]\n",
      "    loss: -7.521284 | batch: [  357/  512]\n",
      "    loss: -7.878779 | batch: [  408/  512]\n",
      "    loss: -7.726832 | batch: [  459/  512]\n",
      "    loss: -8.094291 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.243185\n",
      "    train_loss = -6.142199\n",
      "    val_loss = -6.177845\n",
      "Epoch 00166: reducing learning rate of group 0 to 8.1000e-06.\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 167 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.796061 | batch: [   51/  512]\n",
      "    loss: -8.089272 | batch: [  102/  512]\n",
      "    loss: -7.695265 | batch: [  153/  512]\n",
      "    loss: -7.933126 | batch: [  204/  512]\n",
      "    loss: -8.078507 | batch: [  255/  512]\n",
      "    loss: -7.955702 | batch: [  306/  512]\n",
      "    loss: -7.759455 | batch: [  357/  512]\n",
      "    loss: -8.078072 | batch: [  408/  512]\n",
      "    loss: -8.240551 | batch: [  459/  512]\n",
      "    loss: -7.937617 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.243185\n",
      "    train_loss = -6.285776\n",
      "    val_loss = -6.291528\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 168 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.019098 | batch: [   51/  512]\n",
      "    loss: -7.740290 | batch: [  102/  512]\n",
      "    loss: -7.702003 | batch: [  153/  512]\n",
      "    loss: -7.755017 | batch: [  204/  512]\n",
      "    loss: -8.194588 | batch: [  255/  512]\n",
      "    loss: -7.721566 | batch: [  306/  512]\n",
      "    loss: -7.694754 | batch: [  357/  512]\n",
      "    loss: -7.678819 | batch: [  408/  512]\n",
      "    loss: -7.908875 | batch: [  459/  512]\n",
      "    loss: -8.096271 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.291528\n",
      "    train_loss = -6.279274\n",
      "    val_loss = -6.282198\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 169 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.537432 | batch: [   51/  512]\n",
      "    loss: -7.613484 | batch: [  102/  512]\n",
      "    loss: -8.023125 | batch: [  153/  512]\n",
      "    loss: -6.890199 | batch: [  204/  512]\n",
      "    loss: -7.924104 | batch: [  255/  512]\n",
      "    loss: -7.620914 | batch: [  306/  512]\n",
      "    loss: -7.984090 | batch: [  357/  512]\n",
      "    loss: -7.824436 | batch: [  408/  512]\n",
      "    loss: -8.100736 | batch: [  459/  512]\n",
      "    loss: -7.850114 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.291528\n",
      "    train_loss = -6.307978\n",
      "    val_loss = -6.321692\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 170 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.182255 | batch: [   51/  512]\n",
      "    loss: -8.141094 | batch: [  102/  512]\n",
      "    loss: -8.135453 | batch: [  153/  512]\n",
      "    loss: -7.748544 | batch: [  204/  512]\n",
      "    loss: -7.791776 | batch: [  255/  512]\n",
      "    loss: -7.476810 | batch: [  306/  512]\n",
      "    loss: -8.144271 | batch: [  357/  512]\n",
      "    loss: -7.847479 | batch: [  408/  512]\n",
      "    loss: -7.162388 | batch: [  459/  512]\n",
      "    loss: -7.240692 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.321692\n",
      "    train_loss = -6.291706\n",
      "    val_loss = -6.263224\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 171 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.770723 | batch: [   51/  512]\n",
      "    loss: -7.817687 | batch: [  102/  512]\n",
      "    loss: -8.031620 | batch: [  153/  512]\n",
      "    loss: -8.194205 | batch: [  204/  512]\n",
      "    loss: -7.765265 | batch: [  255/  512]\n",
      "    loss: -7.894793 | batch: [  306/  512]\n",
      "    loss: -7.819615 | batch: [  357/  512]\n",
      "    loss: -7.502703 | batch: [  408/  512]\n",
      "    loss: -8.147071 | batch: [  459/  512]\n",
      "    loss: -7.967462 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.321692\n",
      "    train_loss = -6.285269\n",
      "    val_loss = -6.287208\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 172 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.954798 | batch: [   51/  512]\n",
      "    loss: -8.197186 | batch: [  102/  512]\n",
      "    loss: -7.992250 | batch: [  153/  512]\n",
      "    loss: -8.196955 | batch: [  204/  512]\n",
      "    loss: -8.104357 | batch: [  255/  512]\n",
      "    loss: -7.996482 | batch: [  306/  512]\n",
      "    loss: -7.731969 | batch: [  357/  512]\n",
      "    loss: -6.893476 | batch: [  408/  512]\n",
      "    loss: -7.581563 | batch: [  459/  512]\n",
      "    loss: -7.813658 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.321692\n",
      "    train_loss = -6.350416\n",
      "    val_loss = -6.360895\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 173 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.116363 | batch: [   51/  512]\n",
      "    loss: -8.025986 | batch: [  102/  512]\n",
      "    loss: -7.926843 | batch: [  153/  512]\n",
      "    loss: -8.125022 | batch: [  204/  512]\n",
      "    loss: -7.969535 | batch: [  255/  512]\n",
      "    loss: -8.102928 | batch: [  306/  512]\n",
      "    loss: -7.832836 | batch: [  357/  512]\n",
      "    loss: -8.170575 | batch: [  408/  512]\n",
      "    loss: -7.467650 | batch: [  459/  512]\n",
      "    loss: -7.846448 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.360895\n",
      "    train_loss = -6.348143\n",
      "    val_loss = -6.369486\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 174 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.146264 | batch: [   51/  512]\n",
      "    loss: -7.763708 | batch: [  102/  512]\n",
      "    loss: -8.066455 | batch: [  153/  512]\n",
      "    loss: -7.691794 | batch: [  204/  512]\n",
      "    loss: -7.943855 | batch: [  255/  512]\n",
      "    loss: -8.247775 | batch: [  306/  512]\n",
      "    loss: -7.164787 | batch: [  357/  512]\n",
      "    loss: -8.096504 | batch: [  408/  512]\n",
      "    loss: -8.179652 | batch: [  459/  512]\n",
      "    loss: -8.080695 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.369486\n",
      "    train_loss = -6.318318\n",
      "    val_loss = -6.337924\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 175 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.481554 | batch: [   51/  512]\n",
      "    loss: -7.848509 | batch: [  102/  512]\n",
      "    loss: -8.007277 | batch: [  153/  512]\n",
      "    loss: -7.786068 | batch: [  204/  512]\n",
      "    loss: -8.320714 | batch: [  255/  512]\n",
      "    loss: -7.867850 | batch: [  306/  512]\n",
      "    loss: -8.192936 | batch: [  357/  512]\n",
      "    loss: -8.203382 | batch: [  408/  512]\n",
      "    loss: -8.242238 | batch: [  459/  512]\n",
      "    loss: -7.799815 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.369486\n",
      "    train_loss = -6.329844\n",
      "    val_loss = -6.345289\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 176 --------------\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -7.843696 | batch: [   51/  512]\n",
      "    loss: -7.756599 | batch: [  102/  512]\n",
      "    loss: -8.116247 | batch: [  153/  512]\n",
      "    loss: -7.839636 | batch: [  204/  512]\n",
      "    loss: -7.899718 | batch: [  255/  512]\n",
      "    loss: -8.150448 | batch: [  306/  512]\n",
      "    loss: -6.779878 | batch: [  357/  512]\n",
      "    loss: -8.064602 | batch: [  408/  512]\n",
      "    loss: -7.794668 | batch: [  459/  512]\n",
      "    loss: -7.892708 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.369486\n",
      "    train_loss = -6.311893\n",
      "    val_loss = -6.296679\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 177 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.891938 | batch: [   51/  512]\n",
      "    loss: -8.187006 | batch: [  102/  512]\n",
      "    loss: -8.195739 | batch: [  153/  512]\n",
      "    loss: -7.899524 | batch: [  204/  512]\n",
      "    loss: -7.492311 | batch: [  255/  512]\n",
      "    loss: -8.265191 | batch: [  306/  512]\n",
      "    loss: -8.174704 | batch: [  357/  512]\n",
      "    loss: -8.084233 | batch: [  408/  512]\n",
      "    loss: -8.290527 | batch: [  459/  512]\n",
      "    loss: -7.741395 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.369486\n",
      "    train_loss = -6.279224\n",
      "    val_loss = -6.303437\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 178 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.101461 | batch: [   51/  512]\n",
      "    loss: -7.013556 | batch: [  102/  512]\n",
      "    loss: -8.176104 | batch: [  153/  512]\n",
      "    loss: -8.206511 | batch: [  204/  512]\n",
      "    loss: -8.092917 | batch: [  255/  512]\n",
      "    loss: -8.165468 | batch: [  306/  512]\n",
      "    loss: -7.452512 | batch: [  357/  512]\n",
      "    loss: -6.958570 | batch: [  408/  512]\n",
      "    loss: -7.267275 | batch: [  459/  512]\n",
      "    loss: -8.232631 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.369486\n",
      "    train_loss = -6.303856\n",
      "    val_loss = -6.334888\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 179 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.032407 | batch: [   51/  512]\n",
      "    loss: -7.091376 | batch: [  102/  512]\n",
      "    loss: -8.044990 | batch: [  153/  512]\n",
      "    loss: -8.145276 | batch: [  204/  512]\n",
      "    loss: -8.051918 | batch: [  255/  512]\n",
      "    loss: -7.839488 | batch: [  306/  512]\n",
      "    loss: -8.179674 | batch: [  357/  512]\n",
      "    loss: -8.092196 | batch: [  408/  512]\n",
      "    loss: -7.797697 | batch: [  459/  512]\n",
      "    loss: -7.913019 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.369486\n",
      "    train_loss = -6.301245\n",
      "    val_loss = -6.325255\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 180 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.826360 | batch: [   51/  512]\n",
      "    loss: -8.193781 | batch: [  102/  512]\n",
      "    loss: -8.194889 | batch: [  153/  512]\n",
      "    loss: -7.238407 | batch: [  204/  512]\n",
      "    loss: -7.730563 | batch: [  255/  512]\n",
      "    loss: -8.089564 | batch: [  306/  512]\n",
      "    loss: -7.801242 | batch: [  357/  512]\n",
      "    loss: -7.974681 | batch: [  408/  512]\n",
      "    loss: -7.392135 | batch: [  459/  512]\n",
      "    loss: -7.442005 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.369486\n",
      "    train_loss = -6.375693\n",
      "    val_loss = -6.382480\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 181 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.056588 | batch: [   51/  512]\n",
      "    loss: -7.946299 | batch: [  102/  512]\n",
      "    loss: -7.588843 | batch: [  153/  512]\n",
      "    loss: -7.604073 | batch: [  204/  512]\n",
      "    loss: -7.740716 | batch: [  255/  512]\n",
      "    loss: -8.253128 | batch: [  306/  512]\n",
      "    loss: -7.983127 | batch: [  357/  512]\n",
      "    loss: -7.697055 | batch: [  408/  512]\n",
      "    loss: -7.524394 | batch: [  459/  512]\n",
      "    loss: -8.088888 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.336634\n",
      "    val_loss = -6.347113\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 182 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.072658 | batch: [   51/  512]\n",
      "    loss: -7.962776 | batch: [  102/  512]\n",
      "    loss: -8.116077 | batch: [  153/  512]\n",
      "    loss: -7.923388 | batch: [  204/  512]\n",
      "    loss: -8.034770 | batch: [  255/  512]\n",
      "    loss: -8.216737 | batch: [  306/  512]\n",
      "    loss: -7.623440 | batch: [  357/  512]\n",
      "    loss: -7.889675 | batch: [  408/  512]\n",
      "    loss: -8.144129 | batch: [  459/  512]\n",
      "    loss: -7.015598 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.321958\n",
      "    val_loss = -6.347510\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 183 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.871801 | batch: [   51/  512]\n",
      "    loss: -8.209273 | batch: [  102/  512]\n",
      "    loss: -7.934564 | batch: [  153/  512]\n",
      "    loss: -7.934843 | batch: [  204/  512]\n",
      "    loss: -7.552028 | batch: [  255/  512]\n",
      "    loss: -8.013802 | batch: [  306/  512]\n",
      "    loss: -8.120940 | batch: [  357/  512]\n",
      "    loss: -7.930610 | batch: [  408/  512]\n",
      "    loss: -7.285313 | batch: [  459/  512]\n",
      "    loss: -8.208902 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.355333\n",
      "    val_loss = -6.356681\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 184 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.988810 | batch: [   51/  512]\n",
      "    loss: -7.914910 | batch: [  102/  512]\n",
      "    loss: -7.611645 | batch: [  153/  512]\n",
      "    loss: -8.130135 | batch: [  204/  512]\n",
      "    loss: -8.289795 | batch: [  255/  512]\n",
      "    loss: -8.274721 | batch: [  306/  512]\n",
      "    loss: -7.907560 | batch: [  357/  512]\n",
      "    loss: -7.951780 | batch: [  408/  512]\n",
      "    loss: -7.550289 | batch: [  459/  512]\n",
      "    loss: -7.896070 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.351551\n",
      "    val_loss = -6.350632\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 185 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.196743 | batch: [   51/  512]\n",
      "    loss: -8.309916 | batch: [  102/  512]\n",
      "    loss: -7.591029 | batch: [  153/  512]\n",
      "    loss: -7.420927 | batch: [  204/  512]\n",
      "    loss: -6.687020 | batch: [  255/  512]\n",
      "    loss: -7.920937 | batch: [  306/  512]\n",
      "    loss: -7.981219 | batch: [  357/  512]\n",
      "    loss: -8.091222 | batch: [  408/  512]\n",
      "    loss: -7.955005 | batch: [  459/  512]\n",
      "    loss: -7.988517 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.337523\n",
      "    val_loss = -6.351010\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 186 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.093183 | batch: [   51/  512]\n",
      "    loss: -8.157271 | batch: [  102/  512]\n",
      "    loss: -8.111227 | batch: [  153/  512]\n",
      "    loss: -6.967990 | batch: [  204/  512]\n",
      "    loss: -7.994790 | batch: [  255/  512]\n",
      "    loss: -8.327456 | batch: [  306/  512]\n",
      "    loss: -7.868402 | batch: [  357/  512]\n",
      "    loss: -7.321796 | batch: [  408/  512]\n",
      "    loss: -7.849369 | batch: [  459/  512]\n",
      "    loss: -8.392018 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.346367\n",
      "    val_loss = -6.364886\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 187 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.845611 | batch: [   51/  512]\n",
      "    loss: -8.154908 | batch: [  102/  512]\n",
      "    loss: -8.181562 | batch: [  153/  512]\n",
      "    loss: -7.128453 | batch: [  204/  512]\n",
      "    loss: -7.960276 | batch: [  255/  512]\n",
      "    loss: -7.756837 | batch: [  306/  512]\n",
      "    loss: -8.077303 | batch: [  357/  512]\n",
      "    loss: -8.200747 | batch: [  408/  512]\n",
      "    loss: -7.990761 | batch: [  459/  512]\n",
      "    loss: -7.395561 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.300313\n",
      "    val_loss = -6.303617\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 188 --------------\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -7.418361 | batch: [   51/  512]\n",
      "    loss: -7.944746 | batch: [  102/  512]\n",
      "    loss: -7.806214 | batch: [  153/  512]\n",
      "    loss: -7.882033 | batch: [  204/  512]\n",
      "    loss: -7.643168 | batch: [  255/  512]\n",
      "    loss: -8.311000 | batch: [  306/  512]\n",
      "    loss: -8.191703 | batch: [  357/  512]\n",
      "    loss: -7.767443 | batch: [  408/  512]\n",
      "    loss: -7.692316 | batch: [  459/  512]\n",
      "    loss: -8.203148 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.339404\n",
      "    val_loss = -6.357290\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 189 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.074133 | batch: [   51/  512]\n",
      "    loss: -8.285371 | batch: [  102/  512]\n",
      "    loss: -7.830508 | batch: [  153/  512]\n",
      "    loss: -7.955341 | batch: [  204/  512]\n",
      "    loss: -7.200806 | batch: [  255/  512]\n",
      "    loss: -7.963889 | batch: [  306/  512]\n",
      "    loss: -7.871737 | batch: [  357/  512]\n",
      "    loss: -7.318632 | batch: [  408/  512]\n",
      "    loss: -7.404146 | batch: [  459/  512]\n",
      "    loss: -7.553447 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.265679\n",
      "    val_loss = -6.293600\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 190 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.161184 | batch: [   51/  512]\n",
      "    loss: -7.781687 | batch: [  102/  512]\n",
      "    loss: -7.712533 | batch: [  153/  512]\n",
      "    loss: -7.898024 | batch: [  204/  512]\n",
      "    loss: -8.192707 | batch: [  255/  512]\n",
      "    loss: -7.444281 | batch: [  306/  512]\n",
      "    loss: -8.018587 | batch: [  357/  512]\n",
      "    loss: -8.049363 | batch: [  408/  512]\n",
      "    loss: -7.759386 | batch: [  459/  512]\n",
      "    loss: -8.167933 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.332693\n",
      "    val_loss = -6.326838\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 191 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.071690 | batch: [   51/  512]\n",
      "    loss: -8.149640 | batch: [  102/  512]\n",
      "    loss: -8.195710 | batch: [  153/  512]\n",
      "    loss: -7.647166 | batch: [  204/  512]\n",
      "    loss: -8.068782 | batch: [  255/  512]\n",
      "    loss: -8.134714 | batch: [  306/  512]\n",
      "    loss: -8.197262 | batch: [  357/  512]\n",
      "    loss: -6.700315 | batch: [  408/  512]\n",
      "    loss: -8.197980 | batch: [  459/  512]\n",
      "    loss: -7.965785 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.353379\n",
      "    val_loss = -6.345078\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 192 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.696621 | batch: [   51/  512]\n",
      "    loss: -8.266079 | batch: [  102/  512]\n",
      "    loss: -8.170552 | batch: [  153/  512]\n",
      "    loss: -7.761273 | batch: [  204/  512]\n",
      "    loss: -7.859992 | batch: [  255/  512]\n",
      "    loss: -8.099933 | batch: [  306/  512]\n",
      "    loss: -8.112545 | batch: [  357/  512]\n",
      "    loss: -8.199648 | batch: [  408/  512]\n",
      "    loss: -8.179091 | batch: [  459/  512]\n",
      "    loss: -7.354068 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.311853\n",
      "    val_loss = -6.327123\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 193 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.853638 | batch: [   51/  512]\n",
      "    loss: -7.387569 | batch: [  102/  512]\n",
      "    loss: -8.136080 | batch: [  153/  512]\n",
      "    loss: -7.897379 | batch: [  204/  512]\n",
      "    loss: -7.864855 | batch: [  255/  512]\n",
      "    loss: -7.533404 | batch: [  306/  512]\n",
      "    loss: -7.008725 | batch: [  357/  512]\n",
      "    loss: -7.895438 | batch: [  408/  512]\n",
      "    loss: -8.093418 | batch: [  459/  512]\n",
      "    loss: -7.234383 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.323052\n",
      "    val_loss = -6.355899\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 194 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.948751 | batch: [   51/  512]\n",
      "    loss: -8.275409 | batch: [  102/  512]\n",
      "    loss: -7.817148 | batch: [  153/  512]\n",
      "    loss: -7.793380 | batch: [  204/  512]\n",
      "    loss: -7.004992 | batch: [  255/  512]\n",
      "    loss: -7.319789 | batch: [  306/  512]\n",
      "    loss: -7.856755 | batch: [  357/  512]\n",
      "    loss: -7.882737 | batch: [  408/  512]\n",
      "    loss: -8.200232 | batch: [  459/  512]\n",
      "    loss: -8.028176 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.382480\n",
      "    train_loss = -6.372177\n",
      "    val_loss = -6.389736\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 195 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.639947 | batch: [   51/  512]\n",
      "    loss: -7.880937 | batch: [  102/  512]\n",
      "    loss: -8.222115 | batch: [  153/  512]\n",
      "    loss: -7.899953 | batch: [  204/  512]\n",
      "    loss: -8.136104 | batch: [  255/  512]\n",
      "    loss: -8.019233 | batch: [  306/  512]\n",
      "    loss: -8.136119 | batch: [  357/  512]\n",
      "    loss: -7.959172 | batch: [  408/  512]\n",
      "    loss: -7.739936 | batch: [  459/  512]\n",
      "    loss: -7.580843 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.389736\n",
      "    train_loss = -6.328711\n",
      "    val_loss = -6.340897\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 196 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.501724 | batch: [   51/  512]\n",
      "    loss: -8.104188 | batch: [  102/  512]\n",
      "    loss: -8.096942 | batch: [  153/  512]\n",
      "    loss: -8.240089 | batch: [  204/  512]\n",
      "    loss: -8.211114 | batch: [  255/  512]\n",
      "    loss: -7.949403 | batch: [  306/  512]\n",
      "    loss: -7.533060 | batch: [  357/  512]\n",
      "    loss: -7.923532 | batch: [  408/  512]\n",
      "    loss: -7.831316 | batch: [  459/  512]\n",
      "    loss: -7.190971 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.389736\n",
      "    train_loss = -6.323371\n",
      "    val_loss = -6.333502\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 197 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.559548 | batch: [   51/  512]\n",
      "    loss: -7.853772 | batch: [  102/  512]\n",
      "    loss: -7.997183 | batch: [  153/  512]\n",
      "    loss: -7.938083 | batch: [  204/  512]\n",
      "    loss: -8.022369 | batch: [  255/  512]\n",
      "    loss: -8.289811 | batch: [  306/  512]\n",
      "    loss: -8.136485 | batch: [  357/  512]\n",
      "    loss: -8.002992 | batch: [  408/  512]\n",
      "    loss: -7.930894 | batch: [  459/  512]\n",
      "    loss: -7.961265 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.389736\n",
      "    train_loss = -6.380312\n",
      "    val_loss = -6.372363\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 198 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.903195 | batch: [   51/  512]\n",
      "    loss: -8.209771 | batch: [  102/  512]\n",
      "    loss: -8.140777 | batch: [  153/  512]\n",
      "    loss: -7.424789 | batch: [  204/  512]\n",
      "    loss: -7.928205 | batch: [  255/  512]\n",
      "    loss: -8.168029 | batch: [  306/  512]\n",
      "    loss: -7.956773 | batch: [  357/  512]\n",
      "    loss: -8.347672 | batch: [  408/  512]\n",
      "    loss: -7.926121 | batch: [  459/  512]\n",
      "    loss: -7.672952 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.389736\n",
      "    train_loss = -6.376386\n",
      "    val_loss = -6.381607\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 199 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.231542 | batch: [   51/  512]\n",
      "    loss: -7.962223 | batch: [  102/  512]\n",
      "    loss: -8.122513 | batch: [  153/  512]\n",
      "    loss: -7.980305 | batch: [  204/  512]\n",
      "    loss: -8.145614 | batch: [  255/  512]\n",
      "    loss: -7.841242 | batch: [  306/  512]\n",
      "    loss: -7.736401 | batch: [  357/  512]\n",
      "    loss: -7.197929 | batch: [  408/  512]\n",
      "    loss: -7.869310 | batch: [  459/  512]\n",
      "    loss: -7.900682 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.389736\n",
      "    train_loss = -6.365832\n",
      "    val_loss = -6.383559\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 200 --------------\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -7.612157 | batch: [   51/  512]\n",
      "    loss: -7.416456 | batch: [  102/  512]\n",
      "    loss: -7.987094 | batch: [  153/  512]\n",
      "    loss: -8.333845 | batch: [  204/  512]\n",
      "    loss: -8.238227 | batch: [  255/  512]\n",
      "    loss: -8.098810 | batch: [  306/  512]\n",
      "    loss: -8.160352 | batch: [  357/  512]\n",
      "    loss: -8.375607 | batch: [  408/  512]\n",
      "    loss: -7.615385 | batch: [  459/  512]\n",
      "    loss: -8.065720 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.389736\n",
      "    train_loss = -6.321446\n",
      "    val_loss = -6.339846\n",
      "Epoch 00200: reducing learning rate of group 0 to 2.4300e-06.\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 201 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.890354 | batch: [   51/  512]\n",
      "    loss: -8.314198 | batch: [  102/  512]\n",
      "    loss: -8.016858 | batch: [  153/  512]\n",
      "    loss: -8.202945 | batch: [  204/  512]\n",
      "    loss: -7.613293 | batch: [  255/  512]\n",
      "    loss: -8.424518 | batch: [  306/  512]\n",
      "    loss: -8.147109 | batch: [  357/  512]\n",
      "    loss: -7.325962 | batch: [  408/  512]\n",
      "    loss: -8.065334 | batch: [  459/  512]\n",
      "    loss: -8.017013 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.389736\n",
      "    train_loss = -6.359456\n",
      "    val_loss = -6.382087\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 202 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.119422 | batch: [   51/  512]\n",
      "    loss: -8.440954 | batch: [  102/  512]\n",
      "    loss: -8.017982 | batch: [  153/  512]\n",
      "    loss: -6.897224 | batch: [  204/  512]\n",
      "    loss: -8.221428 | batch: [  255/  512]\n",
      "    loss: -8.213014 | batch: [  306/  512]\n",
      "    loss: -8.146837 | batch: [  357/  512]\n",
      "    loss: -8.175829 | batch: [  408/  512]\n",
      "    loss: -8.430645 | batch: [  459/  512]\n",
      "    loss: -7.806105 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.389736\n",
      "    train_loss = -6.372761\n",
      "    val_loss = -6.379537\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 203 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.019100 | batch: [   51/  512]\n",
      "    loss: -8.132652 | batch: [  102/  512]\n",
      "    loss: -7.833973 | batch: [  153/  512]\n",
      "    loss: -7.379818 | batch: [  204/  512]\n",
      "    loss: -7.831237 | batch: [  255/  512]\n",
      "    loss: -8.054993 | batch: [  306/  512]\n",
      "    loss: -7.898326 | batch: [  357/  512]\n",
      "    loss: -7.557128 | batch: [  408/  512]\n",
      "    loss: -7.416916 | batch: [  459/  512]\n",
      "    loss: -8.456681 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.389736\n",
      "    train_loss = -6.354849\n",
      "    val_loss = -6.369207\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 204 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.211338 | batch: [   51/  512]\n",
      "    loss: -8.184176 | batch: [  102/  512]\n",
      "    loss: -7.759677 | batch: [  153/  512]\n",
      "    loss: -7.705331 | batch: [  204/  512]\n",
      "    loss: -8.145410 | batch: [  255/  512]\n",
      "    loss: -8.073754 | batch: [  306/  512]\n",
      "    loss: -7.860768 | batch: [  357/  512]\n",
      "    loss: -7.924313 | batch: [  408/  512]\n",
      "    loss: -8.062167 | batch: [  459/  512]\n",
      "    loss: -7.906932 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.389736\n",
      "    train_loss = -6.405461\n",
      "    val_loss = -6.417164\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 205 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.421256 | batch: [   51/  512]\n",
      "    loss: -8.267044 | batch: [  102/  512]\n",
      "    loss: -7.394181 | batch: [  153/  512]\n",
      "    loss: -7.982673 | batch: [  204/  512]\n",
      "    loss: -8.077626 | batch: [  255/  512]\n",
      "    loss: -7.721672 | batch: [  306/  512]\n",
      "    loss: -8.049194 | batch: [  357/  512]\n",
      "    loss: -7.837671 | batch: [  408/  512]\n",
      "    loss: -8.171148 | batch: [  459/  512]\n",
      "    loss: -8.267268 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.365748\n",
      "    val_loss = -6.389414\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 206 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.858208 | batch: [   51/  512]\n",
      "    loss: -8.021954 | batch: [  102/  512]\n",
      "    loss: -8.170975 | batch: [  153/  512]\n",
      "    loss: -7.983628 | batch: [  204/  512]\n",
      "    loss: -8.011794 | batch: [  255/  512]\n",
      "    loss: -7.907934 | batch: [  306/  512]\n",
      "    loss: -7.955591 | batch: [  357/  512]\n",
      "    loss: -8.359161 | batch: [  408/  512]\n",
      "    loss: -7.919995 | batch: [  459/  512]\n",
      "    loss: -7.418422 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.368652\n",
      "    val_loss = -6.381998\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 207 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.496831 | batch: [   51/  512]\n",
      "    loss: -8.137285 | batch: [  102/  512]\n",
      "    loss: -7.686687 | batch: [  153/  512]\n",
      "    loss: -8.133202 | batch: [  204/  512]\n",
      "    loss: -7.729921 | batch: [  255/  512]\n",
      "    loss: -8.339423 | batch: [  306/  512]\n",
      "    loss: -8.137533 | batch: [  357/  512]\n",
      "    loss: -8.359762 | batch: [  408/  512]\n",
      "    loss: -8.041469 | batch: [  459/  512]\n",
      "    loss: -7.426713 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.380750\n",
      "    val_loss = -6.381954\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 208 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.032839 | batch: [   51/  512]\n",
      "    loss: -7.855265 | batch: [  102/  512]\n",
      "    loss: -8.199960 | batch: [  153/  512]\n",
      "    loss: -8.211673 | batch: [  204/  512]\n",
      "    loss: -7.857174 | batch: [  255/  512]\n",
      "    loss: -7.338643 | batch: [  306/  512]\n",
      "    loss: -7.835033 | batch: [  357/  512]\n",
      "    loss: -8.017304 | batch: [  408/  512]\n",
      "    loss: -8.122618 | batch: [  459/  512]\n",
      "    loss: -8.287150 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.394138\n",
      "    val_loss = -6.398426\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 209 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.960683 | batch: [   51/  512]\n",
      "    loss: -7.689092 | batch: [  102/  512]\n",
      "    loss: -8.123425 | batch: [  153/  512]\n",
      "    loss: -8.085296 | batch: [  204/  512]\n",
      "    loss: -8.160283 | batch: [  255/  512]\n",
      "    loss: -7.645503 | batch: [  306/  512]\n",
      "    loss: -7.632176 | batch: [  357/  512]\n",
      "    loss: -8.054511 | batch: [  408/  512]\n",
      "    loss: -8.308804 | batch: [  459/  512]\n",
      "    loss: -7.403536 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.369055\n",
      "    val_loss = -6.380561\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 210 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.923044 | batch: [   51/  512]\n",
      "    loss: -7.492287 | batch: [  102/  512]\n",
      "    loss: -7.765332 | batch: [  153/  512]\n",
      "    loss: -8.075939 | batch: [  204/  512]\n",
      "    loss: -6.776256 | batch: [  255/  512]\n",
      "    loss: -7.396694 | batch: [  306/  512]\n",
      "    loss: -8.076469 | batch: [  357/  512]\n",
      "    loss: -7.969847 | batch: [  408/  512]\n",
      "    loss: -8.474797 | batch: [  459/  512]\n",
      "    loss: -7.767807 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.388482\n",
      "    val_loss = -6.408059\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 211 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.203609 | batch: [   51/  512]\n",
      "    loss: -7.892754 | batch: [  102/  512]\n",
      "    loss: -8.268277 | batch: [  153/  512]\n",
      "    loss: -7.704049 | batch: [  204/  512]\n",
      "    loss: -7.849872 | batch: [  255/  512]\n",
      "    loss: -8.264200 | batch: [  306/  512]\n",
      "    loss: -8.036620 | batch: [  357/  512]\n",
      "    loss: -8.042279 | batch: [  408/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -8.012363 | batch: [  459/  512]\n",
      "    loss: -8.248687 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.395485\n",
      "    val_loss = -6.404566\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 212 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.893463 | batch: [   51/  512]\n",
      "    loss: -7.984720 | batch: [  102/  512]\n",
      "    loss: -8.389729 | batch: [  153/  512]\n",
      "    loss: -8.377954 | batch: [  204/  512]\n",
      "    loss: -8.376995 | batch: [  255/  512]\n",
      "    loss: -7.934159 | batch: [  306/  512]\n",
      "    loss: -8.115292 | batch: [  357/  512]\n",
      "    loss: -8.182777 | batch: [  408/  512]\n",
      "    loss: -7.812093 | batch: [  459/  512]\n",
      "    loss: -8.219394 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.381070\n",
      "    val_loss = -6.340654\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 213 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.396678 | batch: [   51/  512]\n",
      "    loss: -8.326853 | batch: [  102/  512]\n",
      "    loss: -8.218443 | batch: [  153/  512]\n",
      "    loss: -8.067747 | batch: [  204/  512]\n",
      "    loss: -7.772806 | batch: [  255/  512]\n",
      "    loss: -8.316996 | batch: [  306/  512]\n",
      "    loss: -8.303397 | batch: [  357/  512]\n",
      "    loss: -7.411304 | batch: [  408/  512]\n",
      "    loss: -8.069928 | batch: [  459/  512]\n",
      "    loss: -7.980861 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.362031\n",
      "    val_loss = -6.359627\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 214 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.982896 | batch: [   51/  512]\n",
      "    loss: -8.316609 | batch: [  102/  512]\n",
      "    loss: -6.197349 | batch: [  153/  512]\n",
      "    loss: -7.950056 | batch: [  204/  512]\n",
      "    loss: -7.550006 | batch: [  255/  512]\n",
      "    loss: -8.180888 | batch: [  306/  512]\n",
      "    loss: -8.264232 | batch: [  357/  512]\n",
      "    loss: -8.146855 | batch: [  408/  512]\n",
      "    loss: -7.830468 | batch: [  459/  512]\n",
      "    loss: -7.851355 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.367109\n",
      "    val_loss = -6.388305\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 215 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.386586 | batch: [   51/  512]\n",
      "    loss: -7.564980 | batch: [  102/  512]\n",
      "    loss: -8.017408 | batch: [  153/  512]\n",
      "    loss: -8.407644 | batch: [  204/  512]\n",
      "    loss: -7.265918 | batch: [  255/  512]\n",
      "    loss: -8.355255 | batch: [  306/  512]\n",
      "    loss: -7.772386 | batch: [  357/  512]\n",
      "    loss: -7.823475 | batch: [  408/  512]\n",
      "    loss: -8.045051 | batch: [  459/  512]\n",
      "    loss: -8.004027 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.375168\n",
      "    val_loss = -6.372964\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 216 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.992526 | batch: [   51/  512]\n",
      "    loss: -8.147499 | batch: [  102/  512]\n",
      "    loss: -8.359455 | batch: [  153/  512]\n",
      "    loss: -8.343020 | batch: [  204/  512]\n",
      "    loss: -8.161335 | batch: [  255/  512]\n",
      "    loss: -8.039690 | batch: [  306/  512]\n",
      "    loss: -7.860878 | batch: [  357/  512]\n",
      "    loss: -8.171573 | batch: [  408/  512]\n",
      "    loss: -8.063097 | batch: [  459/  512]\n",
      "    loss: -7.871960 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.384014\n",
      "    val_loss = -6.392903\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 217 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.838825 | batch: [   51/  512]\n",
      "    loss: -7.629967 | batch: [  102/  512]\n",
      "    loss: -7.818820 | batch: [  153/  512]\n",
      "    loss: -8.130192 | batch: [  204/  512]\n",
      "    loss: -8.278025 | batch: [  255/  512]\n",
      "    loss: -7.802060 | batch: [  306/  512]\n",
      "    loss: -7.327094 | batch: [  357/  512]\n",
      "    loss: -8.117205 | batch: [  408/  512]\n",
      "    loss: -6.716897 | batch: [  459/  512]\n",
      "    loss: -8.006271 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.419868\n",
      "    val_loss = -6.409227\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 218 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.191370 | batch: [   51/  512]\n",
      "    loss: -8.022093 | batch: [  102/  512]\n",
      "    loss: -7.794624 | batch: [  153/  512]\n",
      "    loss: -8.272530 | batch: [  204/  512]\n",
      "    loss: -8.087475 | batch: [  255/  512]\n",
      "    loss: -8.215666 | batch: [  306/  512]\n",
      "    loss: -7.645308 | batch: [  357/  512]\n",
      "    loss: -8.011523 | batch: [  408/  512]\n",
      "    loss: -7.625589 | batch: [  459/  512]\n",
      "    loss: -7.884273 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.356231\n",
      "    val_loss = -6.377551\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 219 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.293409 | batch: [   51/  512]\n",
      "    loss: -7.953189 | batch: [  102/  512]\n",
      "    loss: -8.364857 | batch: [  153/  512]\n",
      "    loss: -7.753591 | batch: [  204/  512]\n",
      "    loss: -7.831212 | batch: [  255/  512]\n",
      "    loss: -7.920699 | batch: [  306/  512]\n",
      "    loss: -7.852717 | batch: [  357/  512]\n",
      "    loss: -7.866887 | batch: [  408/  512]\n",
      "    loss: -8.449396 | batch: [  459/  512]\n",
      "    loss: -7.596694 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.417164\n",
      "    train_loss = -6.419615\n",
      "    val_loss = -6.425698\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 220 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.812919 | batch: [   51/  512]\n",
      "    loss: -7.365543 | batch: [  102/  512]\n",
      "    loss: -8.110204 | batch: [  153/  512]\n",
      "    loss: -7.770056 | batch: [  204/  512]\n",
      "    loss: -7.979372 | batch: [  255/  512]\n",
      "    loss: -8.167852 | batch: [  306/  512]\n",
      "    loss: -8.359604 | batch: [  357/  512]\n",
      "    loss: -7.723829 | batch: [  408/  512]\n",
      "    loss: -8.061642 | batch: [  459/  512]\n",
      "    loss: -8.222866 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.425698\n",
      "    train_loss = -6.401003\n",
      "    val_loss = -6.424015\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 221 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.033615 | batch: [   51/  512]\n",
      "    loss: -8.186949 | batch: [  102/  512]\n",
      "    loss: -8.159128 | batch: [  153/  512]\n",
      "    loss: -8.314557 | batch: [  204/  512]\n",
      "    loss: -8.072082 | batch: [  255/  512]\n",
      "    loss: -8.155747 | batch: [  306/  512]\n",
      "    loss: -8.165829 | batch: [  357/  512]\n",
      "    loss: -7.946165 | batch: [  408/  512]\n",
      "    loss: -8.022790 | batch: [  459/  512]\n",
      "    loss: -7.938942 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.425698\n",
      "    train_loss = -6.389006\n",
      "    val_loss = -6.406207\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 222 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.323008 | batch: [   51/  512]\n",
      "    loss: -6.002400 | batch: [  102/  512]\n",
      "    loss: -7.429653 | batch: [  153/  512]\n",
      "    loss: -8.281673 | batch: [  204/  512]\n",
      "    loss: -8.295769 | batch: [  255/  512]\n",
      "    loss: -6.705641 | batch: [  306/  512]\n",
      "    loss: -7.861227 | batch: [  357/  512]\n",
      "    loss: -7.964234 | batch: [  408/  512]\n",
      "    loss: -7.454291 | batch: [  459/  512]\n",
      "    loss: -8.162555 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.425698\n",
      "    train_loss = -6.415932\n",
      "    val_loss = -6.407419\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 223 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.818155 | batch: [   51/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -8.123908 | batch: [  102/  512]\n",
      "    loss: -8.223317 | batch: [  153/  512]\n",
      "    loss: -7.905694 | batch: [  204/  512]\n",
      "    loss: -6.954719 | batch: [  255/  512]\n",
      "    loss: -8.282248 | batch: [  306/  512]\n",
      "    loss: -7.988760 | batch: [  357/  512]\n",
      "    loss: -8.085024 | batch: [  408/  512]\n",
      "    loss: -8.262983 | batch: [  459/  512]\n",
      "    loss: -7.856990 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.425698\n",
      "    train_loss = -6.356011\n",
      "    val_loss = -6.364304\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 224 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.097758 | batch: [   51/  512]\n",
      "    loss: -8.460384 | batch: [  102/  512]\n",
      "    loss: -7.602917 | batch: [  153/  512]\n",
      "    loss: -8.060778 | batch: [  204/  512]\n",
      "    loss: -8.109869 | batch: [  255/  512]\n",
      "    loss: -7.600983 | batch: [  306/  512]\n",
      "    loss: -8.039478 | batch: [  357/  512]\n",
      "    loss: -7.715601 | batch: [  408/  512]\n",
      "    loss: -8.029503 | batch: [  459/  512]\n",
      "    loss: -8.016576 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.425698\n",
      "    train_loss = -6.376318\n",
      "    val_loss = -6.385076\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 225 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -6.361964 | batch: [   51/  512]\n",
      "    loss: -7.976210 | batch: [  102/  512]\n",
      "    loss: -7.626018 | batch: [  153/  512]\n",
      "    loss: -7.932570 | batch: [  204/  512]\n",
      "    loss: -8.201861 | batch: [  255/  512]\n",
      "    loss: -8.337056 | batch: [  306/  512]\n",
      "    loss: -7.440832 | batch: [  357/  512]\n",
      "    loss: -8.226437 | batch: [  408/  512]\n",
      "    loss: -7.146977 | batch: [  459/  512]\n",
      "    loss: -7.902791 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.425698\n",
      "    train_loss = -6.385237\n",
      "    val_loss = -6.401188\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 226 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.099996 | batch: [   51/  512]\n",
      "    loss: -8.000570 | batch: [  102/  512]\n",
      "    loss: -8.217135 | batch: [  153/  512]\n",
      "    loss: -7.801971 | batch: [  204/  512]\n",
      "    loss: -8.328540 | batch: [  255/  512]\n",
      "    loss: -8.212725 | batch: [  306/  512]\n",
      "    loss: -7.763886 | batch: [  357/  512]\n",
      "    loss: -8.305599 | batch: [  408/  512]\n",
      "    loss: -8.239426 | batch: [  459/  512]\n",
      "    loss: -8.060966 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.425698\n",
      "    train_loss = -6.427692\n",
      "    val_loss = -6.436191\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 227 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.981199 | batch: [   51/  512]\n",
      "    loss: -8.171865 | batch: [  102/  512]\n",
      "    loss: -6.669116 | batch: [  153/  512]\n",
      "    loss: -8.009750 | batch: [  204/  512]\n",
      "    loss: -7.805638 | batch: [  255/  512]\n",
      "    loss: -8.179357 | batch: [  306/  512]\n",
      "    loss: -7.571954 | batch: [  357/  512]\n",
      "    loss: -8.396695 | batch: [  408/  512]\n",
      "    loss: -7.887423 | batch: [  459/  512]\n",
      "    loss: -7.889157 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.357678\n",
      "    val_loss = -6.383943\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 228 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.121743 | batch: [   51/  512]\n",
      "    loss: -8.027903 | batch: [  102/  512]\n",
      "    loss: -8.001490 | batch: [  153/  512]\n",
      "    loss: -7.445014 | batch: [  204/  512]\n",
      "    loss: -7.927832 | batch: [  255/  512]\n",
      "    loss: -7.638953 | batch: [  306/  512]\n",
      "    loss: -8.256250 | batch: [  357/  512]\n",
      "    loss: -8.019333 | batch: [  408/  512]\n",
      "    loss: -7.150173 | batch: [  459/  512]\n",
      "    loss: -7.668746 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.357231\n",
      "    val_loss = -6.370958\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 229 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.076069 | batch: [   51/  512]\n",
      "    loss: -8.278185 | batch: [  102/  512]\n",
      "    loss: -7.978250 | batch: [  153/  512]\n",
      "    loss: -8.036087 | batch: [  204/  512]\n",
      "    loss: -8.172024 | batch: [  255/  512]\n",
      "    loss: -8.311165 | batch: [  306/  512]\n",
      "    loss: -7.989660 | batch: [  357/  512]\n",
      "    loss: -8.255774 | batch: [  408/  512]\n",
      "    loss: -7.538977 | batch: [  459/  512]\n",
      "    loss: -8.079136 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.407869\n",
      "    val_loss = -6.396777\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 230 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.985874 | batch: [   51/  512]\n",
      "    loss: -8.447916 | batch: [  102/  512]\n",
      "    loss: -7.768393 | batch: [  153/  512]\n",
      "    loss: -7.843276 | batch: [  204/  512]\n",
      "    loss: -8.209121 | batch: [  255/  512]\n",
      "    loss: -7.696134 | batch: [  306/  512]\n",
      "    loss: -8.200500 | batch: [  357/  512]\n",
      "    loss: -7.631749 | batch: [  408/  512]\n",
      "    loss: -8.111785 | batch: [  459/  512]\n",
      "    loss: -8.183287 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.411449\n",
      "    val_loss = -6.419468\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 231 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.048677 | batch: [   51/  512]\n",
      "    loss: -8.342649 | batch: [  102/  512]\n",
      "    loss: -7.773010 | batch: [  153/  512]\n",
      "    loss: -8.112030 | batch: [  204/  512]\n",
      "    loss: -8.122503 | batch: [  255/  512]\n",
      "    loss: -8.129586 | batch: [  306/  512]\n",
      "    loss: -8.240013 | batch: [  357/  512]\n",
      "    loss: -8.309169 | batch: [  408/  512]\n",
      "    loss: -8.414051 | batch: [  459/  512]\n",
      "    loss: -7.624109 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.348171\n",
      "    val_loss = -6.359133\n",
      "Epoch 00231: reducing learning rate of group 0 to 7.2900e-07.\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 232 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.112017 | batch: [   51/  512]\n",
      "    loss: -7.849364 | batch: [  102/  512]\n",
      "    loss: -8.156805 | batch: [  153/  512]\n",
      "    loss: -7.973062 | batch: [  204/  512]\n",
      "    loss: -8.229877 | batch: [  255/  512]\n",
      "    loss: -8.111615 | batch: [  306/  512]\n",
      "    loss: -7.947448 | batch: [  357/  512]\n",
      "    loss: -7.458576 | batch: [  408/  512]\n",
      "    loss: -7.709383 | batch: [  459/  512]\n",
      "    loss: -8.193095 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.406490\n",
      "    val_loss = -6.415562\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 233 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.817256 | batch: [   51/  512]\n",
      "    loss: -8.223149 | batch: [  102/  512]\n",
      "    loss: -7.974388 | batch: [  153/  512]\n",
      "    loss: -7.789279 | batch: [  204/  512]\n",
      "    loss: -8.046870 | batch: [  255/  512]\n",
      "    loss: -8.157296 | batch: [  306/  512]\n",
      "    loss: -8.203584 | batch: [  357/  512]\n",
      "    loss: -8.312121 | batch: [  408/  512]\n",
      "    loss: -7.704363 | batch: [  459/  512]\n",
      "    loss: -8.474019 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.405976\n",
      "    val_loss = -6.409895\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 234 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.052000 | batch: [   51/  512]\n",
      "    loss: -8.078986 | batch: [  102/  512]\n",
      "    loss: -8.091196 | batch: [  153/  512]\n",
      "    loss: -8.294922 | batch: [  204/  512]\n",
      "    loss: -8.144949 | batch: [  255/  512]\n",
      "    loss: -8.382684 | batch: [  306/  512]\n",
      "    loss: -7.977439 | batch: [  357/  512]\n",
      "    loss: -7.788843 | batch: [  408/  512]\n",
      "    loss: -8.181235 | batch: [  459/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -7.735338 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.421874\n",
      "    val_loss = -6.425842\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 235 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.004930 | batch: [   51/  512]\n",
      "    loss: -8.302248 | batch: [  102/  512]\n",
      "    loss: -7.458150 | batch: [  153/  512]\n",
      "    loss: -7.724348 | batch: [  204/  512]\n",
      "    loss: -8.029797 | batch: [  255/  512]\n",
      "    loss: -8.159183 | batch: [  306/  512]\n",
      "    loss: -8.434129 | batch: [  357/  512]\n",
      "    loss: -7.800990 | batch: [  408/  512]\n",
      "    loss: -7.749285 | batch: [  459/  512]\n",
      "    loss: -8.160725 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.404360\n",
      "    val_loss = -6.415502\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 236 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.769112 | batch: [   51/  512]\n",
      "    loss: -8.322588 | batch: [  102/  512]\n",
      "    loss: -7.902104 | batch: [  153/  512]\n",
      "    loss: -8.033335 | batch: [  204/  512]\n",
      "    loss: -8.003987 | batch: [  255/  512]\n",
      "    loss: -8.086499 | batch: [  306/  512]\n",
      "    loss: -8.047620 | batch: [  357/  512]\n",
      "    loss: -7.918921 | batch: [  408/  512]\n",
      "    loss: -8.031567 | batch: [  459/  512]\n",
      "    loss: -8.292551 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.395481\n",
      "    val_loss = -6.402483\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 237 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.298320 | batch: [   51/  512]\n",
      "    loss: -8.041280 | batch: [  102/  512]\n",
      "    loss: -8.006340 | batch: [  153/  512]\n",
      "    loss: -7.831216 | batch: [  204/  512]\n",
      "    loss: -8.048412 | batch: [  255/  512]\n",
      "    loss: -7.893478 | batch: [  306/  512]\n",
      "    loss: -8.215552 | batch: [  357/  512]\n",
      "    loss: -7.862809 | batch: [  408/  512]\n",
      "    loss: -7.735617 | batch: [  459/  512]\n",
      "    loss: -7.872128 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.379646\n",
      "    val_loss = -6.399667\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 238 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.803476 | batch: [   51/  512]\n",
      "    loss: -7.208980 | batch: [  102/  512]\n",
      "    loss: -6.869996 | batch: [  153/  512]\n",
      "    loss: -7.957043 | batch: [  204/  512]\n",
      "    loss: -8.279258 | batch: [  255/  512]\n",
      "    loss: -8.105571 | batch: [  306/  512]\n",
      "    loss: -7.858129 | batch: [  357/  512]\n",
      "    loss: -7.995465 | batch: [  408/  512]\n",
      "    loss: -8.140647 | batch: [  459/  512]\n",
      "    loss: -7.766800 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.404820\n",
      "    val_loss = -6.417032\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 239 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.414763 | batch: [   51/  512]\n",
      "    loss: -8.180670 | batch: [  102/  512]\n",
      "    loss: -8.027326 | batch: [  153/  512]\n",
      "    loss: -8.037493 | batch: [  204/  512]\n",
      "    loss: -7.927829 | batch: [  255/  512]\n",
      "    loss: -8.086021 | batch: [  306/  512]\n",
      "    loss: -7.812231 | batch: [  357/  512]\n",
      "    loss: -7.154605 | batch: [  408/  512]\n",
      "    loss: -8.308402 | batch: [  459/  512]\n",
      "    loss: -8.259352 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.394901\n",
      "    val_loss = -6.392174\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 240 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.626285 | batch: [   51/  512]\n",
      "    loss: -8.267604 | batch: [  102/  512]\n",
      "    loss: -8.398055 | batch: [  153/  512]\n",
      "    loss: -8.201077 | batch: [  204/  512]\n",
      "    loss: -7.711647 | batch: [  255/  512]\n",
      "    loss: -7.590146 | batch: [  306/  512]\n",
      "    loss: -8.216662 | batch: [  357/  512]\n",
      "    loss: -8.318565 | batch: [  408/  512]\n",
      "    loss: -8.274153 | batch: [  459/  512]\n",
      "    loss: -7.697793 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.393206\n",
      "    val_loss = -6.386750\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 241 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.178684 | batch: [   51/  512]\n",
      "    loss: -8.012481 | batch: [  102/  512]\n",
      "    loss: -7.391451 | batch: [  153/  512]\n",
      "    loss: -8.138152 | batch: [  204/  512]\n",
      "    loss: -8.335519 | batch: [  255/  512]\n",
      "    loss: -7.969932 | batch: [  306/  512]\n",
      "    loss: -8.381571 | batch: [  357/  512]\n",
      "    loss: -6.835349 | batch: [  408/  512]\n",
      "    loss: -7.979324 | batch: [  459/  512]\n",
      "    loss: -8.056852 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.409548\n",
      "    val_loss = -6.410618\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 242 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.361805 | batch: [   51/  512]\n",
      "    loss: -7.582403 | batch: [  102/  512]\n",
      "    loss: -7.812696 | batch: [  153/  512]\n",
      "    loss: -8.069510 | batch: [  204/  512]\n",
      "    loss: -8.400962 | batch: [  255/  512]\n",
      "    loss: -8.304138 | batch: [  306/  512]\n",
      "    loss: -7.542112 | batch: [  357/  512]\n",
      "    loss: -8.344508 | batch: [  408/  512]\n",
      "    loss: -7.979565 | batch: [  459/  512]\n",
      "    loss: -8.085834 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.420782\n",
      "    val_loss = -6.434683\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 243 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.131652 | batch: [   51/  512]\n",
      "    loss: -7.824789 | batch: [  102/  512]\n",
      "    loss: -7.884297 | batch: [  153/  512]\n",
      "    loss: -8.192240 | batch: [  204/  512]\n",
      "    loss: -6.984993 | batch: [  255/  512]\n",
      "    loss: -8.433884 | batch: [  306/  512]\n",
      "    loss: -8.090080 | batch: [  357/  512]\n",
      "    loss: -7.729456 | batch: [  408/  512]\n",
      "    loss: -7.398218 | batch: [  459/  512]\n",
      "    loss: -8.326379 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.349357\n",
      "    val_loss = -6.359560\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 244 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.461902 | batch: [   51/  512]\n",
      "    loss: -8.300794 | batch: [  102/  512]\n",
      "    loss: -7.944415 | batch: [  153/  512]\n",
      "    loss: -7.977540 | batch: [  204/  512]\n",
      "    loss: -7.680722 | batch: [  255/  512]\n",
      "    loss: -8.117210 | batch: [  306/  512]\n",
      "    loss: -8.203384 | batch: [  357/  512]\n",
      "    loss: -8.069420 | batch: [  408/  512]\n",
      "    loss: -7.729410 | batch: [  459/  512]\n",
      "    loss: -7.863705 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.407611\n",
      "    val_loss = -6.356822\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 245 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.265167 | batch: [   51/  512]\n",
      "    loss: -7.959198 | batch: [  102/  512]\n",
      "    loss: -7.741477 | batch: [  153/  512]\n",
      "    loss: -7.851260 | batch: [  204/  512]\n",
      "    loss: -7.896998 | batch: [  255/  512]\n",
      "    loss: -7.773182 | batch: [  306/  512]\n",
      "    loss: -8.116601 | batch: [  357/  512]\n",
      "    loss: -8.107288 | batch: [  408/  512]\n",
      "    loss: -8.438311 | batch: [  459/  512]\n",
      "    loss: -8.259439 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.386993\n",
      "    val_loss = -6.406250\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 246 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.987840 | batch: [   51/  512]\n",
      "    loss: -7.613494 | batch: [  102/  512]\n",
      "    loss: -8.068390 | batch: [  153/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -8.274587 | batch: [  204/  512]\n",
      "    loss: -8.074408 | batch: [  255/  512]\n",
      "    loss: -8.318235 | batch: [  306/  512]\n",
      "    loss: -7.042849 | batch: [  357/  512]\n",
      "    loss: -7.966690 | batch: [  408/  512]\n",
      "    loss: -8.265670 | batch: [  459/  512]\n",
      "    loss: -8.296427 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.418643\n",
      "    val_loss = -6.429205\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 247 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.352089 | batch: [   51/  512]\n",
      "    loss: -8.300836 | batch: [  102/  512]\n",
      "    loss: -8.229007 | batch: [  153/  512]\n",
      "    loss: -7.762839 | batch: [  204/  512]\n",
      "    loss: -8.328344 | batch: [  255/  512]\n",
      "    loss: -8.223750 | batch: [  306/  512]\n",
      "    loss: -8.014047 | batch: [  357/  512]\n",
      "    loss: -8.172213 | batch: [  408/  512]\n",
      "    loss: -7.898752 | batch: [  459/  512]\n",
      "    loss: -8.145941 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.436191\n",
      "    train_loss = -6.446782\n",
      "    val_loss = -6.453522\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 248 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.123631 | batch: [   51/  512]\n",
      "    loss: -7.987209 | batch: [  102/  512]\n",
      "    loss: -6.943645 | batch: [  153/  512]\n",
      "    loss: -7.627746 | batch: [  204/  512]\n",
      "    loss: -7.733525 | batch: [  255/  512]\n",
      "    loss: -8.444370 | batch: [  306/  512]\n",
      "    loss: -8.450675 | batch: [  357/  512]\n",
      "    loss: -7.618929 | batch: [  408/  512]\n",
      "    loss: -8.188675 | batch: [  459/  512]\n",
      "    loss: -7.808521 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.453522\n",
      "    train_loss = -6.390495\n",
      "    val_loss = -6.404652\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 249 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.837477 | batch: [   51/  512]\n",
      "    loss: -8.203451 | batch: [  102/  512]\n",
      "    loss: -7.070442 | batch: [  153/  512]\n",
      "    loss: -7.204101 | batch: [  204/  512]\n",
      "    loss: -8.092168 | batch: [  255/  512]\n",
      "    loss: -7.906702 | batch: [  306/  512]\n",
      "    loss: -8.098994 | batch: [  357/  512]\n",
      "    loss: -8.003569 | batch: [  408/  512]\n",
      "    loss: -8.001900 | batch: [  459/  512]\n",
      "    loss: -8.337437 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.453522\n",
      "    train_loss = -6.432228\n",
      "    val_loss = -6.431319\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 250 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.114683 | batch: [   51/  512]\n",
      "    loss: -8.032145 | batch: [  102/  512]\n",
      "    loss: -8.301060 | batch: [  153/  512]\n",
      "    loss: -8.063348 | batch: [  204/  512]\n",
      "    loss: -8.209662 | batch: [  255/  512]\n",
      "    loss: -8.122435 | batch: [  306/  512]\n",
      "    loss: -7.793121 | batch: [  357/  512]\n",
      "    loss: -8.162458 | batch: [  408/  512]\n",
      "    loss: -7.910742 | batch: [  459/  512]\n",
      "    loss: -8.188385 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.453522\n",
      "    train_loss = -6.405128\n",
      "    val_loss = -6.406710\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 251 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.092235 | batch: [   51/  512]\n",
      "    loss: -7.621177 | batch: [  102/  512]\n",
      "    loss: -7.188261 | batch: [  153/  512]\n",
      "    loss: -8.221059 | batch: [  204/  512]\n",
      "    loss: -7.505497 | batch: [  255/  512]\n",
      "    loss: -8.088439 | batch: [  306/  512]\n",
      "    loss: -7.952829 | batch: [  357/  512]\n",
      "    loss: -8.366402 | batch: [  408/  512]\n",
      "    loss: -8.214350 | batch: [  459/  512]\n",
      "    loss: -8.091992 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.453522\n",
      "    train_loss = -6.371515\n",
      "    val_loss = -6.391118\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 252 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.066374 | batch: [   51/  512]\n",
      "    loss: -7.706352 | batch: [  102/  512]\n",
      "    loss: -8.375720 | batch: [  153/  512]\n",
      "    loss: -7.576981 | batch: [  204/  512]\n",
      "    loss: -8.191650 | batch: [  255/  512]\n",
      "    loss: -8.151548 | batch: [  306/  512]\n",
      "    loss: -7.798430 | batch: [  357/  512]\n",
      "    loss: -7.992482 | batch: [  408/  512]\n",
      "    loss: -7.907738 | batch: [  459/  512]\n",
      "    loss: -8.262936 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.453522\n",
      "    train_loss = -6.417276\n",
      "    val_loss = -6.425286\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 253 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.316336 | batch: [   51/  512]\n",
      "    loss: -8.014323 | batch: [  102/  512]\n",
      "    loss: -7.599658 | batch: [  153/  512]\n",
      "    loss: -8.366985 | batch: [  204/  512]\n",
      "    loss: -7.824291 | batch: [  255/  512]\n",
      "    loss: -7.792156 | batch: [  306/  512]\n",
      "    loss: -8.172567 | batch: [  357/  512]\n",
      "    loss: -7.728015 | batch: [  408/  512]\n",
      "    loss: -7.431551 | batch: [  459/  512]\n",
      "    loss: -7.980300 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.453522\n",
      "    train_loss = -6.456353\n",
      "    val_loss = -6.459142\n",
      "    Saving Model\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 254 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.004130 | batch: [   51/  512]\n",
      "    loss: -8.226710 | batch: [  102/  512]\n",
      "    loss: -8.229818 | batch: [  153/  512]\n",
      "    loss: -7.959844 | batch: [  204/  512]\n",
      "    loss: -7.373215 | batch: [  255/  512]\n",
      "    loss: -7.577881 | batch: [  306/  512]\n",
      "    loss: -8.179173 | batch: [  357/  512]\n",
      "    loss: -7.763491 | batch: [  408/  512]\n",
      "    loss: -8.051242 | batch: [  459/  512]\n",
      "    loss: -8.201468 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.422375\n",
      "    val_loss = -6.435341\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 255 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.902139 | batch: [   51/  512]\n",
      "    loss: -8.141034 | batch: [  102/  512]\n",
      "    loss: -7.504517 | batch: [  153/  512]\n",
      "    loss: -7.981241 | batch: [  204/  512]\n",
      "    loss: -8.307751 | batch: [  255/  512]\n",
      "    loss: -7.790864 | batch: [  306/  512]\n",
      "    loss: -8.145581 | batch: [  357/  512]\n",
      "    loss: -7.913996 | batch: [  408/  512]\n",
      "    loss: -8.041340 | batch: [  459/  512]\n",
      "    loss: -8.260725 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.401923\n",
      "    val_loss = -6.406028\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 256 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.287755 | batch: [   51/  512]\n",
      "    loss: -8.472076 | batch: [  102/  512]\n",
      "    loss: -7.773601 | batch: [  153/  512]\n",
      "    loss: -7.853260 | batch: [  204/  512]\n",
      "    loss: -8.243773 | batch: [  255/  512]\n",
      "    loss: -7.876350 | batch: [  306/  512]\n",
      "    loss: -8.375114 | batch: [  357/  512]\n",
      "    loss: -7.535560 | batch: [  408/  512]\n",
      "    loss: -8.141147 | batch: [  459/  512]\n",
      "    loss: -7.837768 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.397217\n",
      "    val_loss = -6.410736\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 257 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.932414 | batch: [   51/  512]\n",
      "    loss: -8.102408 | batch: [  102/  512]\n",
      "    loss: -7.999016 | batch: [  153/  512]\n",
      "    loss: -8.306601 | batch: [  204/  512]\n",
      "    loss: -7.965097 | batch: [  255/  512]\n",
      "    loss: -8.036779 | batch: [  306/  512]\n",
      "    loss: -8.028611 | batch: [  357/  512]\n",
      "    loss: -8.389195 | batch: [  408/  512]\n",
      "    loss: -7.446558 | batch: [  459/  512]\n",
      "    loss: -8.237726 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.397664\n",
      "    val_loss = -6.405435\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 258 --------------\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -8.087611 | batch: [   51/  512]\n",
      "    loss: -7.843795 | batch: [  102/  512]\n",
      "    loss: -7.358210 | batch: [  153/  512]\n",
      "    loss: -8.373377 | batch: [  204/  512]\n",
      "    loss: -6.772175 | batch: [  255/  512]\n",
      "    loss: -7.710175 | batch: [  306/  512]\n",
      "    loss: -7.573834 | batch: [  357/  512]\n",
      "    loss: -8.033219 | batch: [  408/  512]\n",
      "    loss: -8.359263 | batch: [  459/  512]\n",
      "    loss: -7.955659 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.386984\n",
      "    val_loss = -6.408234\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 259 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.325211 | batch: [   51/  512]\n",
      "    loss: -8.224363 | batch: [  102/  512]\n",
      "    loss: -7.483900 | batch: [  153/  512]\n",
      "    loss: -7.646272 | batch: [  204/  512]\n",
      "    loss: -8.283000 | batch: [  255/  512]\n",
      "    loss: -6.501084 | batch: [  306/  512]\n",
      "    loss: -8.259593 | batch: [  357/  512]\n",
      "    loss: -8.017514 | batch: [  408/  512]\n",
      "    loss: -8.232813 | batch: [  459/  512]\n",
      "    loss: -7.983086 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.413640\n",
      "    val_loss = -6.421184\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 260 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.207954 | batch: [   51/  512]\n",
      "    loss: -8.347182 | batch: [  102/  512]\n",
      "    loss: -7.727400 | batch: [  153/  512]\n",
      "    loss: -8.248006 | batch: [  204/  512]\n",
      "    loss: -7.938425 | batch: [  255/  512]\n",
      "    loss: -7.695484 | batch: [  306/  512]\n",
      "    loss: -7.681138 | batch: [  357/  512]\n",
      "    loss: -7.790791 | batch: [  408/  512]\n",
      "    loss: -7.715995 | batch: [  459/  512]\n",
      "    loss: -8.215944 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.423906\n",
      "    val_loss = -6.373301\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 261 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.794344 | batch: [   51/  512]\n",
      "    loss: -7.897719 | batch: [  102/  512]\n",
      "    loss: -8.125425 | batch: [  153/  512]\n",
      "    loss: -7.983304 | batch: [  204/  512]\n",
      "    loss: -7.792077 | batch: [  255/  512]\n",
      "    loss: -7.500659 | batch: [  306/  512]\n",
      "    loss: -8.463519 | batch: [  357/  512]\n",
      "    loss: -7.815646 | batch: [  408/  512]\n",
      "    loss: -8.109920 | batch: [  459/  512]\n",
      "    loss: -8.252404 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.408296\n",
      "    val_loss = -6.390371\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 262 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.076466 | batch: [   51/  512]\n",
      "    loss: -8.060017 | batch: [  102/  512]\n",
      "    loss: -8.379498 | batch: [  153/  512]\n",
      "    loss: -7.993831 | batch: [  204/  512]\n",
      "    loss: -8.132477 | batch: [  255/  512]\n",
      "    loss: -7.279240 | batch: [  306/  512]\n",
      "    loss: -7.880131 | batch: [  357/  512]\n",
      "    loss: -7.929602 | batch: [  408/  512]\n",
      "    loss: -8.110409 | batch: [  459/  512]\n",
      "    loss: -7.853056 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.415853\n",
      "    val_loss = -6.431051\n",
      "Epoch 00262: reducing learning rate of group 0 to 2.1870e-07.\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 263 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.425862 | batch: [   51/  512]\n",
      "    loss: -7.901166 | batch: [  102/  512]\n",
      "    loss: -8.082746 | batch: [  153/  512]\n",
      "    loss: -8.143076 | batch: [  204/  512]\n",
      "    loss: -8.017555 | batch: [  255/  512]\n",
      "    loss: -7.724895 | batch: [  306/  512]\n",
      "    loss: -8.081666 | batch: [  357/  512]\n",
      "    loss: -7.978519 | batch: [  408/  512]\n",
      "    loss: -7.610162 | batch: [  459/  512]\n",
      "    loss: -7.952652 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.388731\n",
      "    val_loss = -6.402696\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 264 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.205674 | batch: [   51/  512]\n",
      "    loss: -8.144666 | batch: [  102/  512]\n",
      "    loss: -8.105249 | batch: [  153/  512]\n",
      "    loss: -7.262032 | batch: [  204/  512]\n",
      "    loss: -7.945229 | batch: [  255/  512]\n",
      "    loss: -7.820404 | batch: [  306/  512]\n",
      "    loss: -7.947780 | batch: [  357/  512]\n",
      "    loss: -8.269854 | batch: [  408/  512]\n",
      "    loss: -7.094270 | batch: [  459/  512]\n",
      "    loss: -8.408933 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.428394\n",
      "    val_loss = -6.435509\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 265 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.965141 | batch: [   51/  512]\n",
      "    loss: -8.005624 | batch: [  102/  512]\n",
      "    loss: -7.742392 | batch: [  153/  512]\n",
      "    loss: -8.302657 | batch: [  204/  512]\n",
      "    loss: -8.348337 | batch: [  255/  512]\n",
      "    loss: -8.094810 | batch: [  306/  512]\n",
      "    loss: -7.361721 | batch: [  357/  512]\n",
      "    loss: -7.961843 | batch: [  408/  512]\n",
      "    loss: -8.472358 | batch: [  459/  512]\n",
      "    loss: -7.808126 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.402833\n",
      "    val_loss = -6.380318\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 266 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.093991 | batch: [   51/  512]\n",
      "    loss: -8.303444 | batch: [  102/  512]\n",
      "    loss: -8.192322 | batch: [  153/  512]\n",
      "    loss: -8.422606 | batch: [  204/  512]\n",
      "    loss: -7.881951 | batch: [  255/  512]\n",
      "    loss: -8.258664 | batch: [  306/  512]\n",
      "    loss: -7.798257 | batch: [  357/  512]\n",
      "    loss: -7.858612 | batch: [  408/  512]\n",
      "    loss: -7.689856 | batch: [  459/  512]\n",
      "    loss: -8.392289 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.357306\n",
      "    val_loss = -6.372993\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 267 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.738043 | batch: [   51/  512]\n",
      "    loss: -8.138417 | batch: [  102/  512]\n",
      "    loss: -8.234282 | batch: [  153/  512]\n",
      "    loss: -7.579981 | batch: [  204/  512]\n",
      "    loss: -7.836757 | batch: [  255/  512]\n",
      "    loss: -8.309025 | batch: [  306/  512]\n",
      "    loss: -8.037811 | batch: [  357/  512]\n",
      "    loss: -8.192046 | batch: [  408/  512]\n",
      "    loss: -7.933049 | batch: [  459/  512]\n",
      "    loss: -7.679169 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.421475\n",
      "    val_loss = -6.426892\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 268 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.337514 | batch: [   51/  512]\n",
      "    loss: -7.888929 | batch: [  102/  512]\n",
      "    loss: -7.805362 | batch: [  153/  512]\n",
      "    loss: -8.035399 | batch: [  204/  512]\n",
      "    loss: -8.119003 | batch: [  255/  512]\n",
      "    loss: -7.684915 | batch: [  306/  512]\n",
      "    loss: -8.004241 | batch: [  357/  512]\n",
      "    loss: -7.890893 | batch: [  408/  512]\n",
      "    loss: -8.035304 | batch: [  459/  512]\n",
      "    loss: -7.358265 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.413042\n",
      "    val_loss = -6.397701\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 269 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.020056 | batch: [   51/  512]\n",
      "    loss: -7.657928 | batch: [  102/  512]\n",
      "    loss: -6.940647 | batch: [  153/  512]\n",
      "    loss: -7.106233 | batch: [  204/  512]\n",
      "    loss: -8.420998 | batch: [  255/  512]\n",
      "    loss: -7.933455 | batch: [  306/  512]\n",
      "    loss: -8.351440 | batch: [  357/  512]\n",
      "    loss: -7.454970 | batch: [  408/  512]\n",
      "    loss: -8.410395 | batch: [  459/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -8.110725 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.426805\n",
      "    val_loss = -6.433635\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 270 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.159691 | batch: [   51/  512]\n",
      "    loss: -7.968309 | batch: [  102/  512]\n",
      "    loss: -7.877506 | batch: [  153/  512]\n",
      "    loss: -7.731649 | batch: [  204/  512]\n",
      "    loss: -8.280301 | batch: [  255/  512]\n",
      "    loss: -7.952706 | batch: [  306/  512]\n",
      "    loss: -8.149199 | batch: [  357/  512]\n",
      "    loss: -6.994458 | batch: [  408/  512]\n",
      "    loss: -8.123665 | batch: [  459/  512]\n",
      "    loss: -8.137007 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.417215\n",
      "    val_loss = -6.427797\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 271 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.572815 | batch: [   51/  512]\n",
      "    loss: -8.217430 | batch: [  102/  512]\n",
      "    loss: -7.530558 | batch: [  153/  512]\n",
      "    loss: -8.079012 | batch: [  204/  512]\n",
      "    loss: -7.863732 | batch: [  255/  512]\n",
      "    loss: -8.285956 | batch: [  306/  512]\n",
      "    loss: -7.840288 | batch: [  357/  512]\n",
      "    loss: -7.667223 | batch: [  408/  512]\n",
      "    loss: -7.666779 | batch: [  459/  512]\n",
      "    loss: -8.083628 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.398214\n",
      "    val_loss = -6.407994\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 272 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.083302 | batch: [   51/  512]\n",
      "    loss: -8.108659 | batch: [  102/  512]\n",
      "    loss: -7.938103 | batch: [  153/  512]\n",
      "    loss: -8.301595 | batch: [  204/  512]\n",
      "    loss: -8.473906 | batch: [  255/  512]\n",
      "    loss: -8.308434 | batch: [  306/  512]\n",
      "    loss: -8.031228 | batch: [  357/  512]\n",
      "    loss: -8.137075 | batch: [  408/  512]\n",
      "    loss: -8.043294 | batch: [  459/  512]\n",
      "    loss: -7.931810 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.364599\n",
      "    val_loss = -6.378782\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 273 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.908359 | batch: [   51/  512]\n",
      "    loss: -8.303746 | batch: [  102/  512]\n",
      "    loss: -7.913347 | batch: [  153/  512]\n",
      "    loss: -8.316342 | batch: [  204/  512]\n",
      "    loss: -7.991612 | batch: [  255/  512]\n",
      "    loss: -7.894366 | batch: [  306/  512]\n",
      "    loss: -7.741707 | batch: [  357/  512]\n",
      "    loss: -7.941562 | batch: [  408/  512]\n",
      "    loss: -8.067044 | batch: [  459/  512]\n",
      "    loss: -7.825549 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.402308\n",
      "    val_loss = -6.410350\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 274 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.099173 | batch: [   51/  512]\n",
      "    loss: -8.371927 | batch: [  102/  512]\n",
      "    loss: -7.805888 | batch: [  153/  512]\n",
      "    loss: -8.215110 | batch: [  204/  512]\n",
      "    loss: -8.237364 | batch: [  255/  512]\n",
      "    loss: -7.772778 | batch: [  306/  512]\n",
      "    loss: -7.543439 | batch: [  357/  512]\n",
      "    loss: -7.871874 | batch: [  408/  512]\n",
      "    loss: -8.015503 | batch: [  459/  512]\n",
      "    loss: -8.238837 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.441936\n",
      "    val_loss = -6.432493\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 275 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.904474 | batch: [   51/  512]\n",
      "    loss: -7.461952 | batch: [  102/  512]\n",
      "    loss: -8.029036 | batch: [  153/  512]\n",
      "    loss: -8.070649 | batch: [  204/  512]\n",
      "    loss: -8.367677 | batch: [  255/  512]\n",
      "    loss: -8.017112 | batch: [  306/  512]\n",
      "    loss: -7.589356 | batch: [  357/  512]\n",
      "    loss: -8.148945 | batch: [  408/  512]\n",
      "    loss: -8.072314 | batch: [  459/  512]\n",
      "    loss: -8.089085 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.426845\n",
      "    val_loss = -6.432235\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 276 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.135909 | batch: [   51/  512]\n",
      "    loss: -8.023911 | batch: [  102/  512]\n",
      "    loss: -8.340268 | batch: [  153/  512]\n",
      "    loss: -8.172046 | batch: [  204/  512]\n",
      "    loss: -8.395931 | batch: [  255/  512]\n",
      "    loss: -8.100629 | batch: [  306/  512]\n",
      "    loss: -7.745319 | batch: [  357/  512]\n",
      "    loss: -8.081744 | batch: [  408/  512]\n",
      "    loss: -7.997572 | batch: [  459/  512]\n",
      "    loss: -8.030893 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.377974\n",
      "    val_loss = -6.392054\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 277 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.068871 | batch: [   51/  512]\n",
      "    loss: -8.263676 | batch: [  102/  512]\n",
      "    loss: -8.173518 | batch: [  153/  512]\n",
      "    loss: -8.014881 | batch: [  204/  512]\n",
      "    loss: -7.981968 | batch: [  255/  512]\n",
      "    loss: -8.139063 | batch: [  306/  512]\n",
      "    loss: -8.291291 | batch: [  357/  512]\n",
      "    loss: -7.971611 | batch: [  408/  512]\n",
      "    loss: -8.423344 | batch: [  459/  512]\n",
      "    loss: -8.353770 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.370533\n",
      "    val_loss = -6.374925\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 278 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.363099 | batch: [   51/  512]\n",
      "    loss: -7.889532 | batch: [  102/  512]\n",
      "    loss: -8.128368 | batch: [  153/  512]\n",
      "    loss: -7.850310 | batch: [  204/  512]\n",
      "    loss: -8.130153 | batch: [  255/  512]\n",
      "    loss: -8.029881 | batch: [  306/  512]\n",
      "    loss: -8.087399 | batch: [  357/  512]\n",
      "    loss: -8.037567 | batch: [  408/  512]\n",
      "    loss: -8.233699 | batch: [  459/  512]\n",
      "    loss: -7.892860 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.362313\n",
      "    val_loss = -6.378422\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 279 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.069574 | batch: [   51/  512]\n",
      "    loss: -8.015484 | batch: [  102/  512]\n",
      "    loss: -8.015290 | batch: [  153/  512]\n",
      "    loss: -7.242130 | batch: [  204/  512]\n",
      "    loss: -8.188552 | batch: [  255/  512]\n",
      "    loss: -8.098780 | batch: [  306/  512]\n",
      "    loss: -8.240146 | batch: [  357/  512]\n",
      "    loss: -7.880355 | batch: [  408/  512]\n",
      "    loss: -7.965303 | batch: [  459/  512]\n",
      "    loss: -7.832768 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.400045\n",
      "    val_loss = -6.414894\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 280 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.283684 | batch: [   51/  512]\n",
      "    loss: -8.198903 | batch: [  102/  512]\n",
      "    loss: -7.251503 | batch: [  153/  512]\n",
      "    loss: -8.192293 | batch: [  204/  512]\n",
      "    loss: -6.874437 | batch: [  255/  512]\n",
      "    loss: -7.769269 | batch: [  306/  512]\n",
      "    loss: -7.841354 | batch: [  357/  512]\n",
      "    loss: -8.400426 | batch: [  408/  512]\n",
      "    loss: -7.863583 | batch: [  459/  512]\n",
      "    loss: -8.282638 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.424814\n",
      "    val_loss = -6.415926\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 281 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.029069 | batch: [   51/  512]\n",
      "    loss: -8.148327 | batch: [  102/  512]\n",
      "    loss: -8.221257 | batch: [  153/  512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -8.142015 | batch: [  204/  512]\n",
      "    loss: -7.775508 | batch: [  255/  512]\n",
      "    loss: -7.914419 | batch: [  306/  512]\n",
      "    loss: -8.103599 | batch: [  357/  512]\n",
      "    loss: -7.755075 | batch: [  408/  512]\n",
      "    loss: -8.037695 | batch: [  459/  512]\n",
      "    loss: -8.298652 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.430825\n",
      "    val_loss = -6.432006\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 282 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.177758 | batch: [   51/  512]\n",
      "    loss: -7.469458 | batch: [  102/  512]\n",
      "    loss: -7.770541 | batch: [  153/  512]\n",
      "    loss: -8.327889 | batch: [  204/  512]\n",
      "    loss: -8.493128 | batch: [  255/  512]\n",
      "    loss: -8.290772 | batch: [  306/  512]\n",
      "    loss: -7.296863 | batch: [  357/  512]\n",
      "    loss: -7.830082 | batch: [  408/  512]\n",
      "    loss: -7.940163 | batch: [  459/  512]\n",
      "    loss: -8.334415 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.428847\n",
      "    val_loss = -6.438516\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 283 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.517101 | batch: [   51/  512]\n",
      "    loss: -8.375898 | batch: [  102/  512]\n",
      "    loss: -6.065077 | batch: [  153/  512]\n",
      "    loss: -8.151849 | batch: [  204/  512]\n",
      "    loss: -8.086291 | batch: [  255/  512]\n",
      "    loss: -7.577872 | batch: [  306/  512]\n",
      "    loss: -8.226771 | batch: [  357/  512]\n",
      "    loss: -8.202371 | batch: [  408/  512]\n",
      "    loss: -8.262483 | batch: [  459/  512]\n",
      "    loss: -8.098931 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.371596\n",
      "    val_loss = -6.383755\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 284 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.287768 | batch: [   51/  512]\n",
      "    loss: -8.280201 | batch: [  102/  512]\n",
      "    loss: -7.951849 | batch: [  153/  512]\n",
      "    loss: -8.048413 | batch: [  204/  512]\n",
      "    loss: -8.231821 | batch: [  255/  512]\n",
      "    loss: -7.359375 | batch: [  306/  512]\n",
      "    loss: -7.564956 | batch: [  357/  512]\n",
      "    loss: -8.122444 | batch: [  408/  512]\n",
      "    loss: -7.985651 | batch: [  459/  512]\n",
      "    loss: -7.698239 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.382878\n",
      "    val_loss = -6.402103\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 285 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.657026 | batch: [   51/  512]\n",
      "    loss: -8.248236 | batch: [  102/  512]\n",
      "    loss: -8.404865 | batch: [  153/  512]\n",
      "    loss: -8.229245 | batch: [  204/  512]\n",
      "    loss: -8.071193 | batch: [  255/  512]\n",
      "    loss: -8.179779 | batch: [  306/  512]\n",
      "    loss: -8.148025 | batch: [  357/  512]\n",
      "    loss: -7.892869 | batch: [  408/  512]\n",
      "    loss: -7.687138 | batch: [  459/  512]\n",
      "    loss: -7.924109 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.340472\n",
      "    val_loss = -6.325719\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 286 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.339998 | batch: [   51/  512]\n",
      "    loss: -8.441626 | batch: [  102/  512]\n",
      "    loss: -8.283957 | batch: [  153/  512]\n",
      "    loss: -7.925022 | batch: [  204/  512]\n",
      "    loss: -7.468088 | batch: [  255/  512]\n",
      "    loss: -7.904410 | batch: [  306/  512]\n",
      "    loss: -8.080965 | batch: [  357/  512]\n",
      "    loss: -7.805760 | batch: [  408/  512]\n",
      "    loss: -8.131096 | batch: [  459/  512]\n",
      "    loss: -8.228256 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.440292\n",
      "    val_loss = -6.436671\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 287 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.529210 | batch: [   51/  512]\n",
      "    loss: -7.465978 | batch: [  102/  512]\n",
      "    loss: -7.807281 | batch: [  153/  512]\n",
      "    loss: -8.141276 | batch: [  204/  512]\n",
      "    loss: -7.928270 | batch: [  255/  512]\n",
      "    loss: -8.116169 | batch: [  306/  512]\n",
      "    loss: -8.271376 | batch: [  357/  512]\n",
      "    loss: -7.818132 | batch: [  408/  512]\n",
      "    loss: -7.849569 | batch: [  459/  512]\n",
      "    loss: -7.895508 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.405530\n",
      "    val_loss = -6.419164\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 288 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.040164 | batch: [   51/  512]\n",
      "    loss: -7.470509 | batch: [  102/  512]\n",
      "    loss: -8.109724 | batch: [  153/  512]\n",
      "    loss: -8.010976 | batch: [  204/  512]\n",
      "    loss: -7.960273 | batch: [  255/  512]\n",
      "    loss: -7.990960 | batch: [  306/  512]\n",
      "    loss: -7.744412 | batch: [  357/  512]\n",
      "    loss: -7.636084 | batch: [  408/  512]\n",
      "    loss: -8.289383 | batch: [  459/  512]\n",
      "    loss: -8.066470 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.407763\n",
      "    val_loss = -6.417475\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 289 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.693915 | batch: [   51/  512]\n",
      "    loss: -7.902682 | batch: [  102/  512]\n",
      "    loss: -8.332305 | batch: [  153/  512]\n",
      "    loss: -8.157018 | batch: [  204/  512]\n",
      "    loss: -8.203014 | batch: [  255/  512]\n",
      "    loss: -8.489345 | batch: [  306/  512]\n",
      "    loss: -7.669580 | batch: [  357/  512]\n",
      "    loss: -8.079542 | batch: [  408/  512]\n",
      "    loss: -7.879473 | batch: [  459/  512]\n",
      "    loss: -7.835404 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.412165\n",
      "    val_loss = -6.426579\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 290 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.317784 | batch: [   51/  512]\n",
      "    loss: -8.086887 | batch: [  102/  512]\n",
      "    loss: -7.705420 | batch: [  153/  512]\n",
      "    loss: -8.035119 | batch: [  204/  512]\n",
      "    loss: -7.365008 | batch: [  255/  512]\n",
      "    loss: -8.279961 | batch: [  306/  512]\n",
      "    loss: -8.043843 | batch: [  357/  512]\n",
      "    loss: -8.273734 | batch: [  408/  512]\n",
      "    loss: -8.249466 | batch: [  459/  512]\n",
      "    loss: -7.585839 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.420031\n",
      "    val_loss = -6.433825\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 291 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.292415 | batch: [   51/  512]\n",
      "    loss: -8.270943 | batch: [  102/  512]\n",
      "    loss: -8.256598 | batch: [  153/  512]\n",
      "    loss: -7.634646 | batch: [  204/  512]\n",
      "    loss: -7.499704 | batch: [  255/  512]\n",
      "    loss: -7.530682 | batch: [  306/  512]\n",
      "    loss: -8.335523 | batch: [  357/  512]\n",
      "    loss: -7.341720 | batch: [  408/  512]\n",
      "    loss: -8.145112 | batch: [  459/  512]\n",
      "    loss: -6.125673 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.412119\n",
      "    val_loss = -6.426572\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 292 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.020134 | batch: [   51/  512]\n",
      "    loss: -7.979730 | batch: [  102/  512]\n",
      "    loss: -7.921247 | batch: [  153/  512]\n",
      "    loss: -7.903121 | batch: [  204/  512]\n",
      "    loss: -7.734398 | batch: [  255/  512]\n",
      "    loss: -7.710429 | batch: [  306/  512]\n",
      "    loss: -8.310091 | batch: [  357/  512]\n",
      "    loss: -7.733880 | batch: [  408/  512]\n",
      "    loss: -8.004817 | batch: [  459/  512]\n",
      "    loss: -8.153179 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.425257\n",
      "    val_loss = -6.431425\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 293 --------------\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss: -7.780154 | batch: [   51/  512]\n",
      "    loss: -7.868979 | batch: [  102/  512]\n",
      "    loss: -8.244761 | batch: [  153/  512]\n",
      "    loss: -7.972445 | batch: [  204/  512]\n",
      "    loss: -7.977626 | batch: [  255/  512]\n",
      "    loss: -8.203180 | batch: [  306/  512]\n",
      "    loss: -7.588324 | batch: [  357/  512]\n",
      "    loss: -7.332750 | batch: [  408/  512]\n",
      "    loss: -8.113297 | batch: [  459/  512]\n",
      "    loss: -7.616636 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.440177\n",
      "    val_loss = -6.441028\n",
      "Epoch 00293: reducing learning rate of group 0 to 6.5610e-08.\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 294 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.196744 | batch: [   51/  512]\n",
      "    loss: -8.244374 | batch: [  102/  512]\n",
      "    loss: -7.850173 | batch: [  153/  512]\n",
      "    loss: -8.294567 | batch: [  204/  512]\n",
      "    loss: -7.918967 | batch: [  255/  512]\n",
      "    loss: -7.871542 | batch: [  306/  512]\n",
      "    loss: -7.998578 | batch: [  357/  512]\n",
      "    loss: -8.128290 | batch: [  408/  512]\n",
      "    loss: -8.220559 | batch: [  459/  512]\n",
      "    loss: -7.723604 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.402489\n",
      "    val_loss = -6.410063\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 295 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.094414 | batch: [   51/  512]\n",
      "    loss: -8.206499 | batch: [  102/  512]\n",
      "    loss: -7.693557 | batch: [  153/  512]\n",
      "    loss: -8.158175 | batch: [  204/  512]\n",
      "    loss: -7.396374 | batch: [  255/  512]\n",
      "    loss: -8.229543 | batch: [  306/  512]\n",
      "    loss: -8.115484 | batch: [  357/  512]\n",
      "    loss: -8.188912 | batch: [  408/  512]\n",
      "    loss: -7.977197 | batch: [  459/  512]\n",
      "    loss: -8.156536 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.442407\n",
      "    val_loss = -6.445204\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 296 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.301030 | batch: [   51/  512]\n",
      "    loss: -7.143549 | batch: [  102/  512]\n",
      "    loss: -8.040874 | batch: [  153/  512]\n",
      "    loss: -8.319431 | batch: [  204/  512]\n",
      "    loss: -8.125113 | batch: [  255/  512]\n",
      "    loss: -8.004242 | batch: [  306/  512]\n",
      "    loss: -8.116760 | batch: [  357/  512]\n",
      "    loss: -8.334918 | batch: [  408/  512]\n",
      "    loss: -7.847600 | batch: [  459/  512]\n",
      "    loss: -8.298628 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.408340\n",
      "    val_loss = -6.412957\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 297 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.320926 | batch: [   51/  512]\n",
      "    loss: -7.646693 | batch: [  102/  512]\n",
      "    loss: -8.102211 | batch: [  153/  512]\n",
      "    loss: -7.601487 | batch: [  204/  512]\n",
      "    loss: -8.150728 | batch: [  255/  512]\n",
      "    loss: -8.053169 | batch: [  306/  512]\n",
      "    loss: -7.907142 | batch: [  357/  512]\n",
      "    loss: -8.068713 | batch: [  408/  512]\n",
      "    loss: -8.058977 | batch: [  459/  512]\n",
      "    loss: -7.893747 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.447562\n",
      "    val_loss = -6.451344\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 298 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.134575 | batch: [   51/  512]\n",
      "    loss: -8.120655 | batch: [  102/  512]\n",
      "    loss: -7.665430 | batch: [  153/  512]\n",
      "    loss: -7.962599 | batch: [  204/  512]\n",
      "    loss: -8.004613 | batch: [  255/  512]\n",
      "    loss: -8.293157 | batch: [  306/  512]\n",
      "    loss: -7.797106 | batch: [  357/  512]\n",
      "    loss: -8.255398 | batch: [  408/  512]\n",
      "    loss: -8.196857 | batch: [  459/  512]\n",
      "    loss: -8.503304 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.425530\n",
      "    val_loss = -6.426822\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 299 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -8.170960 | batch: [   51/  512]\n",
      "    loss: -8.190497 | batch: [  102/  512]\n",
      "    loss: -8.165972 | batch: [  153/  512]\n",
      "    loss: -8.022620 | batch: [  204/  512]\n",
      "    loss: -7.263330 | batch: [  255/  512]\n",
      "    loss: -8.324217 | batch: [  306/  512]\n",
      "    loss: -7.998112 | batch: [  357/  512]\n",
      "    loss: -8.378293 | batch: [  408/  512]\n",
      "    loss: -7.904004 | batch: [  459/  512]\n",
      "    loss: -7.876215 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.379576\n",
      "    val_loss = -6.349018\n",
      "\n",
      "--------- done eval epoch --------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "-------------- Epoch 300 --------------\n",
      "-------------------------------------\n",
      "\n",
      "    loss: -7.585464 | batch: [   51/  512]\n",
      "    loss: -8.279148 | batch: [  102/  512]\n",
      "    loss: -8.166520 | batch: [  153/  512]\n",
      "    loss: -7.813255 | batch: [  204/  512]\n",
      "    loss: -8.357096 | batch: [  255/  512]\n",
      "    loss: -7.895415 | batch: [  306/  512]\n",
      "    loss: -7.892819 | batch: [  357/  512]\n",
      "    loss: -7.534940 | batch: [  408/  512]\n",
      "    loss: -8.168614 | batch: [  459/  512]\n",
      "    loss: -8.193646 | batch: [  510/  512]\n",
      "\n",
      "---------- done train epoch ---------\n",
      "\n",
      "    min_val_loss = -6.459142\n",
      "    train_loss = -6.430142\n",
      "    val_loss = -6.440438\n",
      "\n",
      "--------- done eval epoch --------\n"
     ]
    }
   ],
   "source": [
    "run_name = \"manual-sweep-0\"\n",
    "loss = cl_inference.wrapper_wandb_tools.wrapper_train_from_config(run_name=run_name, **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95214e2f",
   "metadata": {},
   "source": [
    "# PLOT LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "754dfdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute('tabindex', '0');\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;' +\n",
       "            'z-index: 2;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: relative;' +\n",
       "            'z-index: 0;'\n",
       "    );\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'left: 0;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: absolute;' +\n",
       "            'top: 0;' +\n",
       "            'z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            /* This rescales the canvas back to display pixels, so that it\n",
       "             * appears correct on HiDPI screens. */\n",
       "            canvas.style.width = width + 'px';\n",
       "            canvas.style.height = height + 'px';\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        /* User Agent sniffing is bad, but WebKit is busted:\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
       "         * The worst that happens here is that they get an extra browser\n",
       "         * selection when dragging, if this check fails to catch them.\n",
       "         */\n",
       "        var UA = navigator.userAgent;\n",
       "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
       "        if(isWebKit) {\n",
       "            return function (event) {\n",
       "                /* This prevents the web browser from automatically changing to\n",
       "                 * the text insertion cursor when the button is pressed. We\n",
       "                 * want to control all of the cursor setting manually through\n",
       "                 * the 'cursor' event from matplotlib */\n",
       "                event.preventDefault()\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        } else {\n",
       "            return function (event) {\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        }\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    canvas_div.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.canvas_div.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "function getModifiers(event) {\n",
       "    var mods = [];\n",
       "    if (event.ctrlKey) {\n",
       "        mods.push('ctrl');\n",
       "    }\n",
       "    if (event.altKey) {\n",
       "        mods.push('alt');\n",
       "    }\n",
       "    if (event.shiftKey) {\n",
       "        mods.push('shift');\n",
       "    }\n",
       "    if (event.metaKey) {\n",
       "        mods.push('meta');\n",
       "    }\n",
       "    return mods;\n",
       "}\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    // from https://stackoverflow.com/q/1114465\n",
       "    var boundingRect = this.canvas.getBoundingClientRect();\n",
       "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
       "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        modifiers: getModifiers(event),\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"700\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = np.loadtxt(os.path.join(config[\"path_save\"], run_name, 'register.txt'))\n",
    "\n",
    "custom_lines = [\n",
    "    mpl.lines.Line2D([0], [0], color='k', ls='-', lw=3, marker=None, markersize=9),\n",
    "    mpl.lines.Line2D([0], [0], color='k', ls='--', lw=3, marker=None, markersize=9)\n",
    "]\n",
    "\n",
    "fig, ax = cl_inference.plot_utils.simple_plot(\n",
    "    custom_labels=[r'Train', r'Val'],\n",
    "    custom_lines=custom_lines,\n",
    "    x_label='Epoch',\n",
    "    y_label='Loss'\n",
    ")\n",
    "\n",
    "ax.plot(losses[:, 0], c='k', lw=1, ls='-')\n",
    "ax.plot(losses[:, 1], c='k', lw=1, ls='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776a43ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
